{
    "docs": [
        {
            "location": "/", 
            "text": "Beam is a highly-general library for accessing any kind of database with\nHaskell. Currently, it supports two SQL backends, Postgres and SQLite. Work is\nunderway for an official MySQL backend (contributions appreciated and\naccepted!).\n\n\nBeam is highly extensible and other backends can be shipped independently\nwithout requiring any changes in the core libraries. For example, there is an\nindependently maintained \nFirebird\n\nbackend. For information on creating additional SQL backends, see\nthe \nmanual section\n for more.\n\n\nBeam features\n\n\n\n\nEasy schema generation\n from existing databases\n\n\nA basic migration infrastructure\n for working with multiple versions of your\n  database schema.\n\n\nSupport for most SQL92, SQL99, and SQL2003 features\n across backends that\n  support them, including aggregations, subqueries, and window functions.\n\n\nA straightforward Haskell-friendly query syntax\n. You can use Beam's \nQ\n\n  monad much like you would interact with the \n[]\n monad.\n\n\nNo Template Haskell\n Beam uses the GHC Haskell type system and nothing else.\n  The types have been designed to be easily-inferrable by the compiler, and\n  appropriate functions to refine types have been provided for the where the\n  compiler may need more help.\n\n\n\n\nHow to install\n\n\nBeam is available via both \nHackage\n\nand \nStack\n. For most Haskell\ninstallations, one of the two commands should work.\n\n\ncabal install beam-core beam-migrate \nbackend\n\n\n\n\n\n\nor\n\n\nstack install beam-core beam-migrate \nbackend\n\n\n\n\n\n\nYou will also need to install an appropriate backend. Available backends are\n\n\n\n\n\n\nbeam-postgres\n -- A feature-complete backend for the Postgres RDBMS.\n  See \nthe beam-postgres documentation\n\n  for more information.\n\n\n\n\n\n\nbeam-sqlite\n -- An almost feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to \nthe beam-sqlite documentation\n for\n  more information on compatibility.\n\n\n\n\n\n\nQuick Start Guide\n\n\nFor those looking to get started with beam, we first recommend you go through\nthe \ntutorial\n. The \nuser guide\n\ncontains much more detailed reference-like information. Finally, the\ndocumentation on hackage is always available (although the types may seem\nobtuse).\n\n\nIf you're interested if beam supports your favorite database feature, refer to\nthe documentation for your backend or take a look at\nthe \ncompatibility matrix\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Contribute\n\n\nWe always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the \nbeam-users\n Google\nGroup. The following is a quick step-by-step guide of contributing a new feature:\n\n\n\n\nFork the github repository at \nhttps://github.com/tathougies/beam\n\n   and clone the fork to a local directory.\n\n\nWork on your feature on your own branch, or pick\n   an \nissue\n.\n\n\nWhen you feel ready to contribute the feature back to \nbeam-core\n, send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.\n\n\nRespond to community comments and rework your patch.\n\n\nWhen the maintainer feels comfortable with your patch, he will commit it to\n   the \nmaster\n branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.\n\n\n\n\n\n\nTip\n\n\nBe sure to add your name to\nthe\n\nCONTRIBUTORS\n file\nfor eternal fame and glory!\n\n\n\n\nQuestions, Feedback, Discussion\n\n\n\n\nFor frequently asked questions, see the \nFAQ\n.\n\n\nFor general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list\n\n\nFor bugs or feature requests,\n  please \nopen an issue\n\n\n\n\nWhy Beam?\n\n\nBeam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the entire breadth of the SQL92, SQL99, SQL2003, SQL2006, SQL2008,\nSQL2011, and SQL2016 specifications, as well as the entire breadth of features\nof each of its backends. See the \ncompatibility matrix\n.\nYou will rarely be forced to write a SQL query 'by hand' when using Beam\n(but \nyou can\n).\n\n\nAdditionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of the underlying\n\ndb\n-simple\n packages. Beam provides only minimum support for querying data\nacross multiple databases. It is assumed that you have chosen you RDBMS with\nmuch care, and we want to support you in that. Beam's main purpose is to marshal\ndata back and forth, to serve as the source of truth for the DB schema, and to\ngenerate properly formed SQL from Haskell expressions.", 
            "title": "Home"
        }, 
        {
            "location": "/#how-to-install", 
            "text": "Beam is available via both  Hackage \nand  Stack . For most Haskell\ninstallations, one of the two commands should work.  cabal install beam-core beam-migrate  backend   or  stack install beam-core beam-migrate  backend   You will also need to install an appropriate backend. Available backends are    beam-postgres  -- A feature-complete backend for the Postgres RDBMS.\n  See  the beam-postgres documentation \n  for more information.    beam-sqlite  -- An almost feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to  the beam-sqlite documentation  for\n  more information on compatibility.", 
            "title": "How to install"
        }, 
        {
            "location": "/#quick-start-guide", 
            "text": "For those looking to get started with beam, we first recommend you go through\nthe  tutorial . The  user guide \ncontains much more detailed reference-like information. Finally, the\ndocumentation on hackage is always available (although the types may seem\nobtuse).  If you're interested if beam supports your favorite database feature, refer to\nthe documentation for your backend or take a look at\nthe  compatibility matrix .", 
            "title": "Quick Start Guide"
        }, 
        {
            "location": "/#how-to-contribute", 
            "text": "We always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the  beam-users  Google\nGroup. The following is a quick step-by-step guide of contributing a new feature:   Fork the github repository at  https://github.com/tathougies/beam \n   and clone the fork to a local directory.  Work on your feature on your own branch, or pick\n   an  issue .  When you feel ready to contribute the feature back to  beam-core , send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.  Respond to community comments and rework your patch.  When the maintainer feels comfortable with your patch, he will commit it to\n   the  master  branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.    Tip  Be sure to add your name to\nthe CONTRIBUTORS  file\nfor eternal fame and glory!", 
            "title": "How to Contribute"
        }, 
        {
            "location": "/#questions-feedback-discussion", 
            "text": "For frequently asked questions, see the  FAQ .  For general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list  For bugs or feature requests,\n  please  open an issue", 
            "title": "Questions, Feedback, Discussion"
        }, 
        {
            "location": "/#why-beam", 
            "text": "Beam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the entire breadth of the SQL92, SQL99, SQL2003, SQL2006, SQL2008,\nSQL2011, and SQL2016 specifications, as well as the entire breadth of features\nof each of its backends. See the  compatibility matrix .\nYou will rarely be forced to write a SQL query 'by hand' when using Beam\n(but  you can ).  Additionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of the underlying db -simple  packages. Beam provides only minimum support for querying data\nacross multiple databases. It is assumed that you have chosen you RDBMS with\nmuch care, and we want to support you in that. Beam's main purpose is to marshal\ndata back and forth, to serve as the source of truth for the DB schema, and to\ngenerate properly formed SQL from Haskell expressions.", 
            "title": "Why Beam?"
        }, 
        {
            "location": "/about/faq/", 
            "text": "How does \nbeam\n compare with \nx\n?\n\n\nHelp! The type checker keeps complaining about \nSyntax\n types\n\n\nSuppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.\n\n\nlistEmployees\n \n::\n \n(\nIsSql92Syntax\n \ncmd\n,\n \nMonadBeam\n \ncmd\n \nbe\n \nhdl\n \nm\n)\n \n=\n \nm\n \n[\nEmployee\n]\n\n\nlistEmployees\n \n=\n \nrunSelectReturningList\n \n$\n \nselect\n \n(\nall_\n \n(\nemployees\n \nemployeeDb\n))\n\n\n\n\n\n\nYou may get an error message like the following\n\n\nMyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of \nselect\n\n\n\n\n\n\nBeam uses a \nfinally-tagless\n\nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in \nWHERE\n and \nHAVING\n\nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking\n\nUndecidableSuperclasses\n extension in GHC).\n\n\nNevertheless, we can avoid all this hullabaloo by using the \nSql92SanityCheck\n\nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.\n\n\nlistEmployees\n \n::\n \n(\n \nIsSql92Syntax\n \ncmd\n,\n \nSql92SanityCheck\n \ncmd\n\n                 \n,\n \nMonadBeam\n \ncmd\n \nbe\n \nhdl\n \nm\n)\n\n              \n=\n \nm\n \n[\nEmployee\n]\n\n\nlistEmployees\n \n=\n \nrunSelectReturningList\n \n$\n \nselect\n \n(\nall_\n \n(\nemployees\n \nemployeeDb\n))\n\n\n\n\n\n\nOther database mappers simulate features on databases that lack support, why not beam?\n\n\nBeam assumes that the developer has picked their RDBMS for a reason. Beam does\nnot try to take on features of the RDBMS, because often there is no reasonable\nand equally performant substitution that can be made. Beam tries to follow the\nprinciple of least surprise -- the SQL queries beam generates should be easily\nguessable from the Haskell query DSL (modulo aliasing). Generating complicated\nemulation code which can result in unpredictable performance would violate this\nprinciple.", 
            "title": "Frequently Asked Questions"
        }, 
        {
            "location": "/about/faq/#how-does-beam-compare-with-x", 
            "text": "", 
            "title": "How does beam compare with &lt;x&gt;?"
        }, 
        {
            "location": "/about/faq/#help-the-type-checker-keeps-complaining-about-syntax-types", 
            "text": "Suppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.  listEmployees   ::   ( IsSql92Syntax   cmd ,   MonadBeam   cmd   be   hdl   m )   =   m   [ Employee ]  listEmployees   =   runSelectReturningList   $   select   ( all_   ( employees   employeeDb ))   You may get an error message like the following  MyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of  select   Beam uses a  finally-tagless \nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in  WHERE  and  HAVING \nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking UndecidableSuperclasses  extension in GHC).  Nevertheless, we can avoid all this hullabaloo by using the  Sql92SanityCheck \nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.  listEmployees   ::   (   IsSql92Syntax   cmd ,   Sql92SanityCheck   cmd \n                  ,   MonadBeam   cmd   be   hdl   m ) \n               =   m   [ Employee ]  listEmployees   =   runSelectReturningList   $   select   ( all_   ( employees   employeeDb ))", 
            "title": "Help! The type checker keeps complaining about Syntax types"
        }, 
        {
            "location": "/about/faq/#other-database-mappers-simulate-features-on-databases-that-lack-support-why-not-beam", 
            "text": "Beam assumes that the developer has picked their RDBMS for a reason. Beam does\nnot try to take on features of the RDBMS, because often there is no reasonable\nand equally performant substitution that can be made. Beam tries to follow the\nprinciple of least surprise -- the SQL queries beam generates should be easily\nguessable from the Haskell query DSL (modulo aliasing). Generating complicated\nemulation code which can result in unpredictable performance would violate this\nprinciple.", 
            "title": "Other database mappers simulate features on databases that lack support, why not beam?"
        }, 
        {
            "location": "/tutorials/tutorial1/", 
            "text": "In this tutorial sequence, we'll walk through creating a schema for a simple\nshopping cart database. We'll start by defining a user table. Then, we'll show\nhow beam makes it easy to manipulate data in our database. Finally, we'll\ndemonstrate how beam lets us declare type-safe and composable queries.\n\n\nBeam Module Structure\n\n\nBeam makes extensive use of GHC's Generics mechanism. This extension means beam does not need to\nrely on template haskell.\n\n\nTo start defining beam schemas and queries, you only need to import the\n\nDatabase.Beam\n module. To interface with an actual database, you'll need to\nimport one of the database backends. We'll see how to use the Sqlite backend\nhere (found in the \nbeam-sqlite\n package). Now, open up a GHCi prompt for us to\nuse. Make sure to get the \nbeam-core\n and \nbeam-sqlite\n packages.\n\n\n$\n stack repl --package beam-core --package beam-sqlite --package sqlite-simple\n\n\n\n\n\nThis will put you into a GHCi prompt with the \nbeam-core\n and \nbeam-sqlite\n\npackages available. We also include the \nsqlite-simple\n package. Beam mainly\nmanages querying and data marshalling. Connections to the backends are done via\nbackend specific packages. In this case, \nbeam-sqlite\n uses the \nsqlite-simple\n\nbackend.\n\n\nBefore starting, we'll need to enable some extensions.\n\n\n :set -XDeriveGeneric -XGADTs -XOverloadedStrings -XFlexibleContexts -XFlexibleInstances -XTypeFamilies -XTypeApplications\n\n\n\n\n\nAnd import some modules...\n\n\nimport\n \nDatabase.Beam\n\n\nimport\n \nDatabase.Beam.Sqlite\n\n\n\nimport\n \nData.Text\n \n(\nText\n)\n\n\n\n\n\n\nDefining our first table\n\n\nBeam tables are regular Haskell data types with a bit of scaffolding. Thankfully, the magic of the\nmodern Haskell type system allows us to remove the overhead and the syntactic fuzz of the\nscaffolding in most situations.\n\n\nWe start by declaring a data structure named \nUserT\n. As a matter of convention, Beam table types\nare suffixed with 'T'. Table types have only one constructor. Again, as a matter of convention, the\nconstructor has the same name as the table, but without the 'T' suffix. We'll soon see the reason\nfor this convention.\n\n\nIn this tutorial, I'll prefix all record selectors with an underscore. This is a matter of personal\npreference. One reason for the prefix is that it plays nicely with the \nlens\n library. Beam does not\nnecessitate the use of \nlens\n (in fact Beam includes its own mechanism to generically derive van\nLaarhoven lenses), but I recognize that some programmers use \nlens\n quite a lot.\n\n\ndata\n \nUserT\n \nf\n\n    \n=\n \nUser\n\n    \n{\n \n_userEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userPassword\n  \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n    \nderiving\n \nGeneric\n\n\n\n\n\n\nThis data type might look very complicated, so I'd like to show you that it's not that scary. Let's\nsee if we can use GHCi to help us.\n\n\nPrelude Database.Beam.Sqlite Database.Beam Data.Text\n :t User\nUser\n  :: Columnar f Text\n     -\n Columnar f Text -\n Columnar f Text -\n Columnar f Text -\n UserT f\n\n\n\n\n\nHmm... That did not help much. However, consider the type of the following:\n\n\nPrelude Database.Beam.Sqlite Database.Beam Data.Text\n :t (\\email firstName lastName password -\n User email firstName lastName password :: UserT Identity)\n(\\email firstName lastName password -\n User email firstName lastName password :: UserT Identity)\n  :: Text -\n Text -\n Text -\n Text -\n UserT Identity\n\n\n\n\n\nWoah! That looks a lot like what we'd expect if we had declared the type in the \"regular\" Haskell way:\n\n\ndata\n \nUser\n \n=\n \nUser\n\n          \n{\n \n_userEmail\n     \n::\n \nText\n\n          \n,\n \n_userFirstName\n \n::\n \nText\n\n          \n,\n \n_userLastName\n  \n::\n \nText\n\n          \n,\n \n_userPassword\n  \n::\n \nText\n \n}\n\n\n\n\n\n\nThis functionality is due to the fact that \nColumnar\n is a type family defined\nsuch that for any \nx\n, \nColumnar Identity x = x\n. This strategy is known as\n\ndefunctionalization\n \n1\n.\n\n\nKnowing this, let's define a type synonym to make our life easier.\n\n\ntype\n \nUser\n \n=\n \nUserT\n \nIdentity\n\n\ntype\n \nUserId\n \n=\n \nPrimaryKey\n \nUserT\n \nIdentity\n\n\n\n\n\n\nNow you can see why we named the type of the table \nUserT\n and its constructor\n\nUser\n. This allows us to use the \"regular\" \nUser\n constructor to construct\nvalues of type \nUser\n. We can use the \nStandaloneDeriving\n and\n\nTypeSynonymInstances\n extensions to derive instances of \nShow\n and \nEq\n for the\n'regular' datatype.\n\n\n :set -XStandaloneDeriving -XTypeSynonymInstances\n\n\n\n\n\nNow we can derive \nShow\n and \nEq\n instances.\n\n\nderiving\n \ninstance\n \nShow\n \nUser\n\n\nderiving\n \ninstance\n \nEq\n \nUser\n\n\n\n\n\n\nNote that this does require us to use an explicit type signature where we\notherwise wouldn't. For example,\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \nDatabase\n.\nBeam\n \nData\n.\nText\n \nUser\n \njohn@example.com\n \nJohn\n \nSmith\n \npassword!\n\n\n\ninteractive\n:\n46\n:\n2\n:\n \nerror\n:\n\n    \n*\n \nNo\n \ninstance\n \nfor\n \n(\nShow\n \n(\nUserT\n \nf0\n))\n \narising\n \nfrom\n \na\n \nuse\n \nof\n \nlsquo\n;\nprint\nrsquo\n;\n\n    \n*\n \nIn\n \na\n \nstmt\n \nof\n \nan\n \ninteractive\n \nGHCi\n \ncommand\n:\n \nprint\n \nit\n\n\n\n\n\n\nHere, GHC is complaining that it cannot infer the type of the \nf\n parameter\nbased on the values we've supplied. This is because the \nColumnar\n type family\nis non-injective. However, an explicit type annotation fixes it all up.\n\n\nPrelude Database.Beam.Sqlite Database.Beam Data.Text\n User \njohn@example.com\n \nJohn\n \nSmith\n \npassword!\n :: User\nUser {_userEmail = \njohn@example.com\n, _userFirstName = \nJohn\n, _userLastName = \nSmith\n, _userPassword = \npassword!\n}\n\n\n\n\n\nUsually, you won't need to deal with this, as you'll explicitly annotate your\ntop-level functions to use the \nUser\n type.\n\n\nTeaching Beam about our table\n\n\nWe've defined a type that can represent our the data in our table. Now, let's\ninform beam that we'd like to use \nUserT\n as a table.\n\n\nAll beam tables need to implement the \nBeamable\n type class. Due to GHC's\nDeriveGeneric and DefaultSignatures extensions, all these methods can be written\nfor us by the compiler at compile-time!\n\n\ninstance\n \nBeamable\n \nUserT\n\n\n\n\n\n\nAdditionally, all beam tables must implement the \nTable\n type class, which we\ncan use to declare a primary key.\n\n\ninstance\n \nTable\n \nUserT\n \nwhere\n\n\n\n\n\n\nThe only thing we need to provide is the type of the primary keys for users, and\na function that can extract the primary key from any \nUserT f\n object. To do\nthis, we just add the following lines to the instance declaration.\n\n\n    \ndata\n \nPrimaryKey\n \nUserT\n \nf\n \n=\n \nUserId\n \n(\nColumnar\n \nf\n \nText\n)\n \nderiving\n \nGeneric\n\n    \nprimaryKey\n \n=\n \nUserId\n \n.\n \n_userEmail\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nUserT\n)\n\n\n\n\n\n\n\n\nNote\n\n\nThe standalone \nBeamable\n instances are quite ugly. Luckily, the new\nderiving strategies extension in GHC 8.2 will allow us to write the\n\nBeamable\n instance 'in-line', so we can write \nderiving (Generic,\nBeamable)\n instead.\n\n\n\n\nDefining our database\n\n\nNow that we have our table, we're going to define a type to hold information about our\ndatabase. Defining our database is going to follow the same pattern as defining a table. We'll\ndefine a higher-kinded datatype and then declare an instance of \nDatabase\n, and let the compiler\nfigure most of it out.\n\n\nTables are a collection of \nColumnar\n values. Databases are a collection of\nentities, such as tables. Many database systems can also hold other entities\n(such as views, domain types, etc). Beam allows you to declare these as well \n2\n.\n\n\nOur database consists of only one table.\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n \n}\n\n                        \nderiving\n \nGeneric\n\n\n\ninstance\n \nDatabase\n \nShoppingCartDb\n\n\n\n\n\n\nThe next step is to create a description of the particular database we'd like to create. This\ninvolves giving each of the tables in our database a name. If you've named all your database\nselectors using camel case, beam can automatically figure out what all the table names should be. If\nyou haven't, or you have multiple tables holding the same type in your database, you might have to\nmanually name your tables. For now, we'll let beam do the hard work \n3\n.\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nAdding users to our database\n\n\nLet's add some users to our database. As we said above, beam is\nbackend-agnostic. However, backend integration libraries are maintained in the\nofficial beam repository. The \nbeam-sqlite\n package offers straightforwards\nintegration with the \nsqlite-simple\n library.\n\n\nFirst, let's create a sqlite3 database with the right schema. Open up terminal, and do\n\n\n$\n sqlite3 shoppingcart1.db\n\nSQLite version 3.14.0 2016-07-26 15:17:14\n\n\nEnter \n.help\n for usage hints.\n\n\nsqlite\n CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nsqlite\n\n\n\n\n\n\nNow, let's open the database in Haskell.\n\n\nimport\n \nDatabase.SQLite.Simple\n\n\n\nconn\n \n-\n \nopen\n \nshoppingcart1.db\n\n\n\n\n\n\n\n\nNote\n\n\nPrevious versions of beam would attempt automatic schema migration. This is\ndangerous and not required for many use cases. A more powerful\nimplementation of this functionality has been moved into the optional\n\nbeam-migrate\n package.\nSee \nthe appropriate documentation\n\n\n\n\nNow let's add a few users. We'll give each user an MD5 encoded password too.\nWe'll use the \nwithDatabaseDebug\n function (supplied by beam) to output the\nstatements that beam would normally run. In production, you'd use the\n\nwithDatabase\n function, or use the backend integration packages to directly use\nthe underlying backend library.\n\n\nwithDatabaseDebug\n \nputStrLn\n \n{- for debug output -}\n \nconn\n \n$\n \nrunInsert\n \n$\n\n\ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n\ninsertValues\n \n[\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n             \n,\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n             \n,\n \nUser\n \nsam@example.com\n \nSam\n \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n\n\n\n\n\nThe \nrunInsert\n function runs an insert statement, which we construct using the\n\ninsert\n function. Since we're inserting concrete values, we use the\n\ninsertValues\n function to supply the values. We can also use the\n\ninsertExpressions\n function to insert arbitrary SQL expressions, or the\n\ninsertFrom\n to insert the results of an arbitrary select (the \nINSERT INTO ..\nSELECT ..\n syntax).\n\n\nBecause we're in debug mode, we'll see the SQL that beam is running:\n\n\nINSERT INTO \ncart_users\n(\nemail\n, \nfirst_name\n, \nlast_name\n, \npassword\n) VALUES (?, ?, ?, ?), (?, ?, ?, ?), (?, ?, ?, ?)\n-- With values: [SQLText \njames@example.com\n,SQLText \nJames\n,SQLText \nSmith\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nbetty@example.com\n,SQLText \nBetty\n,SQLText \nJones\n,SQLText \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n,SQLText \nsam@example.com\n,SQLText \nSam\n,SQLText \nTaylor\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n]\n\n\n\n\n\nThe \n?\n represent the values passed to the database (beam uses the backend's\nvalue interpolation to avoid SQL injection attacks).\n\n\nQuerying the database\n\n\nNow let's write some queries for the database. Let's get all the users we just\nadded. Click between the tabs to see the SQL and console output generated\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nallUsers\n \n=\n \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nallUsers\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \njames@example.com\n,\n      _userFirstName = \nJames\n,\n      _userLastName = \nSmith\n,\n      _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n} --\nUser {_userEmail = \nbetty@example.com\n,\n      _userFirstName = \nBetty\n,\n      _userLastName = \nJones\n,\n      _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n} --\nUser {_userEmail = \nsam@example.com\n,\n      _userFirstName = \nSam\n,\n      _userLastName = \nTaylor\n,\n      _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nThe \n--\n at the ends of the console output lines are an artifact of the\ndocumentation build process. They won't appear in your console.\n\n\n\n\nNext let's suppose you wanted to sort the users into order by their first name,\nand then descending by their last name. We can use the \norderBy_\n function to\norder the query results. This is similar to the \nsortBy\n function for lists.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nsortUsersByFirstName\n \n=\n \norderBy_\n \n(\n\\\nu\n \n-\n \n(\nasc_\n \n(\n_userFirstName\n \nu\n),\n \ndesc_\n \n(\n_userLastName\n \nu\n)))\n \n(\nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n))\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nsortUsersByFirstName\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nfirst_name\n \nASC\n,\n\n         \nt0\n.\nlast_name\n \nDESC\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nbetty@example.com\n,\n      _userFirstName = \nBetty\n,\n      _userLastName = \nJones\n,\n      _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n} --\nUser {_userEmail = \njames@example.com\n,\n      _userFirstName = \nJames\n,\n      _userLastName = \nSmith\n,\n      _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n} --\nUser {_userEmail = \nsam@example.com\n,\n      _userFirstName = \nSam\n,\n      _userLastName = \nTaylor\n,\n      _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can use \nlimit_\n and \noffset_\n in a similar manner to \ntake\n and \ndrop\n respectively.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nboundedQuery\n \n::\n \nQ\n \nSqliteSelectSyntax\n \n_\n \n_\n \n_\n\n    \nboundedQuery\n \n=\n \nlimit_\n \n1\n \n$\n \noffset_\n \n1\n \n$\n\n                   \norderBy_\n \n(\nasc_\n \n.\n \n_userFirstName\n)\n \n$\n\n                   \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nusers\n \n-\n \nrunSelectReturningList\n \n(\nselect\n \nboundedQuery\n \n::\n \nSqlSelect\n \nSqliteSelectSyntax\n \n_\n)\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \nusers\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nfirst_name\n \nASC\n\n\nLIMIT\n \n1\n\n\nOFFSET\n \n1\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \njames@example.com\n,\n      _userFirstName = \nJames\n,\n      _userLastName = \nSmith\n,\n      _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nThe type signatures above are not necessary when run in GHCi. The\ndocumentation automates building and testing the queries, but the above\nresults in strange type errors in GHC. This may be a compiler type-inference\nbug. More investigation is being carried out.\n\n\nNevertheless, this shows how you could limit your queries to only work in a\nparticular syntax.\n\n\nThe \n_\n are type holes, which means GHC will happily infer these types, if\nthe \nPartialTypeSignatures\n extension is turned on.\n\n\n\n\nAggregations\n\n\nSometimes we also want to group our data together and perform calculations over\nthe groups of data. SQL calls these aggregations.\n\n\nThe simplest aggregation is counting. We use the \naggregate_\n function to create\naggregations. For example, to count all users, we can use the \ncountAll_\n\naggregation. We also use the \nrunSelectReturningOne\n function to get at most one\nrecord from the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nuserCount\n \n=\n \naggregate_\n \n(\n\\\nu\n \n-\n \nas_\n \n@\nInt\n \ncountAll_\n)\n \n(\nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n))\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nJust\n \nc\n \n-\n \nrunSelectReturningOne\n \n$\n \nselect\n \nuserCount\n\n  \nliftIO\n \n$\n \nputStrLn\n \n(\nWe have \n \n++\n \nshow\n \nc\n \n++\n \n users in the database\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nWe have 3 users in the database --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\ncountAll_\n is happy to unmarshal into any \nIntegral\n type, so we use \nas_\n\nto constrain the type to \nInt\n.\n\n\n\n\nMaybe we'd like something a little more interesting, such as the number of users\nfor each unique first name. We can also express these aggregations using the\n\naggregate_\n function. In order to get interesting results, we'll need to add\nmore users to our database. We'll demonstrate using \nwithDatabase\n to silence the debug messages.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n  \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertValues\n \n[\n \nUser\n \njames@pallo.com\n \nJames\n \nPallo\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n               \n,\n \nUser\n \nbetty@sims.com\n \nBetty\n \nSims\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n               \n,\n \nUser\n \njames@oreily.com\n \nJames\n \nO\nReily\n \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n               \n,\n \nUser\n \nsam@sophitz.com\n \nSam\n \nSophitz\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n\n               \n,\n \nUser\n \nsam@jely.com\n \nSam\n \nJely\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \ncart_users\n(\nemail\n,\n\n                         \nfirst_name\n,\n\n                         \nlast_name\n,\n\n                         \npassword\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n,\n\n             \n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n,\n\n                  \n?\n,\n\n                  \n?\n),\n \n(\n?\n,\n\n                       \n?\n,\n\n                       \n?\n,\n\n                       \n?\n),\n \n(\n?\n,\n\n                            \n?\n,\n\n                            \n?\n,\n\n                            \n?\n)\n \n-- With values: [SQLText \njames@pallo.com\n,SQLText \nJames\n,SQLText \nPallo\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nbetty@sims.com\n,SQLText \nBetty\n,SQLText \nSims\n,SQLText \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n,SQLText \njames@oreily.com\n,SQLText \nJames\n,SQLText \nO\nReily\n,SQLText \nb4cc344d25a2efe540adbf2678e2304c\n,SQLText \nsam@sophitz.com\n,SQLText \nSam\n,SQLText \nSophitz\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n,SQLText \nsam@jely.com\n,SQLText \nSam\n,SQLText \nJely\n,SQLText \n332532dcfaa1cbf61e2a266bd723612c\n]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow we can use \naggregate_\n to both group by a user's first name, and then count\nthe number of users.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOutput\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nnumberOfUsersByName\n \n=\n \naggregate_\n \n(\n\\\nu\n \n-\n \n(\ngroup_\n \n(\n_userFirstName\n \nu\n),\n \nas_\n \n@\nInt\n \ncountAll_\n))\n \n$\n \n                          \nall_\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \ncountedByName\n \n-\n \nrunSelectReturningList\n \n$\n \nselect\n \nnumberOfUsersByName\n\n  \nmapM_\n \n(\nliftIO\n \n.\n \nputStrLn\n \n.\n \nshow\n)\n \ncountedByName\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nfirst_name\n \nAS\n \nres0\n,\n\n       \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nfirst_name\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(\nBetty\n,\n 2) --\n(\nJames\n,\n 3) --\n(\nSam\n,\n 3) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nIn this tutorial, we've covered creating a database schema, opening up a beam\ndatabase, inserting values into the database, and querying values from them. We\nused the knowledge we learned to create a partial shopping cart database that\ncontains information about users. In the next tutorial, we'll delve deeper into\nthe some of the query types and show how we can create relations between tables.\nWe'll also use the monadic query interface to create SQL joins.\n\n\nUntil next time!\n\n\nIf you have any questions about beam, feel free to send them to\ntravis@athougies.net . Pull requests and bug reports are welcome\non \nGitHub\n.\n\n\n\n\n\n\n\n\n\n\nThanks to various bloggers for pointing this out. You can read more about this technique\n   \nhere\n.\n\n\n\n\n\n\nAdding entities other than tables is covered in more depth in\n   the \nuser guide\n.\n\n\n\n\n\n\nMore on the default naming conventions can be found in\n   the \nmodels section\n of the user guide. We'll talk\n   about how to override defaults in the next sections.", 
            "title": "Part 1"
        }, 
        {
            "location": "/tutorials/tutorial1/#beam-module-structure", 
            "text": "Beam makes extensive use of GHC's Generics mechanism. This extension means beam does not need to\nrely on template haskell.  To start defining beam schemas and queries, you only need to import the Database.Beam  module. To interface with an actual database, you'll need to\nimport one of the database backends. We'll see how to use the Sqlite backend\nhere (found in the  beam-sqlite  package). Now, open up a GHCi prompt for us to\nuse. Make sure to get the  beam-core  and  beam-sqlite  packages.  $  stack repl --package beam-core --package beam-sqlite --package sqlite-simple  This will put you into a GHCi prompt with the  beam-core  and  beam-sqlite \npackages available. We also include the  sqlite-simple  package. Beam mainly\nmanages querying and data marshalling. Connections to the backends are done via\nbackend specific packages. In this case,  beam-sqlite  uses the  sqlite-simple \nbackend.  Before starting, we'll need to enable some extensions.   :set -XDeriveGeneric -XGADTs -XOverloadedStrings -XFlexibleContexts -XFlexibleInstances -XTypeFamilies -XTypeApplications  And import some modules...  import   Database.Beam  import   Database.Beam.Sqlite  import   Data.Text   ( Text )", 
            "title": "Beam Module Structure"
        }, 
        {
            "location": "/tutorials/tutorial1/#defining-our-first-table", 
            "text": "Beam tables are regular Haskell data types with a bit of scaffolding. Thankfully, the magic of the\nmodern Haskell type system allows us to remove the overhead and the syntactic fuzz of the\nscaffolding in most situations.  We start by declaring a data structure named  UserT . As a matter of convention, Beam table types\nare suffixed with 'T'. Table types have only one constructor. Again, as a matter of convention, the\nconstructor has the same name as the table, but without the 'T' suffix. We'll soon see the reason\nfor this convention.  In this tutorial, I'll prefix all record selectors with an underscore. This is a matter of personal\npreference. One reason for the prefix is that it plays nicely with the  lens  library. Beam does not\nnecessitate the use of  lens  (in fact Beam includes its own mechanism to generically derive van\nLaarhoven lenses), but I recognize that some programmers use  lens  quite a lot.  data   UserT   f \n     =   User \n     {   _userEmail       ::   Columnar   f   Text \n     ,   _userFirstName   ::   Columnar   f   Text \n     ,   _userLastName    ::   Columnar   f   Text \n     ,   _userPassword    ::   Columnar   f   Text   } \n     deriving   Generic   This data type might look very complicated, so I'd like to show you that it's not that scary. Let's\nsee if we can use GHCi to help us.  Prelude Database.Beam.Sqlite Database.Beam Data.Text  :t User\nUser\n  :: Columnar f Text\n     -  Columnar f Text -  Columnar f Text -  Columnar f Text -  UserT f  Hmm... That did not help much. However, consider the type of the following:  Prelude Database.Beam.Sqlite Database.Beam Data.Text  :t (\\email firstName lastName password -  User email firstName lastName password :: UserT Identity)\n(\\email firstName lastName password -  User email firstName lastName password :: UserT Identity)\n  :: Text -  Text -  Text -  Text -  UserT Identity  Woah! That looks a lot like what we'd expect if we had declared the type in the \"regular\" Haskell way:  data   User   =   User \n           {   _userEmail       ::   Text \n           ,   _userFirstName   ::   Text \n           ,   _userLastName    ::   Text \n           ,   _userPassword    ::   Text   }   This functionality is due to the fact that  Columnar  is a type family defined\nsuch that for any  x ,  Columnar Identity x = x . This strategy is known as defunctionalization   1 .  Knowing this, let's define a type synonym to make our life easier.  type   User   =   UserT   Identity  type   UserId   =   PrimaryKey   UserT   Identity   Now you can see why we named the type of the table  UserT  and its constructor User . This allows us to use the \"regular\"  User  constructor to construct\nvalues of type  User . We can use the  StandaloneDeriving  and TypeSynonymInstances  extensions to derive instances of  Show  and  Eq  for the\n'regular' datatype.   :set -XStandaloneDeriving -XTypeSynonymInstances  Now we can derive  Show  and  Eq  instances.  deriving   instance   Show   User  deriving   instance   Eq   User   Note that this does require us to use an explicit type signature where we\notherwise wouldn't. For example,  Prelude   Database . Beam . Sqlite   Database . Beam   Data . Text   User   john@example.com   John   Smith   password!  interactive : 46 : 2 :   error : \n     *   No   instance   for   ( Show   ( UserT   f0 ))   arising   from   a   use   of   lsquo ; print rsquo ; \n     *   In   a   stmt   of   an   interactive   GHCi   command :   print   it   Here, GHC is complaining that it cannot infer the type of the  f  parameter\nbased on the values we've supplied. This is because the  Columnar  type family\nis non-injective. However, an explicit type annotation fixes it all up.  Prelude Database.Beam.Sqlite Database.Beam Data.Text  User  john@example.com   John   Smith   password!  :: User\nUser {_userEmail =  john@example.com , _userFirstName =  John , _userLastName =  Smith , _userPassword =  password! }  Usually, you won't need to deal with this, as you'll explicitly annotate your\ntop-level functions to use the  User  type.", 
            "title": "Defining our first table"
        }, 
        {
            "location": "/tutorials/tutorial1/#teaching-beam-about-our-table", 
            "text": "We've defined a type that can represent our the data in our table. Now, let's\ninform beam that we'd like to use  UserT  as a table.  All beam tables need to implement the  Beamable  type class. Due to GHC's\nDeriveGeneric and DefaultSignatures extensions, all these methods can be written\nfor us by the compiler at compile-time!  instance   Beamable   UserT   Additionally, all beam tables must implement the  Table  type class, which we\ncan use to declare a primary key.  instance   Table   UserT   where   The only thing we need to provide is the type of the primary keys for users, and\na function that can extract the primary key from any  UserT f  object. To do\nthis, we just add the following lines to the instance declaration.       data   PrimaryKey   UserT   f   =   UserId   ( Columnar   f   Text )   deriving   Generic \n     primaryKey   =   UserId   .   _userEmail  instance   Beamable   ( PrimaryKey   UserT )    Note  The standalone  Beamable  instances are quite ugly. Luckily, the new\nderiving strategies extension in GHC 8.2 will allow us to write the Beamable  instance 'in-line', so we can write  deriving (Generic,\nBeamable)  instead.", 
            "title": "Teaching Beam about our table"
        }, 
        {
            "location": "/tutorials/tutorial1/#defining-our-database", 
            "text": "Now that we have our table, we're going to define a type to hold information about our\ndatabase. Defining our database is going to follow the same pattern as defining a table. We'll\ndefine a higher-kinded datatype and then declare an instance of  Database , and let the compiler\nfigure most of it out.  Tables are a collection of  Columnar  values. Databases are a collection of\nentities, such as tables. Many database systems can also hold other entities\n(such as views, domain types, etc). Beam allows you to declare these as well  2 .  Our database consists of only one table.  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers   ::   f   ( TableEntity   UserT )   } \n                         deriving   Generic  instance   Database   ShoppingCartDb   The next step is to create a description of the particular database we'd like to create. This\ninvolves giving each of the tables in our database a name. If you've named all your database\nselectors using camel case, beam can automatically figure out what all the table names should be. If\nyou haven't, or you have multiple tables holding the same type in your database, you might have to\nmanually name your tables. For now, we'll let beam do the hard work  3 .  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings", 
            "title": "Defining our database"
        }, 
        {
            "location": "/tutorials/tutorial1/#adding-users-to-our-database", 
            "text": "Let's add some users to our database. As we said above, beam is\nbackend-agnostic. However, backend integration libraries are maintained in the\nofficial beam repository. The  beam-sqlite  package offers straightforwards\nintegration with the  sqlite-simple  library.  First, let's create a sqlite3 database with the right schema. Open up terminal, and do  $  sqlite3 shoppingcart1.db SQLite version 3.14.0 2016-07-26 15:17:14  Enter  .help  for usage hints.  sqlite  CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  sqlite   Now, let's open the database in Haskell.  import   Database.SQLite.Simple  conn   -   open   shoppingcart1.db    Note  Previous versions of beam would attempt automatic schema migration. This is\ndangerous and not required for many use cases. A more powerful\nimplementation of this functionality has been moved into the optional beam-migrate  package.\nSee  the appropriate documentation   Now let's add a few users. We'll give each user an MD5 encoded password too.\nWe'll use the  withDatabaseDebug  function (supplied by beam) to output the\nstatements that beam would normally run. In production, you'd use the withDatabase  function, or use the backend integration packages to directly use\nthe underlying backend library.  withDatabaseDebug   putStrLn   {- for debug output -}   conn   $   runInsert   $  insert   ( _shoppingCartUsers   shoppingCartDb )   $  insertValues   [   User   james@example.com   James   Smith   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n              ,   User   betty@example.com   Betty   Jones   82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n              ,   User   sam@example.com   Sam   Taylor   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ]   The  runInsert  function runs an insert statement, which we construct using the insert  function. Since we're inserting concrete values, we use the insertValues  function to supply the values. We can also use the insertExpressions  function to insert arbitrary SQL expressions, or the insertFrom  to insert the results of an arbitrary select (the  INSERT INTO ..\nSELECT ..  syntax).  Because we're in debug mode, we'll see the SQL that beam is running:  INSERT INTO  cart_users ( email ,  first_name ,  last_name ,  password ) VALUES (?, ?, ?, ?), (?, ?, ?, ?), (?, ?, ?, ?)\n-- With values: [SQLText  james@example.com ,SQLText  James ,SQLText  Smith ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  betty@example.com ,SQLText  Betty ,SQLText  Jones ,SQLText  82b054bd83ffad9b6cf8bdb98ce3cc2f ,SQLText  sam@example.com ,SQLText  Sam ,SQLText  Taylor ,SQLText  332532dcfaa1cbf61e2a266bd723612c ]  The  ?  represent the values passed to the database (beam uses the backend's\nvalue interpolation to avoid SQL injection attacks).", 
            "title": "Adding users to our database"
        }, 
        {
            "location": "/tutorials/tutorial1/#querying-the-database", 
            "text": "Now let's write some queries for the database. Let's get all the users we just\nadded. Click between the tabs to see the SQL and console output generated  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   allUsers   =   all_   ( _shoppingCartUsers   shoppingCartDb )  withDatabaseDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   $   select   allUsers \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0   -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  james@example.com ,\n      _userFirstName =  James ,\n      _userLastName =  Smith ,\n      _userPassword =  b4cc344d25a2efe540adbf2678e2304c } --\nUser {_userEmail =  betty@example.com ,\n      _userFirstName =  Betty ,\n      _userLastName =  Jones ,\n      _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f } --\nUser {_userEmail =  sam@example.com ,\n      _userFirstName =  Sam ,\n      _userLastName =  Taylor ,\n      _userPassword =  332532dcfaa1cbf61e2a266bd723612c } -- \n\n         \n    \n         \n    \n                 \n                       Note  The  --  at the ends of the console output lines are an artifact of the\ndocumentation build process. They won't appear in your console.   Next let's suppose you wanted to sort the users into order by their first name,\nand then descending by their last name. We can use the  orderBy_  function to\norder the query results. This is similar to the  sortBy  function for lists.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   sortUsersByFirstName   =   orderBy_   ( \\ u   -   ( asc_   ( _userFirstName   u ),   desc_   ( _userLastName   u )))   ( all_   ( _shoppingCartUsers   shoppingCartDb ))  withDatabaseDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   $   select   sortUsersByFirstName \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  ORDER   BY   t0 . first_name   ASC , \n          t0 . last_name   DESC   -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  betty@example.com ,\n      _userFirstName =  Betty ,\n      _userLastName =  Jones ,\n      _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f } --\nUser {_userEmail =  james@example.com ,\n      _userFirstName =  James ,\n      _userLastName =  Smith ,\n      _userPassword =  b4cc344d25a2efe540adbf2678e2304c } --\nUser {_userEmail =  sam@example.com ,\n      _userFirstName =  Sam ,\n      _userLastName =  Taylor ,\n      _userPassword =  332532dcfaa1cbf61e2a266bd723612c } -- \n\n         \n    \n         \n    \n                 \n                      We can use  limit_  and  offset_  in a similar manner to  take  and  drop  respectively.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   boundedQuery   ::   Q   SqliteSelectSyntax   _   _   _ \n     boundedQuery   =   limit_   1   $   offset_   1   $ \n                    orderBy_   ( asc_   .   _userFirstName )   $ \n                    all_   ( _shoppingCartUsers   shoppingCartDb )  withDatabaseDebug   putStrLn   conn   $   do \n   users   -   runSelectReturningList   ( select   boundedQuery   ::   SqlSelect   SqliteSelectSyntax   _ ) \n   mapM_   ( liftIO   .   putStrLn   .   show )   users  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  ORDER   BY   t0 . first_name   ASC  LIMIT   1  OFFSET   1   -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  james@example.com ,\n      _userFirstName =  James ,\n      _userLastName =  Smith ,\n      _userPassword =  b4cc344d25a2efe540adbf2678e2304c } -- \n\n         \n    \n         \n    \n                 \n                       Note  The type signatures above are not necessary when run in GHCi. The\ndocumentation automates building and testing the queries, but the above\nresults in strange type errors in GHC. This may be a compiler type-inference\nbug. More investigation is being carried out.  Nevertheless, this shows how you could limit your queries to only work in a\nparticular syntax.  The  _  are type holes, which means GHC will happily infer these types, if\nthe  PartialTypeSignatures  extension is turned on.", 
            "title": "Querying the database"
        }, 
        {
            "location": "/tutorials/tutorial1/#aggregations", 
            "text": "Sometimes we also want to group our data together and perform calculations over\nthe groups of data. SQL calls these aggregations.  The simplest aggregation is counting. We use the  aggregate_  function to create\naggregations. For example, to count all users, we can use the  countAll_ \naggregation. We also use the  runSelectReturningOne  function to get at most one\nrecord from the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   userCount   =   aggregate_   ( \\ u   -   as_   @ Int   countAll_ )   ( all_   ( _shoppingCartUsers   shoppingCartDb ))  withDatabaseDebug   putStrLn   conn   $   do \n   Just   c   -   runSelectReturningOne   $   select   userCount \n   liftIO   $   putStrLn   ( We have    ++   show   c   ++    users in the database )  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   cart_users   AS   t0   -- With values: []  \n\n         \n    \n         \n             We have 3 users in the database -- \n\n         \n    \n         \n    \n                 \n                       Note  countAll_  is happy to unmarshal into any  Integral  type, so we use  as_ \nto constrain the type to  Int .   Maybe we'd like something a little more interesting, such as the number of users\nfor each unique first name. We can also express these aggregations using the aggregate_  function. In order to get interesting results, we'll need to add\nmore users to our database. We'll demonstrate using  withDatabase  to silence the debug messages.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             withDatabaseDebug   putStrLn   conn   $ \n   runInsert   $ \n   insert   ( _shoppingCartUsers   shoppingCartDb )   $ \n   insertValues   [   User   james@pallo.com   James   Pallo   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n                ,   User   betty@sims.com   Betty   Sims   82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n                ,   User   james@oreily.com   James   O Reily   b4cc344d25a2efe540adbf2678e2304c   {- james -} \n                ,   User   sam@sophitz.com   Sam   Sophitz   332532dcfaa1cbf61e2a266bd723612c   {- sam -} \n                ,   User   sam@jely.com   Sam   Jely   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ]  \n\n         \n    \n         \n             INSERT   INTO   cart_users ( email , \n                          first_name , \n                          last_name , \n                          password )  VALUES   ( ? , \n         ? , \n         ? , \n         ? ),   ( ? , \n              ? , \n              ? , \n              ? ),   ( ? , \n                   ? , \n                   ? , \n                   ? ),   ( ? , \n                        ? , \n                        ? , \n                        ? ),   ( ? , \n                             ? , \n                             ? , \n                             ? )   -- With values: [SQLText  james@pallo.com ,SQLText  James ,SQLText  Pallo ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  betty@sims.com ,SQLText  Betty ,SQLText  Sims ,SQLText  82b054bd83ffad9b6cf8bdb98ce3cc2f ,SQLText  james@oreily.com ,SQLText  James ,SQLText  O Reily ,SQLText  b4cc344d25a2efe540adbf2678e2304c ,SQLText  sam@sophitz.com ,SQLText  Sam ,SQLText  Sophitz ,SQLText  332532dcfaa1cbf61e2a266bd723612c ,SQLText  sam@jely.com ,SQLText  Sam ,SQLText  Jely ,SQLText  332532dcfaa1cbf61e2a266bd723612c ]  \n\n         \n    \n         \n    \n                 \n                      Now we can use  aggregate_  to both group by a user's first name, and then count\nthe number of users.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Output \n         \n    \n         \n    \n         \n            \n         \n             let   numberOfUsersByName   =   aggregate_   ( \\ u   -   ( group_   ( _userFirstName   u ),   as_   @ Int   countAll_ ))   $  \n                           all_   ( _shoppingCartUsers   shoppingCartDb )  withDatabaseDebug   putStrLn   conn   $   do \n   countedByName   -   runSelectReturningList   $   select   numberOfUsersByName \n   mapM_   ( liftIO   .   putStrLn   .   show )   countedByName  \n\n         \n    \n         \n             SELECT   t0 . first_name   AS   res0 , \n        COUNT ( * )   AS   res1  FROM   cart_users   AS   t0  GROUP   BY   t0 . first_name   -- With values: []  \n\n         \n    \n         \n             ( Betty ,\n 2) --\n( James ,\n 3) --\n( Sam ,\n 3) --", 
            "title": "Aggregations"
        }, 
        {
            "location": "/tutorials/tutorial1/#conclusion", 
            "text": "In this tutorial, we've covered creating a database schema, opening up a beam\ndatabase, inserting values into the database, and querying values from them. We\nused the knowledge we learned to create a partial shopping cart database that\ncontains information about users. In the next tutorial, we'll delve deeper into\nthe some of the query types and show how we can create relations between tables.\nWe'll also use the monadic query interface to create SQL joins.  Until next time!  If you have any questions about beam, feel free to send them to\ntravis@athougies.net . Pull requests and bug reports are welcome\non  GitHub .      Thanks to various bloggers for pointing this out. You can read more about this technique\n    here .    Adding entities other than tables is covered in more depth in\n   the  user guide .    More on the default naming conventions can be found in\n   the  models section  of the user guide. We'll talk\n   about how to override defaults in the next sections.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/tutorials/tutorial2/", 
            "text": "Introduction\n\n\nIn the last part, we created a simple database with one table. We then used the\nbeam interface to add entities into that table and query them. In this tutorial,\nwe'll see how to update and delete rows and how to establish and query relations\nbetween tables.\n\n\nWe'll then delve deeper into queries to see how to create queries that return\nmultiple tables.\n\n\nAdding a related table\n\n\nThe users in our simple e-commerce application would like to ship orders to\ntheir homes. Let's build an addresses model to allow users to add home addresses\nto their profile. Our table will store United States addresses for now. An\naddress in the United States consists of\n\n\n\n\none required house number and street line\n\n\nan optional apartment/suite number line\n\n\na required city\n\n\na required 2-letter state/territory code\n\n\none 5-digit ZIP code\n\n\n\n\nLet's build the \nAddressT\n table. \nAddressT\n will follow a similar formula to\n\nUserT\n, but it will contain a reference to a \nUserT\n table. ]\n\n\ndata\n \nAddressT\n \nf\n \n=\n \nAddress\n\n                \n{\n \n_addressId\n    \n::\n \nC\n \nf\n \n(\nAuto\n \nInt\n)\n\n                \n,\n \n_addressLine1\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressLine2\n \n::\n \nC\n \nf\n \n(\nMaybe\n \nText\n)\n\n                \n,\n \n_addressCity\n  \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressState\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressZip\n   \n::\n \nC\n \nf\n \nText\n\n\n                \n,\n \n_addressForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n \n}\n\n                  \nderiving\n \nGeneric\n\n\ntype\n \nAddress\n \n=\n \nAddressT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nUserT\n \nIdentity\n)\n\n\nderiving\n \ninstance\n \nShow\n \nAddress\n\n\n\ninstance\n \nTable\n \nAddressT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nAddressT\n \nf\n \n=\n \nAddressId\n \n(\nColumnar\n \nf\n \n(\nAuto\n \nInt\n))\n \nderiving\n \nGeneric\n\n    \nprimaryKey\n \n=\n \nAddressId\n \n.\n \n_addressId\n\n\ntype\n \nAddressId\n \n=\n \nPrimaryKey\n \nAddressT\n \nIdentity\n \n-- For convenience    \n\n\n\ninstance\n \nBeamable\n \nAddressT\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nAddressT\n)\n\n\n\n\n\n\n\n\nTip\n\n\nAbove, we used the \nC\n constructor instead of \nColumnar\n for each column.\n\nC\n is a type synonym for \nColumnar\n, and some find it reduces the syntactic\noverhead of model declaration.\n\n\n\n\nThe lines of particular interest are the declarations for \n_addressId\n and\n\n_addressForUser\n.\n\n\nThe \n_addressId\n field is declared with type \nAuto\n. \nAuto\n is defined in\n\nDatabase.Beam.Backend.Types\n as\n\n\nnewtype\n \nAuto\n \nx\n \n=\n \nAuto\n \n{\n \nunAuto\n \n::\n \nMaybe\n \nx\n \n}\n\n\n\n\n\n\nAuto x\n describes a field that mainly acts the same as \nx\n during marshaling\nand unmarshaling. The only difference is that, if the wrapped value is\n\nNothing\n, then \nAuto x\n will make sure to use whatever syntax is necessary to\nhave the database assign the default value. The unmarshaled \nAuto x\n value is\nalways a wrapper over a \nJust\n. This allows the common use case of defaulted\nauto increment primary key columns.\n\n\n\n\nWarning\n\n\nUnfortunately, the invariant of an unmarshaled \nAuto\n always having a \nJust\n\nvalue is not currently checked at compile time. Future versions of beam will\nlikely be more strict about this.\n\n\n\n\nThe second field of interest is \n_addressForUser\n, which is declared as a\n\nPrimaryKey UserT f\n. This pulls in all the columns necessary for referencing a\n\nUserT\n \n1\n. Later, we'll also see how beam can use the field to automatically\ncreate JOINs.\n\n\nWe have all the tables we need now, so let's go ahead and redefine our newest database type.\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n \n}\n\n                        \nderiving\n \nGeneric\n\n\n\ninstance\n \nDatabase\n \nShoppingCartDb\n\n\n\n\n\n\nModifying the default naming choices\n\n\nIn the last part of the tutorial, we let beam decide our field names for us.\nThis is great for simple cases. However, sometimes you want more control over\nthe naming options.\n\n\n\n\nNote\n\n\nPrevious versions of this tutorial had instructions on changing the schema\ntype of particular tables. This functionality has been moved from\n\nbeam-core\n into the \nbeam-migrate\n package. See\nthe \nmigrations guide\n for more information.\n\n\n\n\nThe \ndefaultDbSettings\n function generates names using the Haskell record\nselector names \n2\n. This function returns the \nDatabaseType\n parameterized over\n\nDatabaseEntity\n, which is a type that contains metadata about entity names. We\ncan \nmodify\n this description after it is created by using the\n\nwithDbModification\n function. You can think of \nwithDbModification\n as applying\na transformation function to each name in our database.\n\n\nMost of the time \nwithDbModification\n needs a full description of the database\nnames. However, most of the time we only want to rename certain columns or\ntables. We can use the \ndbModification\n value to construct a modification that\ndoesn't change any names. We can then use the Haskell record update syntax to\nupdate field and column names. This is best illustrated by an example.\n\n\nRecall our Haskell data types above.\n\n\ndata\n \nUserT\n \nf\n\n    \n=\n \nUser\n\n    \n{\n \n_userEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \n_userPassword\n  \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n    \nderiving\n \nGeneric\n\n\n\ndata\n \nAddressT\n \nf\n \n=\n \nAddress\n\n                \n{\n \n_addressId\n    \n::\n \nC\n \nf\n \n(\nAuto\n \nInt\n)\n\n                \n,\n \n_addressLine1\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressLine2\n \n::\n \nC\n \nf\n \n(\nMaybe\n \nText\n)\n\n                \n,\n \n_addressCity\n  \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressState\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_addressZip\n   \n::\n \nC\n \nf\n \nText\n\n\n                \n,\n \n_addressForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n \n}\n\n                  \nderiving\n \nGeneric\n\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n \n}\n\n                        \nderiving\n \nGeneric\n\n\n\n\n\n\nNow, let's say we want beam to use the name \naddresses\n to access the\n\n_shoppingCartUserAddresses\n table, and the names \naddress1\n and \naddress2\n to\naccess \n_addressLine1\n and \n_addressLine2\n respectively.\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                 \ndbModification\n \n{\n\n                   \n_shoppingCartUserAddresses\n \n=\n\n                     \nmodifyTable\n \n(\n\\\n_\n \n-\n \naddresses\n)\n \n$\n\n                     \ntableModification\n \n{\n\n                       \n_addressLine1\n \n=\n \nfieldNamed\n \naddress1\n,\n\n                       \n_addressLine2\n \n=\n \nfieldNamed\n \naddress2\n\n                     \n}\n\n                 \n}\n\n\n\n\n\n\nAbove, we use \ndbModification\n to produce a default modification, then we\noverride the \n_shoppingCartUserAddresses\n modification to change the addresses\ntable. The \nmodifyTable\n function takes a function to transform the default\ntable name and a table modification. Like the \ndbModification\n value,\n\ntableModification\n produces a modification for each table field that does\nnothing.\n\n\nWe only override the \n_addressLine1\n and \n_addressLine2\n modifications with\n\nfieldNamed \"address1\"\n and \nfieldNamed \"address2\"\n. Because \ntableModification\n\nproduces a default modification, the other columns are kept at their default\nvalue.\n\n\nIf you didn't need to modify any of the table names, simply do not update any of\nthe table fields. For example, to simply produce a database with the first table\nnamed \nusers\n and the second named \nuser_addresses\n, you can do\n\n\nshoppingCartDb1\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb1\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                  \ndbModification\n \n{\n\n                    \n_shoppingCartUsers\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \nusers\n)\n \ntableModification\n,\n\n                    \n_shoppingCartUserAddresses\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \nuser_addresses\n)\n \ntableModification\n\n                  \n}\n\n\n\n\n\n\nFor the purposes of this tutorial, we'll stick with \nshoppingCartDb\n.\n\n\nEasier queries with lenses\n\n\nIn the previous part, we accessed table columns by using regular Haskell record\nsyntax. Sometimes, we would like to use the more convenient lens syntax to\naccess columns. Of course, all of beam's definitions are compatible with the\n\nlens\n library -- that is to say, \nmakeLenses\n will work just fine. However,\nbeam's motivation is, in part, the avoidance of Template Haskell, and it would\nhardly be worth it if you had to include a Template Haskell splice just to have\nlenses for the models you declared TH free.\n\n\nIn reality, the \nlens\n library isn't required to construct valid lenses. Lenses\nare a plain old Haskell type.\n\n\nWe can use beam's \nColumnar\n mechanism to automatically derive lenses. The\n\ntableLenses\n function produces a table value where each column is given a type\n\nLensFor\n, which is a \nnewtype\n wrapper over a correctly constructed,\npolymorphic Van Laarhoven lens.\n\n\nWe can bring these lenses into scope globally via a global pattern match against\n\ntableLenses\n. For example, to get lenses for each column of the \nAddressT\n and\n\nUserT\n table.\n\n\nAddress\n \n(\nLensFor\n \naddressId\n)\n    \n(\nLensFor\n \naddressLine1\n)\n\n        \n(\nLensFor\n \naddressLine2\n)\n \n(\nLensFor\n \naddressCity\n)\n\n        \n(\nLensFor\n \naddressState\n)\n \n(\nLensFor\n \naddressZip\n)\n\n        \n(\nUserId\n \n(\nLensFor\n \naddressForUserId\n))\n \n=\n \n        \ntableLenses\n\n\n\nUser\n \n(\nLensFor\n \nuserEmail\n)\n    \n(\nLensFor\n \nuserFirstName\n)\n\n     \n(\nLensFor\n \nuserLastName\n)\n \n(\nLensFor\n \nuserPassword\n)\n \n=\n\n     \ntableLenses\n\n\n\n\n\n\nAs in tables, we can generate lenses for databases via the \ndbLenses\n function.\n\n\nShoppingCartDb\n \n(\nTableLens\n \nshoppingCartUsers\n)\n\n               \n(\nTableLens\n \nshoppingCartUserAddresses\n)\n \n=\n\n               \ndbLenses\n\n\n\n\n\n\nWe can ask GHCi for the type of a column lens.\n\n\nAnd a table lens.\n\n\n\n\nWarning\n\n\nThese lens generating functions are \nawesome\n but if you use them in a\ncompiled Haskell module (rather than GHC), GHC may give you odd compile\nerrors about ambiguous types. These occur due to what's known as the\nmonomorphism restriction. You can turn it off using the\n\nNoMonomorphismRestriction\n extension.\n\n\nThe monomorphism restriction is part of the Haskell standard, but there has\nbeen talk about removing it in future language versions. Basically, it\nrequires GHC to not automatically infer polymorphic types for global\ndefinitions. In this case though, polymorphic global definitions is exactly\nwhat we want.\n\n\n\n\nWorking with relations\n\n\nNow, let's see how we can add related addresses to our database. We begin by\nopening up a connection for us to use in the rest of the tutorial.\n\n\nFirst, let's open a new database and create the schema.\n\n\n$\n sqlite3 shoppingcart2.db\n\nSQLite version 3.14.0 2016-07-26 15:17:14\n\n\nEnter \n.help\n for usage hints.\n\n\nsqlite\n CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nsqlite\n CREATE TABLE addresses ( id INT AUTO_INCREMENT PRIMARY KEY, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );\n\n\n\n\n\n\nNow, in GHCi, we can use \nsqlite-simple\n to get a handle to this database.\n\n\nconn\n \n-\n \nopen\n \nshoppingcart2.db\n\n\n\n\n\n\nBefore we add addresses, we need to add some users that we can reference.\n\n\nlet\n \njames\n \n=\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n \nb4cc344d25a2efe540adbf2678e2304c\n\n    \nbetty\n \n=\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n\n    \nsam\n \n=\n \nUser\n \nsam@example.com\n \nSam\n \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUsers\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertValues\n \n[\n \njames\n,\n \nbetty\n,\n \nsam\n \n]\n\n\n\n\n\n\nNow that we have some \nUser\n objects, we can create associated addresses. Let's give James one\naddress, Betty two addresses, and Sam none.\n\n\nlet\n \naddresses\n \n=\n \n[\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n123 Little Street\n \nNothing\n \nBoston\n \nMA\n \n12345\n \n(\npk\n \njames\n)\n\n                \n,\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n222 Main Street\n \n(\nJust\n \nSte 1\n)\n \nHouston\n \nTX\n \n8888\n \n(\npk\n \nbetty\n)\n\n                \n,\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n9999 Residence Ave\n \nNothing\n \nSugarland\n \nTX\n \n8989\n \n(\npk\n \nbetty\n)\n \n]\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \nrunInsert\n \n$\n\n  \ninsert\n \n(\n_shoppingCartUserAddresses\n \nshoppingCartDb\n)\n \n$\n\n  \ninsertValues\n \naddresses\n\n\n\n\n\n\nNotice that we used the \npk\n function to assign the reference to the \nUserT\n table. \npk\n is a\nsynonym of the \nprimaryKey\n function from the \nTable\n type class. It should be clear what's going\non, but if it's not, let's ask GHCi.\n\n\n*NextSteps\n pk (james :: User)\n\n\nUserId \njames@example.com\n\n\n\n\n\n\nNotice also that we set \n_addressId\n to \nAuto Nothing\n. As mentioned above, the\n\nAutoId\n type means the addresses won't have an id until they're inserted into\nthe database. This could be an issue if we want to refer to the addresses in the\nfuture.\n\n\nIf we query for all the addresses, we'll see that SQLite has assigned them an\nappropriate id.\n\n\nFirst, let's use the new lenses we made. Make sure to import \nLens.Micro\n or\n\nControl.Lens\n or whichever (van Laarhoven) lens module you prefer.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- import Lens.Micro\n\n\n-- import Control.Lens\n\n\naddresses\n \n-\n \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \n             \nrunSelectReturningList\n \n$\n\n             \nselect\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n))\n\n\nmapM_\n \nprint\n \naddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                              _addressLine2 = Nothing,\n\n\n                                                              _addressCity = \nBoston\n,\n\n\n                                                              _addressState = \nMA\n,\n\n\n                                                              _addressZip = \n12345\n,\n\n\n                                                              _addressForUser = UserId \njames@example.com\n} --\n\n\nAddress {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                              _addressLine2 = Just \nSte 1\n,\n\n\n                                              _addressCity = \nHouston\n,\n\n\n                                              _addressState = \nTX\n,\n\n\n                                              _addressZip = \n8888\n,\n\n\n                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\nAddress {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                              _addressLine2 = Nothing,\n\n\n                                                              _addressCity = \nSugarland\n,\n\n\n                                                              _addressState = \nTX\n,\n\n\n                                                              _addressZip = \n8989\n,\n\n\n                                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nA note about queries\n\n\nIn the last tutorial, we saw how queries and list supported similar interfaces.\nNamely we saw how \nlimit_\n is like \ntake\n, \noffset_\n like \ndrop\n, \norderBy\n like\nan enhanced \nsortBy\n, and \naggregate\n like an enhanced \ngroupBy\n. These\ncorresponded to the \nLIMIT\n, \nOFFSET\n, \nORDER BY\n, and \nGROUP BY\n SQL\nconstructs. The missing SQL operation in this list is the \nJOIN\n, which computes\nthe cartesian product of two tables. In other words, a join between table \nA\n\nand table \nB\n results in a query of pairs \n(x, y)\n for every \nx\n in \nA\n and\nevery \ny\n in \nB\n. SQL joins can result in two-way, three-way, four-way, etc.\ncartesian products.\n\n\nThose familiar with lists in Haskell will note that there is an easy abstraction\nfor taking \nn\n-ary cartesian products over lists: monads.\n\n\nThe list monad\n\n\nWe can use GHCi to see what we mean.\n\n\n*\nNextSteps\n \ndo\n \n{\n \nx\n \n-\n \n[\n1\n,\n2\n,\n3\n];\n \ny\n \n-\n \n[\n4\n,\n5\n,\n6\n];\n \nreturn\n \n(\nx\n,\n \ny\n);\n \n}\n\n\n[(\n1\n,\n4\n),(\n1\n,\n5\n),(\n1\n,\n6\n),(\n2\n,\n4\n),(\n2\n,\n5\n),(\n2\n,\n6\n),(\n3\n,\n4\n),(\n3\n,\n5\n),(\n3\n,\n6\n)]\n\n\n\n\n\n\nWe get the two-way cartesian product of \n[1,2,3]\n and \n[4,5,6]\n. We can make the\nproduct arbitrarily long.\n\n\n*\nNextSteps\n \ndo\n \n{\n \nw\n \n-\n \n[\n10\n,\n \n20\n,\n \n30\n];\n \nx\n \n-\n \n[\n1\n,\n2\n,\n3\n];\n \ny\n \n-\n \n[\n4\n,\n5\n,\n6\n];\n \nz\n \n-\n \n[\n100\n,\n \n200\n,\n \n1\n];\n \nreturn\n \n(\nx\n,\n \ny\n,\n \nz\n,\n \nw\n);\n \n}\n\n\n[(\n1\n,\n4\n,\n100\n,\n10\n),(\n1\n,\n4\n,\n200\n,\n10\n),(\n1\n,\n4\n,\n1\n,\n10\n),(\n1\n,\n5\n,\n100\n,\n10\n),(\n1\n,\n5\n,\n200\n,\n10\n),(\n1\n,\n5\n,\n1\n,\n10\n),\n \n...\n \n]\n\n\n\n\n\n\nWe can also use \nguard\n from \nControl.Monad\n to limit the combinations that the\nlist monad puts together. For example, if we had the lists\n\n\nlet\n \nusersList\n \n=\n \n[(\n1\n,\n \njames\n),\n \n(\n2\n,\n \nbetty\n),\n \n(\n3\n,\n \ntom\n)]\n\n    \naddressesList\n \n=\n \n[(\n1\n,\n \naddress1\n),\n \n(\n1\n,\n \naddress2\n),\n \n(\n3\n,\n \naddress3\n)]\n\n\n\n\n\n\nWe can use \nguard\n to return all pairs of elements from \nusersList\n and\n\naddressesList\n that matched on their first element. For example,\n\n\n*\nNextSteps\n \ndo\n \n{\n \nuser\n \n-\n \nusersList\n;\n \naddress\n \n-\n \naddressesList\n;\n \nguard\n \n(\nfst\n \nuser\n \n==\n \nfst\n \naddress\n);\n \nreturn\n \n(\nuser\n,\n \naddress\n)\n \n}\n\n\n[((\n1\n,\njames\n),(\n1\n,\naddress1\n)),((\n1\n,\njames\n),(\n1\n,\naddress2\n)),((\n3\n,\ntom\n),(\n3\n,\naddress3\n))]\n\n\n\n\n\n\nThe query monad\n\n\nAs I claimed in the first tutorial, queries support many of the same interfaces and operations lists\ndo. It follows that queries also expose a monadic interface.\n\n\nFor example, to retrieve every pair of user and address, we can write the following query:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallPairs\n \n-\n \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n            \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \ndo\n\n              \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n              \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n              \nreturn\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nallPairs\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nsam@example.com\n,\n\n\n       _userFirstName = \nSam\n,\n\n\n       _userLastName = \nTaylor\n,\n\n\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \nsam@example.com\n,\n\n\n       _userFirstName = \nSam\n,\n\n\n       _userLastName = \nTaylor\n,\n\n\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nsam@example.com\n,\n\n\n       _userFirstName = \nSam\n,\n\n\n       _userLastName = \nTaylor\n,\n\n\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nJust like with lists we can also use a construct similar to guard to ensure that\nwe only retrieve users and addresses that are related. The \nguard_\n function\ntakes in expression of type \nQExpr s Bool\n which represents a SQL expression\nthat returns a boolean. \nQExpr s Bool\ns support all the common operators we have\non regular \nBool\n, except they're suffixed with a \n.\n. For example, where you'd\nuse \n(\n)\n on two Haskell-level \nBool\ns, we'd use \n(\n.)\n on \nQExpr\n-level\nbools.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddresses\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nguard_\n \n(\naddress\n \n^.\n \naddressForUserId\n \n==.\n \nuser\n \n^.\n \nuserEmail\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOf course this is kind of messy because it involves manually matching the\nprimary key of \nUser\n with the reference in \nAddress\n. Alternatively, we can use\nthe \nreferences_\n predicate to have beam automatically generate a \nQExpr\n\nexpression that can match primary keys together.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddressesUsingReferences\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n\n       \nguard_\n \n(\n_addressForUser\n \naddress\n \n`\nreferences_\n`\n \nuser\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddressesUsingReferences\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt1\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt1\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt1\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt1\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \naddresses\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou may have noticed that the joins up until now did not include a SQL \nON\n\nclause. Instead we joined the tables together, and then used the \nWHERE\n clause\nto filter out results we don't want. If you'd like to use the \nON\n clause to\nmake the SQL clearer or save a line in your code, beam offers the \nrelated_\n\ncombinator to pull related tables directly into the query monad.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndRelatedAddressesUsingRelated\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nuser\n \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\n_addressForUser\n \naddress\n)\n\n       \npure\n \n(\nuser\n,\n \naddress\n)\n\n\n\nmapM_\n \nprint\n \nusersAndRelatedAddressesUsingRelated\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt1\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt1\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt1\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt0\n.\nid\n \nAS\n \nres4\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres5\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres6\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres7\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres8\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres9\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres10\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \ncart_users\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nfor_user__email\n)\n=\n(\nt1\n.\nemail\n)\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n,\n\n\n       _userFirstName = \nJames\n,\n\n\n       _userLastName = \nSmith\n,\n\n\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nBoston\n,\n\n\n                                                                                                                         _addressState = \nMA\n,\n\n\n                                                                                                                         _addressZip = \n12345\n,\n\n\n                                                                                                                         _addressForUser = UserId \njames@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                                                                                         _addressLine2 = Just \nSte 1\n,\n\n\n                                                                                                         _addressCity = \nHouston\n,\n\n\n                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                         _addressZip = \n8888\n,\n\n\n                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n(User {_userEmail = \nbetty@example.com\n,\n\n\n       _userFirstName = \nBetty\n,\n\n\n       _userLastName = \nJones\n,\n\n\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                                                                                         _addressLine2 = Nothing,\n\n\n                                                                                                                         _addressCity = \nSugarland\n,\n\n\n                                                                                                                         _addressState = \nTX\n,\n\n\n                                                                                                                         _addressZip = \n8989\n,\n\n\n                                                                                                                         _addressForUser = UserId \nbetty@example.com\n}) --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also query the addresses for a particular user given a \nUserId\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- This is a contrived example to show how we can use an arbitrary UserId to fetch a particular user.\n\n\n-- We don\nt always have access to the full \nUser\n lying around. For example we may be in a function that\n\n\n-- only accepts \nUserId\ns.\n\n\n\nlet\n \nbettyId\n \n=\n \nUserId\n \nbetty@example.com\n \n::\n \nUserId\n\n\n\nbettysAddresses\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n \nselect\n \n$\n\n    \ndo\n \naddress\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n       \nguard_\n \n(\n_addressForUser\n \naddress\n \n==.\n \nval_\n \nbettyId\n)\n\n       \npure\n \naddress\n\n\n\nmapM_\n \nprint\n \nbettysAddresses\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n       \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n       \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n       \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n       \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n\nFROM\n \naddresses\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nfor_user__email\n)\n=\n(\n?\n)\n \n-- With values: [SQLText \nbetty@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                              _addressLine2 = Just \nSte 1\n,\n\n\n                                              _addressCity = \nHouston\n,\n\n\n                                              _addressState = \nTX\n,\n\n\n                                              _addressZip = \n8888\n,\n\n\n                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\nAddress {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                              _addressLine2 = Nothing,\n\n\n                                                              _addressCity = \nSugarland\n,\n\n\n                                                              _addressState = \nTX\n,\n\n\n                                                              _addressZip = \n8989\n,\n\n\n                                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nMore complicated joins are also supported. See the section\non \nrelationships\n\n\n\n\nUpdates and deletions\n\n\nSo far we've only seen how to insert data and query it. There are two other SQL\noperations that we have not covered: updates and deletions. Beam has full\nsupport for these manipulations as well.\n\n\nUpdates\n\n\nLike \nINSERT\n and \nSELECT\n, to run an \nUPDATE\n command, we use the \nrunUpdate\n\nfunction, with a value of \nSqlUpdate\n.\n\n\nThe \nsave\n function constructs a value of \nSqlUpdate\n given a full record. It\nwill generate an \nUPDATE\n that will set every field (except for the primary key\nfields) for the row that completely matches the primary key.\n\n\nLet's first look at updating passwords given a \nUser\n. For this we can use the\n\nsaveTo\n function. Suppose James wants to change his password to the md5 hash of\n\"supersecure\", which is \n52a516ca6df436828d9c0d26e31ef704\n. We have a \nUser\n\nobject representing James so we can simply call \nsaveTo\n on the update value to\nupdate the corresponding record in the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n[\njames\n]\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \ndo\n \nrunUpdate\n \n$\n\n         \nsave\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\njames\n \n{\n \n_userPassword\n \n=\n \n52a516ca6df436828d9c0d26e31ef704\n \n})\n\n\n       \nrunSelectReturningList\n \n$\n\n         \nlookup\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n(\nUserId\n \njames@example.com\n)\n\n\n\nputStrLn\n \n(\nJames\ns new password is \n \n++\n \nshow\n \n(\njames\n \n^.\n \nuserPassword\n))\n\n\n\n\n        \n\n    \n        \n\n            \nUPDATE\n \ncart_users\n\n\nSET\n \nfirst_name\n=?\n,\n\n    \nlast_name\n=?\n,\n\n    \npassword\n=?\n\n\nWHERE\n \n(\nemail\n)\n=\n(\n?\n)\n \n-- With values: [SQLText \nJames\n,SQLText \nSmith\n,SQLText \n52a516ca6df436828d9c0d26e31ef704\n,SQLText \njames@example.com\n]\n\n\n  \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n         \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n         \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n         \nt0\n.\npassword\n \nAS\n \nres3\n\n  \nFROM\n \ncart_users\n \nAS\n \nt0\n \nWHERE\n \n(\nt0\n.\nemail\n)\n=\n(\n?\n)\n \n-- With values: [SQLText \njames@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n            \nJames\ns new password is \n52a516ca6df436828d9c0d26e31ef704\n --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\nlookup\n (defined in \nDatabase.Beam.Query\n) can be used to easily lookup a\nsingle entity given a table entity in a database and a primary key.\n\n\nYou may have to hide \nlookup\n from \nPrelude\n in order to use \nlookup\n\nunqualified.\n\n\n\n\nThis works great, but \nsave\n requires that we have the whole \nUser\n object at\nour disposal. Additionally, you'll notice that it causes every field to be set\nin the \nUPDATE\n query. Typically, this doesn't matter, but sometimes we'd like\nto update fewer fields, multiple rows, or use criteria other than a primary key\nmatch. The \nupdate\n function offers finer-grained control over the command\nsubmitted to the database.\n\n\nTo illustrate use of this function, let's suppose the city of \"Sugarland, TX\"\nwas renamed \"Sugarville, TX\" and had its ZIP code changed to be \"12345\"\ncitywide. The following beam command will update all addresses in the old city\nto use the new name and ZIP code.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naddresses\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \ndo\n \nrunUpdate\n \n$\n\n         \nupdate\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n                \n(\n\\\naddress\n \n-\n \n[\n \naddress\n \n^.\n \naddressCity\n \n-.\n \nval_\n \nSugarville\n\n                             \n,\n \naddress\n \n^.\n \naddressZip\n \n-.\n \nval_\n \n12345\n \n])\n\n                \n(\n\\\naddress\n \n-\n \naddress\n \n^.\n \naddressCity\n \n==.\n \nval_\n \nSugarland\n \n.\n\n                             \naddress\n \n^.\n \naddressState\n \n==.\n \nval_\n \nTX\n)\n\n\n       \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n\n\nmapM_\n \nprint\n \naddresses\n\n\n\n\n        \n\n    \n        \n\n            \nUPDATE\n \naddresses\n\n\nSET\n \ncity\n=?\n,\n\n    \nzip\n=?\n\n\nWHERE\n \n((\ncity\n)\n=\n(\n?\n))\n\n  \nAND\n \n((\nstate\n)\n=\n(\n?\n))\n-- With values: [SQLText \nSugarville\n,SQLText \n12345\n,SQLText \nSugarland\n,SQLText \nTX\n]\n\n\n  \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n         \nt0\n.\naddress1\n \nAS\n \nres1\n,\n\n         \nt0\n.\naddress2\n \nAS\n \nres2\n,\n\n         \nt0\n.\ncity\n \nAS\n \nres3\n,\n\n         \nt0\n.\nstate\n \nAS\n \nres4\n,\n\n         \nt0\n.\nzip\n \nAS\n \nres5\n,\n\n         \nt0\n.\nfor_user__email\n \nAS\n \nres6\n\n  \nFROM\n \naddresses\n \nAS\n \nt0\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nAddress {_addressId = Auto {unAuto = Just 1}, _addressLine1 = \n123 Little Street\n,\n\n\n                                              _addressLine2 = Nothing,\n\n\n                                                              _addressCity = \nBoston\n,\n\n\n                                                              _addressState = \nMA\n,\n\n\n                                                              _addressZip = \n12345\n,\n\n\n                                                              _addressForUser = UserId \njames@example.com\n} --\n\n\nAddress {_addressId = Auto {unAuto = Just 2}, _addressLine1 = \n222 Main Street\n,\n\n\n                                              _addressLine2 = Just \nSte 1\n,\n\n\n                                              _addressCity = \nHouston\n,\n\n\n                                              _addressState = \nTX\n,\n\n\n                                              _addressZip = \n8888\n,\n\n\n                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\nAddress {_addressId = Auto {unAuto = Just 3}, _addressLine1 = \n9999 Residence Ave\n,\n\n\n                                              _addressLine2 = Nothing,\n\n\n                                                              _addressCity = \nSugarville\n,\n\n\n                                                              _addressState = \nTX\n,\n\n\n                                                              _addressZip = \n12345\n,\n\n\n                                                              _addressForUser = UserId \nbetty@example.com\n} --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDeletions\n\n\nNow suppose that Betty has decided to give up her place in Houston. We can use\n\nrunDelete\n to run a \nDELETE\n command.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n  \nrunDelete\n \n$\n\n  \ndelete\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n\n         \n(\n\\\naddress\n \n-\n \naddress\n \n^.\n \naddressCity\n \n==.\n \nHouston\n \n.\n\n                      \n_addressForUser\n \naddress\n \n`\nreferences_\n`\n \nbetty\n)\n\n\n\n\n        \n\n    \n        \n\n            \nDELETE\n\n\nFROM\n \naddresses\n\n\nWHERE\n \n((\ncity\n)\n=\n(\n?\n))\n\n  \nAND\n \n((\nfor_user__email\n)\n=\n(\n?\n))\n \n-- With values: [SQLText \nHouston\n,SQLText \nbetty@example.com\n]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nIn this tutorial we created our first beam relationship. We saw how to use the\nmodifications system to override the default names given to database entities.\nWe saw how to use \ntableLenses\n to generate lenses that can be used with any\nlens library. We used the monadic query interface to write queries that used SQL\njoins, and we saw how beam makes it easy to automatically pull related tables\ninto our queries. Finally we introduced the \nrunUpdate\n and \nrunDelete\n\nfunctions and demonstrated several ways to construct UPDATEs and DELETEs.\n\n\nAt this point, we've covered enough of the beam interface to start writing\ninteresting programs. Take some time to explore beam and create your own\ndatabases. Afterwards, read on for the last part of the tutorial.\n\n\n\n\n\n\n\n\n\n\nActually, any \nBeamable\n type can be wholly embedded in another. See the\n   section on models in the \nuser guide\n for more\n   information.\n\n\n\n\n\n\nThe \nmodels guide\n explains the exact mechanisms\n   used", 
            "title": "Part 2"
        }, 
        {
            "location": "/tutorials/tutorial2/#introduction", 
            "text": "In the last part, we created a simple database with one table. We then used the\nbeam interface to add entities into that table and query them. In this tutorial,\nwe'll see how to update and delete rows and how to establish and query relations\nbetween tables.  We'll then delve deeper into queries to see how to create queries that return\nmultiple tables.", 
            "title": "Introduction"
        }, 
        {
            "location": "/tutorials/tutorial2/#adding-a-related-table", 
            "text": "The users in our simple e-commerce application would like to ship orders to\ntheir homes. Let's build an addresses model to allow users to add home addresses\nto their profile. Our table will store United States addresses for now. An\naddress in the United States consists of   one required house number and street line  an optional apartment/suite number line  a required city  a required 2-letter state/territory code  one 5-digit ZIP code   Let's build the  AddressT  table.  AddressT  will follow a similar formula to UserT , but it will contain a reference to a  UserT  table. ]  data   AddressT   f   =   Address \n                 {   _addressId      ::   C   f   ( Auto   Int ) \n                 ,   _addressLine1   ::   C   f   Text \n                 ,   _addressLine2   ::   C   f   ( Maybe   Text ) \n                 ,   _addressCity    ::   C   f   Text \n                 ,   _addressState   ::   C   f   Text \n                 ,   _addressZip     ::   C   f   Text \n\n                 ,   _addressForUser   ::   PrimaryKey   UserT   f   } \n                   deriving   Generic  type   Address   =   AddressT   Identity  deriving   instance   Show   ( PrimaryKey   UserT   Identity )  deriving   instance   Show   Address  instance   Table   AddressT   where \n     data   PrimaryKey   AddressT   f   =   AddressId   ( Columnar   f   ( Auto   Int ))   deriving   Generic \n     primaryKey   =   AddressId   .   _addressId  type   AddressId   =   PrimaryKey   AddressT   Identity   -- For convenience      instance   Beamable   AddressT  instance   Beamable   ( PrimaryKey   AddressT )    Tip  Above, we used the  C  constructor instead of  Columnar  for each column. C  is a type synonym for  Columnar , and some find it reduces the syntactic\noverhead of model declaration.   The lines of particular interest are the declarations for  _addressId  and _addressForUser .  The  _addressId  field is declared with type  Auto .  Auto  is defined in Database.Beam.Backend.Types  as  newtype   Auto   x   =   Auto   {   unAuto   ::   Maybe   x   }   Auto x  describes a field that mainly acts the same as  x  during marshaling\nand unmarshaling. The only difference is that, if the wrapped value is Nothing , then  Auto x  will make sure to use whatever syntax is necessary to\nhave the database assign the default value. The unmarshaled  Auto x  value is\nalways a wrapper over a  Just . This allows the common use case of defaulted\nauto increment primary key columns.   Warning  Unfortunately, the invariant of an unmarshaled  Auto  always having a  Just \nvalue is not currently checked at compile time. Future versions of beam will\nlikely be more strict about this.   The second field of interest is  _addressForUser , which is declared as a PrimaryKey UserT f . This pulls in all the columns necessary for referencing a UserT   1 . Later, we'll also see how beam can use the field to automatically\ncreate JOINs.  We have all the tables we need now, so let's go ahead and redefine our newest database type.  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT )   } \n                         deriving   Generic  instance   Database   ShoppingCartDb", 
            "title": "Adding a related table"
        }, 
        {
            "location": "/tutorials/tutorial2/#modifying-the-default-naming-choices", 
            "text": "In the last part of the tutorial, we let beam decide our field names for us.\nThis is great for simple cases. However, sometimes you want more control over\nthe naming options.   Note  Previous versions of this tutorial had instructions on changing the schema\ntype of particular tables. This functionality has been moved from beam-core  into the  beam-migrate  package. See\nthe  migrations guide  for more information.   The  defaultDbSettings  function generates names using the Haskell record\nselector names  2 . This function returns the  DatabaseType  parameterized over DatabaseEntity , which is a type that contains metadata about entity names. We\ncan  modify  this description after it is created by using the withDbModification  function. You can think of  withDbModification  as applying\na transformation function to each name in our database.  Most of the time  withDbModification  needs a full description of the database\nnames. However, most of the time we only want to rename certain columns or\ntables. We can use the  dbModification  value to construct a modification that\ndoesn't change any names. We can then use the Haskell record update syntax to\nupdate field and column names. This is best illustrated by an example.  Recall our Haskell data types above.  data   UserT   f \n     =   User \n     {   _userEmail       ::   Columnar   f   Text \n     ,   _userFirstName   ::   Columnar   f   Text \n     ,   _userLastName    ::   Columnar   f   Text \n     ,   _userPassword    ::   Columnar   f   Text   } \n     deriving   Generic  data   AddressT   f   =   Address \n                 {   _addressId      ::   C   f   ( Auto   Int ) \n                 ,   _addressLine1   ::   C   f   Text \n                 ,   _addressLine2   ::   C   f   ( Maybe   Text ) \n                 ,   _addressCity    ::   C   f   Text \n                 ,   _addressState   ::   C   f   Text \n                 ,   _addressZip     ::   C   f   Text \n\n                 ,   _addressForUser   ::   PrimaryKey   UserT   f   } \n                   deriving   Generic  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT )   } \n                         deriving   Generic   Now, let's say we want beam to use the name  addresses  to access the _shoppingCartUserAddresses  table, and the names  address1  and  address2  to\naccess  _addressLine1  and  _addressLine2  respectively.  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings   ` withDbModification ` \n                  dbModification   { \n                    _shoppingCartUserAddresses   = \n                      modifyTable   ( \\ _   -   addresses )   $ \n                      tableModification   { \n                        _addressLine1   =   fieldNamed   address1 , \n                        _addressLine2   =   fieldNamed   address2 \n                      } \n                  }   Above, we use  dbModification  to produce a default modification, then we\noverride the  _shoppingCartUserAddresses  modification to change the addresses\ntable. The  modifyTable  function takes a function to transform the default\ntable name and a table modification. Like the  dbModification  value, tableModification  produces a modification for each table field that does\nnothing.  We only override the  _addressLine1  and  _addressLine2  modifications with fieldNamed \"address1\"  and  fieldNamed \"address2\" . Because  tableModification \nproduces a default modification, the other columns are kept at their default\nvalue.  If you didn't need to modify any of the table names, simply do not update any of\nthe table fields. For example, to simply produce a database with the first table\nnamed  users  and the second named  user_addresses , you can do  shoppingCartDb1   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb1   =   defaultDbSettings   ` withDbModification ` \n                   dbModification   { \n                     _shoppingCartUsers   =   modifyTable   ( \\ _   -   users )   tableModification , \n                     _shoppingCartUserAddresses   =   modifyTable   ( \\ _   -   user_addresses )   tableModification \n                   }   For the purposes of this tutorial, we'll stick with  shoppingCartDb .", 
            "title": "Modifying the default naming choices"
        }, 
        {
            "location": "/tutorials/tutorial2/#easier-queries-with-lenses", 
            "text": "In the previous part, we accessed table columns by using regular Haskell record\nsyntax. Sometimes, we would like to use the more convenient lens syntax to\naccess columns. Of course, all of beam's definitions are compatible with the lens  library -- that is to say,  makeLenses  will work just fine. However,\nbeam's motivation is, in part, the avoidance of Template Haskell, and it would\nhardly be worth it if you had to include a Template Haskell splice just to have\nlenses for the models you declared TH free.  In reality, the  lens  library isn't required to construct valid lenses. Lenses\nare a plain old Haskell type.  We can use beam's  Columnar  mechanism to automatically derive lenses. The tableLenses  function produces a table value where each column is given a type LensFor , which is a  newtype  wrapper over a correctly constructed,\npolymorphic Van Laarhoven lens.  We can bring these lenses into scope globally via a global pattern match against tableLenses . For example, to get lenses for each column of the  AddressT  and UserT  table.  Address   ( LensFor   addressId )      ( LensFor   addressLine1 ) \n         ( LensFor   addressLine2 )   ( LensFor   addressCity ) \n         ( LensFor   addressState )   ( LensFor   addressZip ) \n         ( UserId   ( LensFor   addressForUserId ))   =  \n         tableLenses  User   ( LensFor   userEmail )      ( LensFor   userFirstName ) \n      ( LensFor   userLastName )   ( LensFor   userPassword )   = \n      tableLenses   As in tables, we can generate lenses for databases via the  dbLenses  function.  ShoppingCartDb   ( TableLens   shoppingCartUsers ) \n                ( TableLens   shoppingCartUserAddresses )   = \n                dbLenses   We can ask GHCi for the type of a column lens.  And a table lens.   Warning  These lens generating functions are  awesome  but if you use them in a\ncompiled Haskell module (rather than GHC), GHC may give you odd compile\nerrors about ambiguous types. These occur due to what's known as the\nmonomorphism restriction. You can turn it off using the NoMonomorphismRestriction  extension.  The monomorphism restriction is part of the Haskell standard, but there has\nbeen talk about removing it in future language versions. Basically, it\nrequires GHC to not automatically infer polymorphic types for global\ndefinitions. In this case though, polymorphic global definitions is exactly\nwhat we want.", 
            "title": "Easier queries with lenses"
        }, 
        {
            "location": "/tutorials/tutorial2/#working-with-relations", 
            "text": "Now, let's see how we can add related addresses to our database. We begin by\nopening up a connection for us to use in the rest of the tutorial.  First, let's open a new database and create the schema.  $  sqlite3 shoppingcart2.db SQLite version 3.14.0 2016-07-26 15:17:14  Enter  .help  for usage hints.  sqlite  CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  sqlite  CREATE TABLE addresses ( id INT AUTO_INCREMENT PRIMARY KEY, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );   Now, in GHCi, we can use  sqlite-simple  to get a handle to this database.  conn   -   open   shoppingcart2.db   Before we add addresses, we need to add some users that we can reference.  let   james   =   User   james@example.com   James   Smith   b4cc344d25a2efe540adbf2678e2304c \n     betty   =   User   betty@example.com   Betty   Jones   82b054bd83ffad9b6cf8bdb98ce3cc2f \n     sam   =   User   sam@example.com   Sam   Taylor   332532dcfaa1cbf61e2a266bd723612c  withDatabaseDebug   putStrLn   conn   $   runInsert   $ \n   insert   ( _shoppingCartUsers   shoppingCartDb )   $ \n   insertValues   [   james ,   betty ,   sam   ]   Now that we have some  User  objects, we can create associated addresses. Let's give James one\naddress, Betty two addresses, and Sam none.  let   addresses   =   [   Address   ( Auto   Nothing )   123 Little Street   Nothing   Boston   MA   12345   ( pk   james ) \n                 ,   Address   ( Auto   Nothing )   222 Main Street   ( Just   Ste 1 )   Houston   TX   8888   ( pk   betty ) \n                 ,   Address   ( Auto   Nothing )   9999 Residence Ave   Nothing   Sugarland   TX   8989   ( pk   betty )   ]  withDatabaseDebug   putStrLn   conn   $   runInsert   $ \n   insert   ( _shoppingCartUserAddresses   shoppingCartDb )   $ \n   insertValues   addresses   Notice that we used the  pk  function to assign the reference to the  UserT  table.  pk  is a\nsynonym of the  primaryKey  function from the  Table  type class. It should be clear what's going\non, but if it's not, let's ask GHCi.  *NextSteps  pk (james :: User)  UserId  james@example.com   Notice also that we set  _addressId  to  Auto Nothing . As mentioned above, the AutoId  type means the addresses won't have an id until they're inserted into\nthe database. This could be an issue if we want to refer to the addresses in the\nfuture.  If we query for all the addresses, we'll see that SQLite has assigned them an\nappropriate id.  First, let's use the new lenses we made. Make sure to import  Lens.Micro  or Control.Lens  or whichever (van Laarhoven) lens module you prefer.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             -- import Lens.Micro  -- import Control.Lens  addresses   -   withDatabaseDebug   putStrLn   conn   $  \n              runSelectReturningList   $ \n              select   ( all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ))  mapM_   print   addresses  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . address1   AS   res1 , \n        t0 . address2   AS   res2 , \n        t0 . city   AS   res3 , \n        t0 . state   AS   res4 , \n        t0 . zip   AS   res5 , \n        t0 . for_user__email   AS   res6  FROM   addresses   AS   t0   -- With values: []  \n\n         \n    \n         \n             Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                _addressLine2 = Nothing,                                                                _addressCity =  Boston ,                                                                _addressState =  MA ,                                                                _addressZip =  12345 ,                                                                _addressForUser = UserId  james@example.com } --  Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                _addressLine2 = Just  Ste 1 ,                                                _addressCity =  Houston ,                                                _addressState =  TX ,                                                _addressZip =  8888 ,                                                _addressForUser = UserId  betty@example.com } --  Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                _addressLine2 = Nothing,                                                                _addressCity =  Sugarland ,                                                                _addressState =  TX ,                                                                _addressZip =  8989 ,                                                                _addressForUser = UserId  betty@example.com } --", 
            "title": "Working with relations"
        }, 
        {
            "location": "/tutorials/tutorial2/#a-note-about-queries", 
            "text": "In the last tutorial, we saw how queries and list supported similar interfaces.\nNamely we saw how  limit_  is like  take ,  offset_  like  drop ,  orderBy  like\nan enhanced  sortBy , and  aggregate  like an enhanced  groupBy . These\ncorresponded to the  LIMIT ,  OFFSET ,  ORDER BY , and  GROUP BY  SQL\nconstructs. The missing SQL operation in this list is the  JOIN , which computes\nthe cartesian product of two tables. In other words, a join between table  A \nand table  B  results in a query of pairs  (x, y)  for every  x  in  A  and\nevery  y  in  B . SQL joins can result in two-way, three-way, four-way, etc.\ncartesian products.  Those familiar with lists in Haskell will note that there is an easy abstraction\nfor taking  n -ary cartesian products over lists: monads.", 
            "title": "A note about queries"
        }, 
        {
            "location": "/tutorials/tutorial2/#the-list-monad", 
            "text": "We can use GHCi to see what we mean.  * NextSteps   do   {   x   -   [ 1 , 2 , 3 ];   y   -   [ 4 , 5 , 6 ];   return   ( x ,   y );   }  [( 1 , 4 ),( 1 , 5 ),( 1 , 6 ),( 2 , 4 ),( 2 , 5 ),( 2 , 6 ),( 3 , 4 ),( 3 , 5 ),( 3 , 6 )]   We get the two-way cartesian product of  [1,2,3]  and  [4,5,6] . We can make the\nproduct arbitrarily long.  * NextSteps   do   {   w   -   [ 10 ,   20 ,   30 ];   x   -   [ 1 , 2 , 3 ];   y   -   [ 4 , 5 , 6 ];   z   -   [ 100 ,   200 ,   1 ];   return   ( x ,   y ,   z ,   w );   }  [( 1 , 4 , 100 , 10 ),( 1 , 4 , 200 , 10 ),( 1 , 4 , 1 , 10 ),( 1 , 5 , 100 , 10 ),( 1 , 5 , 200 , 10 ),( 1 , 5 , 1 , 10 ),   ...   ]   We can also use  guard  from  Control.Monad  to limit the combinations that the\nlist monad puts together. For example, if we had the lists  let   usersList   =   [( 1 ,   james ),   ( 2 ,   betty ),   ( 3 ,   tom )] \n     addressesList   =   [( 1 ,   address1 ),   ( 1 ,   address2 ),   ( 3 ,   address3 )]   We can use  guard  to return all pairs of elements from  usersList  and addressesList  that matched on their first element. For example,  * NextSteps   do   {   user   -   usersList ;   address   -   addressesList ;   guard   ( fst   user   ==   fst   address );   return   ( user ,   address )   }  [(( 1 , james ),( 1 , address1 )),(( 1 , james ),( 1 , address2 )),(( 3 , tom ),( 3 , address3 ))]", 
            "title": "The list monad"
        }, 
        {
            "location": "/tutorials/tutorial2/#the-query-monad", 
            "text": "As I claimed in the first tutorial, queries support many of the same interfaces and operations lists\ndo. It follows that queries also expose a monadic interface.  For example, to retrieve every pair of user and address, we can write the following query:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             allPairs   -   withDatabaseDebug   putStrLn   conn   $ \n             runSelectReturningList   $   select   $   do \n               user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n               address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n               return   ( user ,   address )  mapM_   print   allPairs  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  sam@example.com ,         _userFirstName =  Sam ,         _userLastName =  Taylor ,         _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  sam@example.com ,         _userFirstName =  Sam ,         _userLastName =  Taylor ,         _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  sam@example.com ,         _userFirstName =  Sam ,         _userLastName =  Taylor ,         _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  \n\n         \n    \n         \n    \n                 \n                      Just like with lists we can also use a construct similar to guard to ensure that\nwe only retrieve users and addresses that are related. The  guard_  function\ntakes in expression of type  QExpr s Bool  which represents a SQL expression\nthat returns a boolean.  QExpr s Bool s support all the common operators we have\non regular  Bool , except they're suffixed with a  . . For example, where you'd\nuse  ( )  on two Haskell-level  Bool s, we'd use  ( .)  on  QExpr -level\nbools.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddresses   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        guard_   ( address   ^.   addressForUserId   ==.   user   ^.   userEmail ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddresses  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1  WHERE   ( t1 . for_user__email ) = ( t0 . email )   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  \n\n         \n    \n         \n    \n                 \n                      Of course this is kind of messy because it involves manually matching the\nprimary key of  User  with the reference in  Address . Alternatively, we can use\nthe  references_  predicate to have beam automatically generate a  QExpr \nexpression that can match primary keys together.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddressesUsingReferences   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n\n        guard_   ( _addressForUser   address   ` references_ `   user ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddressesUsingReferences  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . address1   AS   res5 , \n        t1 . address2   AS   res6 , \n        t1 . city   AS   res7 , \n        t1 . state   AS   res8 , \n        t1 . zip   AS   res9 , \n        t1 . for_user__email   AS   res10  FROM   cart_users   AS   t0  INNER   JOIN   addresses   AS   t1  WHERE   ( t1 . for_user__email ) = ( t0 . email )   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  \n\n         \n    \n         \n    \n                 \n                      You may have noticed that the joins up until now did not include a SQL  ON \nclause. Instead we joined the tables together, and then used the  WHERE  clause\nto filter out results we don't want. If you'd like to use the  ON  clause to\nmake the SQL clearer or save a line in your code, beam offers the  related_ \ncombinator to pull related tables directly into the query monad.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             usersAndRelatedAddressesUsingRelated   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        user   -   related_   ( shoppingCartDb   ^.   shoppingCartUsers )   ( _addressForUser   address ) \n        pure   ( user ,   address )  mapM_   print   usersAndRelatedAddressesUsingRelated  \n\n         \n    \n         \n             SELECT   t1 . email   AS   res0 , \n        t1 . first_name   AS   res1 , \n        t1 . last_name   AS   res2 , \n        t1 . password   AS   res3 , \n        t0 . id   AS   res4 , \n        t0 . address1   AS   res5 , \n        t0 . address2   AS   res6 , \n        t0 . city   AS   res7 , \n        t0 . state   AS   res8 , \n        t0 . zip   AS   res9 , \n        t0 . for_user__email   AS   res10  FROM   addresses   AS   t0  INNER   JOIN   cart_users   AS   t1   ON   ( t0 . for_user__email ) = ( t1 . email )   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com ,         _userFirstName =  James ,         _userLastName =  Smith ,         _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Boston ,                                                                                                                           _addressState =  MA ,                                                                                                                           _addressZip =  12345 ,                                                                                                                           _addressForUser = UserId  james@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                                                                           _addressLine2 = Just  Ste 1 ,                                                                                                           _addressCity =  Houston ,                                                                                                           _addressState =  TX ,                                                                                                           _addressZip =  8888 ,                                                                                                           _addressForUser = UserId  betty@example.com }) --  (User {_userEmail =  betty@example.com ,         _userFirstName =  Betty ,         _userLastName =  Jones ,         _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                                                                           _addressLine2 = Nothing,                                                                                                                           _addressCity =  Sugarland ,                                                                                                                           _addressState =  TX ,                                                                                                                           _addressZip =  8989 ,                                                                                                                           _addressForUser = UserId  betty@example.com }) --  \n\n         \n    \n         \n    \n                 \n                      We can also query the addresses for a particular user given a  UserId .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             -- This is a contrived example to show how we can use an arbitrary UserId to fetch a particular user.  -- We don t always have access to the full  User  lying around. For example we may be in a function that  -- only accepts  UserId s.  let   bettyId   =   UserId   betty@example.com   ::   UserId  bettysAddresses   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $   select   $ \n     do   address   -   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n        guard_   ( _addressForUser   address   ==.   val_   bettyId ) \n        pure   address  mapM_   print   bettysAddresses  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . address1   AS   res1 , \n        t0 . address2   AS   res2 , \n        t0 . city   AS   res3 , \n        t0 . state   AS   res4 , \n        t0 . zip   AS   res5 , \n        t0 . for_user__email   AS   res6  FROM   addresses   AS   t0  WHERE   ( t0 . for_user__email ) = ( ? )   -- With values: [SQLText  betty@example.com ]  \n\n         \n    \n         \n             Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                _addressLine2 = Just  Ste 1 ,                                                _addressCity =  Houston ,                                                _addressState =  TX ,                                                _addressZip =  8888 ,                                                _addressForUser = UserId  betty@example.com } --  Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                _addressLine2 = Nothing,                                                                _addressCity =  Sugarland ,                                                                _addressState =  TX ,                                                                _addressZip =  8989 ,                                                                _addressForUser = UserId  betty@example.com } --  \n\n         \n    \n         \n    \n                 \n                       Tip  More complicated joins are also supported. See the section\non  relationships", 
            "title": "The query monad"
        }, 
        {
            "location": "/tutorials/tutorial2/#updates-and-deletions", 
            "text": "So far we've only seen how to insert data and query it. There are two other SQL\noperations that we have not covered: updates and deletions. Beam has full\nsupport for these manipulations as well.", 
            "title": "Updates and deletions"
        }, 
        {
            "location": "/tutorials/tutorial2/#updates", 
            "text": "Like  INSERT  and  SELECT , to run an  UPDATE  command, we use the  runUpdate \nfunction, with a value of  SqlUpdate .  The  save  function constructs a value of  SqlUpdate  given a full record. It\nwill generate an  UPDATE  that will set every field (except for the primary key\nfields) for the row that completely matches the primary key.  Let's first look at updating passwords given a  User . For this we can use the saveTo  function. Suppose James wants to change his password to the md5 hash of\n\"supersecure\", which is  52a516ca6df436828d9c0d26e31ef704 . We have a  User \nobject representing James so we can simply call  saveTo  on the update value to\nupdate the corresponding record in the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             [ james ]   - \n   withDatabaseDebug   putStrLn   conn   $ \n     do   runUpdate   $ \n          save   ( shoppingCartDb   ^.   shoppingCartUsers )   ( james   {   _userPassword   =   52a516ca6df436828d9c0d26e31ef704   }) \n\n        runSelectReturningList   $ \n          lookup   ( shoppingCartDb   ^.   shoppingCartUsers )   ( UserId   james@example.com )  putStrLn   ( James s new password is    ++   show   ( james   ^.   userPassword ))  \n\n         \n    \n         \n             UPDATE   cart_users  SET   first_name =? , \n     last_name =? , \n     password =?  WHERE   ( email ) = ( ? )   -- With values: [SQLText  James ,SQLText  Smith ,SQLText  52a516ca6df436828d9c0d26e31ef704 ,SQLText  james@example.com ] \n\n   SELECT   t0 . email   AS   res0 , \n          t0 . first_name   AS   res1 , \n          t0 . last_name   AS   res2 , \n          t0 . password   AS   res3 \n   FROM   cart_users   AS   t0   WHERE   ( t0 . email ) = ( ? )   -- With values: [SQLText  james@example.com ]  \n\n         \n    \n         \n             James s new password is  52a516ca6df436828d9c0d26e31ef704  --  \n\n         \n    \n         \n    \n                 \n                       Tip  lookup  (defined in  Database.Beam.Query ) can be used to easily lookup a\nsingle entity given a table entity in a database and a primary key.  You may have to hide  lookup  from  Prelude  in order to use  lookup \nunqualified.   This works great, but  save  requires that we have the whole  User  object at\nour disposal. Additionally, you'll notice that it causes every field to be set\nin the  UPDATE  query. Typically, this doesn't matter, but sometimes we'd like\nto update fewer fields, multiple rows, or use criteria other than a primary key\nmatch. The  update  function offers finer-grained control over the command\nsubmitted to the database.  To illustrate use of this function, let's suppose the city of \"Sugarland, TX\"\nwas renamed \"Sugarville, TX\" and had its ZIP code changed to be \"12345\"\ncitywide. The following beam command will update all addresses in the old city\nto use the new name and ZIP code.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             addresses   - \n   withDatabaseDebug   putStrLn   conn   $ \n     do   runUpdate   $ \n          update   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n                 ( \\ address   -   [   address   ^.   addressCity   -.   val_   Sugarville \n                              ,   address   ^.   addressZip   -.   val_   12345   ]) \n                 ( \\ address   -   address   ^.   addressCity   ==.   val_   Sugarland   . \n                              address   ^.   addressState   ==.   val_   TX ) \n\n        runSelectReturningList   $   select   $   all_   ( shoppingCartDb   ^.   shoppingCartUserAddresses )  mapM_   print   addresses  \n\n         \n    \n         \n             UPDATE   addresses  SET   city =? , \n     zip =?  WHERE   (( city ) = ( ? )) \n   AND   (( state ) = ( ? )) -- With values: [SQLText  Sugarville ,SQLText  12345 ,SQLText  Sugarland ,SQLText  TX ] \n\n   SELECT   t0 . id   AS   res0 , \n          t0 . address1   AS   res1 , \n          t0 . address2   AS   res2 , \n          t0 . city   AS   res3 , \n          t0 . state   AS   res4 , \n          t0 . zip   AS   res5 , \n          t0 . for_user__email   AS   res6 \n   FROM   addresses   AS   t0   -- With values: []  \n\n         \n    \n         \n             Address {_addressId = Auto {unAuto = Just 1}, _addressLine1 =  123 Little Street ,                                                _addressLine2 = Nothing,                                                                _addressCity =  Boston ,                                                                _addressState =  MA ,                                                                _addressZip =  12345 ,                                                                _addressForUser = UserId  james@example.com } --  Address {_addressId = Auto {unAuto = Just 2}, _addressLine1 =  222 Main Street ,                                                _addressLine2 = Just  Ste 1 ,                                                _addressCity =  Houston ,                                                _addressState =  TX ,                                                _addressZip =  8888 ,                                                _addressForUser = UserId  betty@example.com } --  Address {_addressId = Auto {unAuto = Just 3}, _addressLine1 =  9999 Residence Ave ,                                                _addressLine2 = Nothing,                                                                _addressCity =  Sugarville ,                                                                _addressState =  TX ,                                                                _addressZip =  12345 ,                                                                _addressForUser = UserId  betty@example.com } --", 
            "title": "Updates"
        }, 
        {
            "location": "/tutorials/tutorial2/#deletions", 
            "text": "Now suppose that Betty has decided to give up her place in Houston. We can use runDelete  to run a  DELETE  command.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             withDatabaseDebug   putStrLn   conn   $ \n   runDelete   $ \n   delete   ( shoppingCartDb   ^.   shoppingCartUserAddresses ) \n          ( \\ address   -   address   ^.   addressCity   ==.   Houston   . \n                       _addressForUser   address   ` references_ `   betty )  \n\n         \n    \n         \n             DELETE  FROM   addresses  WHERE   (( city ) = ( ? )) \n   AND   (( for_user__email ) = ( ? ))   -- With values: [SQLText  Houston ,SQLText  betty@example.com ]", 
            "title": "Deletions"
        }, 
        {
            "location": "/tutorials/tutorial2/#conclusion", 
            "text": "In this tutorial we created our first beam relationship. We saw how to use the\nmodifications system to override the default names given to database entities.\nWe saw how to use  tableLenses  to generate lenses that can be used with any\nlens library. We used the monadic query interface to write queries that used SQL\njoins, and we saw how beam makes it easy to automatically pull related tables\ninto our queries. Finally we introduced the  runUpdate  and  runDelete \nfunctions and demonstrated several ways to construct UPDATEs and DELETEs.  At this point, we've covered enough of the beam interface to start writing\ninteresting programs. Take some time to explore beam and create your own\ndatabases. Afterwards, read on for the last part of the tutorial.      Actually, any  Beamable  type can be wholly embedded in another. See the\n   section on models in the  user guide  for more\n   information.    The  models guide  explains the exact mechanisms\n   used", 
            "title": "Conclusion"
        }, 
        {
            "location": "/tutorials/tutorial3/", 
            "text": "Introduction\n\n\nIn teh last part, we extended our shopping cart database to let users add\nmultiple addresses. We saw how to establish one-to-many relations between two\ntables, and how to use the monadic query interface to write SQL JOINs. In this\ninstallment, we'll be adding support for products and orders to our database\nschema. We'll see how to use an intermediary table to create many-to-many\nrelations and how to write LEFT JOINs. Finally, we'll see how to use \nNullable\n\nto create optional foreign key references.\n\n\nCreating tables is easy now\n\n\nLet's create our products table. By now, the pattern for adding a new table to\nthe schema should be pretty familiar, so I'm going to skip the explanation.\n\n\ndata\n \nProductT\n \nf\n \n=\n \nProduct\n\n                \n{\n \n_productId\n          \n::\n \nC\n \nf\n \n(\nAuto\n \nInt\n)\n\n                \n,\n \n_productTitle\n       \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_productDescription\n \n::\n \nC\n \nf\n \nText\n\n                \n,\n \n_productPrice\n       \n::\n \nC\n \nf\n \nInt\n \n{- Price in cents -}\n \n}\n\n                  \nderiving\n \nGeneric\n\n\ntype\n \nProduct\n \n=\n \nProductT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nProduct\n\n\n\ninstance\n \nTable\n \nProductT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nProductT\n \nf\n \n=\n \nProductId\n \n(\nColumnar\n \nf\n \n(\nAuto\n \nInt\n))\n\n                               \nderiving\n \nGeneric\n\n  \nprimaryKey\n \n=\n \nProductId\n \n.\n \n_productId\n\n\n\ninstance\n \nBeamable\n \nProductT\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nProductT\n)\n\n\n\n\n\n\nFor orders, we want to store an id, date created, and the user who made the\norder. We'd also like to create an optional link to a shipping information\ntable. When the shipping information is created, we'll fill in the shipping\ninformation in the order. In order to create the optional reference, we're going\nto use the \nNullable\n tag modifier to modify the column tag. \nNullable\n will\nturn all fields of type \nx\n into \nMaybe x\n. Note that we could also create this\nrelation by installing a primary key on the shipping info table, and this is\narguably the better option. However, we'll go with a nullable foreign key here\nto show the full breadth of beam's features, and because this sort of relation\nexists in many existing databases.\n\n\nimport\n \nData.Time\n\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nAddressT\n \nIdentity\n)\n\n\n\ndata\n \nOrderT\n \nf\n \n=\n \nOrder\n\n              \n{\n \n_orderId\n      \n::\n \nColumnar\n \nf\n \n(\nAuto\n \nInt\n)\n\n              \n,\n \n_orderDate\n    \n::\n \nColumnar\n \nf\n \nLocalTime\n\n              \n,\n \n_orderForUser\n \n::\n \nPrimaryKey\n \nUserT\n \nf\n\n              \n,\n \n_orderShipToAddress\n \n::\n \nPrimaryKey\n \nAddressT\n \nf\n\n              \n,\n \n_orderShippingInfo\n \n::\n \nPrimaryKey\n \nShippingInfoT\n \n(\nNullable\n \nf\n)\n \n}\n\n                \nderiving\n \nGeneric\n\n\ntype\n \nOrder\n \n=\n \nOrderT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nOrder\n\n\n\ninstance\n \nTable\n \nOrderT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nOrderT\n \nf\n \n=\n \nOrderId\n \n(\nColumnar\n \nf\n \n(\nAuto\n \nInt\n))\n\n                               \nderiving\n \nGeneric\n\n    \nprimaryKey\n \n=\n \nOrderId\n \n.\n \n_orderId\n\n\n\ninstance\n \nBeamable\n \nOrderT\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nOrderT\n)\n\n\n\ndata\n \nShippingCarrier\n \n=\n \nUSPS\n \n|\n \nFedEx\n \n|\n \nUPS\n \n|\n \nDHL\n\n                       \nderiving\n \n(\nShow\n,\n \nRead\n,\n \nEq\n,\n \nOrd\n,\n \nEnum\n)\n\n\n\ndata\n \nShippingInfoT\n \nf\n \n=\n \nShippingInfo\n\n                     \n{\n \n_shippingInfoId\n             \n::\n \nColumnar\n \nf\n \n(\nAuto\n \nInt\n)\n\n                     \n,\n \n_shippingInfoCarrier\n        \n::\n \nColumnar\n \nf\n \nShippingCarrier\n\n                     \n,\n \n_shippingInfoTrackingNumber\n \n::\n \nColumnar\n \nf\n \nText\n \n}\n\n                       \nderiving\n \nGeneric\n\n\ntype\n \nShippingInfo\n \n=\n \nShippingInfoT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nShippingInfo\n\n\n\ninstance\n \nTable\n \nShippingInfoT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nShippingInfoT\n \nf\n \n=\n \nShippingInfoId\n \n(\nColumnar\n \nf\n \n(\nAuto\n \nInt\n))\n\n                                      \nderiving\n \nGeneric\n\n    \nprimaryKey\n \n=\n \nShippingInfoId\n \n.\n \n_shippingInfoId\n\n\n\ninstance\n \nBeamable\n \nShippingInfoT\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nShippingInfoT\n)\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nShippingInfoT\n \n(\nNullable\n \nIdentity\n))\n\n\n\n\n\n\nIn the above example, we show how to use a custom data type as a beam column.\nRecall that beam lets you store any Haskell type in a \nColumnar\n. However, at\nsome point, we will need to demonstrate to SQLite how to store values of type\n\nShippingCarrier\n. We will come back to this later.\n\n\nWe would also like to be able to associate a list of products with each order as\nline items. To do this we will create a table with two foreign keys. This table\nwill establish a many-to-many relationship between orders and products.\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nOrderT\n \nIdentity\n)\n\n\nderiving\n \ninstance\n \nShow\n \n(\nPrimaryKey\n \nProductT\n \nIdentity\n)\n\n\n\ndata\n \nLineItemT\n \nf\n \n=\n \nLineItem\n\n                 \n{\n \n_lineItemInOrder\n    \n::\n \nPrimaryKey\n \nOrderT\n \nf\n\n                 \n,\n \n_lineItemForProduct\n \n::\n \nPrimaryKey\n \nProductT\n \nf\n\n                 \n,\n \n_lineItemQuantity\n   \n::\n \nColumnar\n \nf\n \nInt\n \n}\n\n                   \nderiving\n \nGeneric\n\n\ntype\n \nLineItem\n \n=\n \nLineItemT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nLineItem\n\n\n\ninstance\n \nTable\n \nLineItemT\n \nwhere\n\n    \ndata\n \nPrimaryKey\n \nLineItemT\n \nf\n \n=\n \nLineItemId\n \n(\nPrimaryKey\n \nOrderT\n \nf\n)\n \n(\nPrimaryKey\n \nProductT\n \nf\n)\n\n                                  \nderiving\n \nGeneric\n\n    \nprimaryKey\n \n=\n \nLineItemId\n \n$\n \n_lineItemInOrder\n \n*\n \n_lineItemForProduct\n\n\n\ninstance\n \nBeamable\n \nLineItemT\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nLineItemT\n)\n\n\n\n\n\n\n\n\nTip\n\n\nWe used the \nApplicative\n instance for \n(-\n) a\n above to write the\n\nprimaryKey\n function. The \nApplicative ((-\n) a)\n instance operates like an\nunwrapper \nReader\n of \na\n. The applicative actions are then functions from\n\na -\n x\n that inject values from the \na\n into the applicative bind.\n\n\n\n\nNow we'll add all these tables to our database.\n\n\n-- Some convenience lenses\n\n\n\nLineItem\n \n_\n \n_\n \n(\nLensFor\n \nlineItemQuantity\n)\n \n=\n \ntableLenses\n\n\nProduct\n \n(\nLensFor\n \nproductId\n)\n \n(\nLensFor\n \nproductTitle\n)\n \n(\nLensFor\n \nproductDescription\n)\n \n(\nLensFor\n \nproductPrice\n)\n \n=\n \ntableLenses\n\n\n\ndata\n \nShoppingCartDb\n \nf\n \n=\n \nShoppingCartDb\n\n                      \n{\n \n_shoppingCartUsers\n         \n::\n \nf\n \n(\nTableEntity\n \nUserT\n)\n\n                      \n,\n \n_shoppingCartUserAddresses\n \n::\n \nf\n \n(\nTableEntity\n \nAddressT\n)\n\n                      \n,\n \n_shoppingCartProducts\n      \n::\n \nf\n \n(\nTableEntity\n \nProductT\n)\n\n                      \n,\n \n_shoppingCartOrders\n        \n::\n \nf\n \n(\nTableEntity\n \nOrderT\n)\n\n                      \n,\n \n_shoppingCartShippingInfos\n \n::\n \nf\n \n(\nTableEntity\n \nShippingInfoT\n)\n\n                      \n,\n \n_shoppingCartLineItems\n     \n::\n \nf\n \n(\nTableEntity\n \nLineItemT\n)\n \n}\n\n                        \nderiving\n \nGeneric\n\n\n\ninstance\n \nDatabase\n \nShoppingCartDb\n\n\n\nShoppingCartDb\n \n(\nTableLens\n \nshoppingCartUsers\n)\n \n(\nTableLens\n \nshoppingCartUserAddresses\n)\n\n               \n(\nTableLens\n \nshoppingCartProducts\n)\n \n(\nTableLens\n \nshoppingCartOrders\n)\n\n               \n(\nTableLens\n \nshoppingCartShippingInfos\n)\n \n(\nTableLens\n \nshoppingCartLineItems\n)\n \n=\n \ndbLenses\n\n\n\nshoppingCartDb\n \n::\n \nDatabaseSettings\n \nbe\n \nShoppingCartDb\n\n\nshoppingCartDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n                 \ndbModification\n \n{\n\n                   \n_shoppingCartUserAddresses\n \n=\n\n                     \nmodifyTable\n \n(\n\\\n_\n \n-\n \naddresses\n)\n \n$\n\n                     \ntableModification\n \n{\n\n                       \n_addressLine1\n \n=\n \nfieldNamed\n \naddress1\n,\n\n                       \n_addressLine2\n \n=\n \nfieldNamed\n \naddress2\n\n                     \n},\n\n                   \n_shoppingCartProducts\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \nproducts\n)\n \ntableModification\n,\n\n                   \n_shoppingCartOrders\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \norders\n)\n \n$\n\n                                         \ntableModification\n \n{\n\n                                           \n_orderShippingInfo\n \n=\n \nShippingInfoId\n \nshipping_info__id\n\n                                         \n},\n\n                   \n_shoppingCartShippingInfos\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \nshipping_info\n)\n \n$\n\n                                                \ntableModification\n \n{\n\n                                                  \n_shippingInfoId\n \n=\n \nid\n,\n\n                                                  \n_shippingInfoCarrier\n \n=\n \ncarrier\n,\n\n                                                  \n_shippingInfoTrackingNumber\n \n=\n \ntracking_number\n\n                                                \n},\n\n                   \n_shoppingCartLineItems\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \nline_items\n)\n \ntableModification\n\n                 \n}\n\n\n\n\n\n\nFixtures\n\n\nLet's put some sample data into a new database.\n\n\nconn\n \n-\n \nopen\n \nshoppingcart3.db\n\n\n\nexecute_\n \nconn\n \nCREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));\n\n\nexecute_\n \nconn\n \nCREATE TABLE addresses ( id INTEGER PRIMARY KEY AUTOINCREMENT, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );\n\n\nexecute_\n \nconn\n \nCREATE TABLE products ( id INTEGER PRIMARY KEY AUTOINCREMENT, title VARCHAR NOT NULL, description VARCHAR NOT NULL, price INT NOT NULL );\n\n\nexecute_\n \nconn\n \nCREATE TABLE orders ( id INTEGER PRIMARY KEY AUTOINCREMENT, date TIMESTAMP NOT NULL, for_user__email VARCHAR NOT NULL, ship_to_address__id INT NOT NULL, shipping_info__id INT);\n\n\nexecute_\n \nconn\n \nCREATE TABLE shipping_info ( id INTEGER PRIMARY KEY AUTOINCREMENT, carrier VARCHAR NOT NULL, tracking_number VARCHAR NOT NULL);\n\n\nexecute_\n \nconn\n \nCREATE TABLE line_items (item_in_order__id INTEGER NOT NULL, item_for_product__id INTEGER NOT NULL, item_quantity INTEGER NOT NULL)\n\n\n\n\n\n\nLet's put some sample data into our database. Below, we will use the\n\nbeam-sqlite\n functions \ninsertReturning\n and \nrunInsertReturningList\n to insert\nrows \nand\n retrieve the inserted rows from the database. This will let us see\nwhat values the auto-incremented \nid\n columns took on, which will allow us to\ncreate references to these inserted rows.\n\n\nlet\n \nusers\n@\n[\njames\n,\n \nbetty\n,\n \nsam\n]\n \n=\n\n          \n[\n \nUser\n \njames@example.com\n \nJames\n \nSmith\n  \nb4cc344d25a2efe540adbf2678e2304c\n \n{- james -}\n\n          \n,\n \nUser\n \nbetty@example.com\n \nBetty\n \nJones\n  \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n \n{- betty -}\n\n          \n,\n \nUser\n \nsam@example.com\n   \nSam\n   \nTaylor\n \n332532dcfaa1cbf61e2a266bd723612c\n \n{- sam -}\n \n]\n\n    \naddresses\n \n=\n \n[\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n123 Little Street\n \nNothing\n \nBoston\n \nMA\n \n12345\n \n(\npk\n \njames\n)\n\n\n                \n,\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n222 Main Street\n \n(\nJust\n \nSte 1\n)\n \nHouston\n \nTX\n \n8888\n \n(\npk\n \nbetty\n)\n\n                \n,\n \nAddress\n \n(\nAuto\n \nNothing\n)\n \n9999 Residence Ave\n \nNothing\n \nSugarland\n \nTX\n \n8989\n \n(\npk\n \nbetty\n)\n \n]\n\n\n    \nproducts\n \n=\n \n[\n \nProduct\n \n(\nAuto\n \nNothing\n)\n \nRed Ball\n \nA bright red, very spherical ball\n \n1000\n\n               \n,\n \nProduct\n \n(\nAuto\n \nNothing\n)\n \nMath Textbook\n \nContains a lot of important math theorems and formulae\n \n2500\n\n               \n,\n \nProduct\n \n(\nAuto\n \nNothing\n)\n \nIntro to Haskell\n \nLearn the best programming language in the world\n \n3000\n\n               \n,\n \nProduct\n \n(\nAuto\n \nNothing\n)\n \nSuitcase\n \nA hard durable suitcase\n \n15000\n \n]\n\n\n\n(\njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n,\n \nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n)\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \nrunInsert\n \n$\n \ninsert\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n \n$\n\n                \ninsertValues\n \nusers\n\n\n    \n[\njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUserAddresses\n)\n \n$\n \ninsertValues\n \naddresses\n\n\n    \n[\nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n)\n \n$\n \ninsertValues\n \nproducts\n\n\n    \npure\n \n(\n \njamesAddress1\n,\n \nbettyAddress1\n,\n \nbettyAddress2\n,\n \nredBall\n,\n \nmathTextbook\n,\n \nintroToHaskell\n,\n \nsuitcase\n \n)\n\n\n\n\n\n\nNow, if we take a look at one of the returned addresses, like \njamesAddress1\n,\nwe see it has had it's \nAuto\n field assigned correctly.\n\n\nPrelude\n \nDatabase\n.\nBeam\n \nDatabase\n.\nBeam\n.\nSqlite\n \nData\n.\nTime\n \nDatabase\n.\nSQLite\n.\nSimple\n \nData\n.\nText\n \nLens\n.\nMicro\n \njamesAddress1\n\n\nAddress\n \n{\n_addressId\n \n=\n \nAuto\n \n{\nunAuto\n \n=\n \nJust\n \n1\n},\n \n_addressLine1\n \n=\n \n123 Little Street\n,\n \n_addressLine2\n \n=\n \nNothing\n,\n \n_addressCity\n \n=\n \nBoston\n,\n \n_addressState\n \n=\n \nMA\n,\n \n_addressZip\n \n=\n \n12345\n,\n \n_addressForUser\n \n=\n \nUserId\n \njames@example.com\n}\n\n\n\n\n\n\n\n\nNote\n\n\ninsertReturning\n and \nrunInsertReturningList\n are from the \nbeam-sqlite\n\npackage. They emulate the \nINSERT .. RETURNING ..\n functionatily you may\nexpect in other databases. Because this emulation is backend-specific it is\npart of the backend package, rather than \nbeam-core\n.\n\n\nOther backends may have similar functionality. Please refer to the backend\npackage you're interested in for more information, as well as notes on the\nimplementation.\n\n\n\n\nMarshalling a custom type\n\n\nNow we can insert shipping information. Of course, the shipping information\ncontains the \nShippingCarrier\n enumeration.\n\n\nbettyShippingInfo\n \n-\n \n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \n[\nbettyShippingInfo\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartShippingInfos\n)\n \n$\n\n      \ninsertValues\n \n[\n \nShippingInfo\n \n(\nAuto\n \nNothing\n)\n \nUSPS\n \n12345790ABCDEFGHI\n \n]\n\n    \npure\n \nbettyShippingInfo\n\n\n\n\n\n\nIf you run this, you'll get an error from GHCi.\n\n\ninteractive\n:\n263\n:\n7\n:\n error\n:\n\n    \n*\n No instance \nfor\n \n(\nDatabase.Beam.Backend.Types.FromBackendRow\n                         Sqlite ShippingCarrier\n)\n\n        arising from a use of \nrunInsertReturningList\n\n    \n*\n In a stmt of a \ndo\n block\n:\n\n        \n[\nbettyShippingInfo\n]\n \n-\n runInsertReturningList\n                               \n$\n insertReturning \n(\nshoppingCartDb \n^\n.\n shoppingCartShippingInfos\n)\n\n                                 \n$\n insertValues\n                                     \n[\nShippingInfo \n(\nAuto Nothing\n)\n USPS \n12345790ABCDEFGHI\n]\n\n      In the second argument of \n($)\n,\n namely\n        \ndo { [bettyShippingInfo] \n- runInsertReturningList\n\n\n                                     $ insertReturning (shoppingCartDb ^. shoppingCartShippingInfos)\n\n\n                                       $ insertValues\n\n\n                                           [ShippingInfo (Auto Nothing) USPS \n12345790ABCDEFGHI\n];\n\n\n              pure bettyShippingInfo }\n\n\n      In the first argument of \nGHC.GHCi.ghciStepIO \n::\n\n                                  forall a. IO a \n-\n IO a\n, namely\n\n\n        \nwithDatabaseDebug putStrLn conn\n         \n$\n do \n{\n \n[\nbettyShippingInfo\n]\n \n-\n runInsertReturningList\n                                       \n$\n insertReturning\n                                           \n(\nshoppingCartDb \n^\n.\n shoppingCartShippingInfos\n)\n\n                                         \n$\n insertValues\n                                             \n[\nShippingInfo \n(\nAuto Nothing\n)\n USPS \n12345790ABCDEFGHI\n];\n\n                pure bettyShippingInfo \n}\n\n\n\ninteractive\n:265:7: error:\n\n\n    * No instance for (Database.Beam.Backend.SQL.SQL92.HasSqlValueSyntax\n\n\n                         SqliteValueSyntax ShippingCarrier)\n\n\n        arising from a use of \ninsertValues\n\n\n    * In the second argument of \n(\n$\n)\n, namely\n\n\n        \ninsertValues\n           \n[\nShippingInfo \n(\nAuto Nothing\n)\n USPS \n12345790ABCDEFGHI\n]\n\n      In the second argument of \n($)\n,\n namely\n        \ninsertReturning (shoppingCartDb ^. shoppingCartShippingInfos)\n\n\n         $ insertValues\n\n\n             [ShippingInfo (Auto Nothing) USPS \n12345790ABCDEFGHI\n]\n\n      In a stmt of a \ndo\n block\n:\n\n        \n[\nbettyShippingInfo\n]\n \n-\n runInsertReturningList\n                               \n$\n insertReturning \n(\nshoppingCartDb \n^\n.\n shoppingCartShippingInfos\n)\n\n                                 \n$\n insertValues\n                                     \n[\nShippingInfo \n(\nAuto Nothing\n)\n USPS \n12345790ABCDEFGHI\n]\n\n\n\n\n\n\nThese errors are because there's no way to express a \nShippingCarrier\n in the\nbackend syntax. We can fix this by writing instances for beam. We can re-use the\nfunctionality we already have for \nString\n.\n\n\nThe \nHasSqlValueSyntax\n class tells us how to convert a Haskell value into a\ncorresponding backend value.\n\n\nimport\n \nDatabase.Beam.Backend.SQL\n\n\n\n:\nset\n \n-\nXUndecidableInstances\n\n\n\ninstance\n \nHasSqlValueSyntax\n \nbe\n \nString\n \n=\n \nHasSqlValueSyntax\n \nbe\n \nShippingCarrier\n \nwhere\n\n  \nsqlValueSyntax\n \n=\n \nautoSqlValueSyntax\n\n\n\n\n\n\nThe \nFromBackendRow\n class tells us how to convert a value from the database\ninto a corresponding Haskell value. Most often, it is enough to declare an empty\ninstance, so long as there is a backend-specific instance for unmarshaling your\ndata type.\n\n\nFor example,\n\n\nPrelude\n \nDatabase\n.\nBeam\n \nDatabase\n.\nBeam\n.\nSqlite\n \nData\n.\nTime\n \nDatabase\n.\nSQLite\n.\nSimple\n \nData\n.\nText\n \nLens\n.\nMicro\n \nimport\n \nDatabase.Beam.Backend\n\n\nPrelude\n \nDatabase\n.\nBeam\n \nDatabase\n.\nBeam\n.\nSqlite\n \nData\n.\nTime\n \nDatabase\n.\nSQLite\n.\nSimple\n \nData\n.\nText\n \nLens\n.\nMicro\n \nDatabase\n.\nBeam\n.\nBackend\n \n:\nset\n \n-\nXMultiParamTypeClasses\n\n\nPrelude\n \nDatabase\n.\nBeam\n \nDatabase\n.\nBeam\n.\nSqlite\n \nData\n.\nTime\n \nDatabase\n.\nSQLite\n.\nSimple\n \nData\n.\nText\n \nLens\n.\nMicro\n \nDatabase\n.\nBeam\n.\nBackend\n \ninstance\n \nFromBackendRow\n \nSqlite\n \nShippingCarrier\n\n\n\ninteractive\n:\n271\n:\n10\n:\n \nerror\n:\n\n    \n*\n \nNo\n \ninstance\n \nfor\n \n(\nDatabase\n.\nSQLite\n.\nSimple\n.\nFromField\n.\nFromField\n\n                         \nShippingCarrier\n)\n\n        \narising\n \nfrom\n \na\n \nuse\n \nof\n \nDatabase\n.\nBeam\n.\nBackend\n.\nTypes\n.$\ndmfromBackendRow\n\n    \n*\n \nIn\n \nthe\n \nexpression\n:\n\n        \nDatabase\n.\nBeam\n.\nBackend\n.\nTypes\n.$\ndmfromBackendRow\n\n          \n@\nSqlite\n \n@\nShippingCarrier\n\n      \nIn\n \nan\n \nequation\n \nfor\n \nfromBackendRow\n:\n\n          \nfromBackendRow\n\n            \n=\n \nDatabase\n.\nBeam\n.\nBackend\n.\nTypes\n.$\ndmfromBackendRow\n\n                \n@\nSqlite\n \n@\nShippingCarrier\n\n      \nIn\n \nthe\n \ninstance\n \ndeclaration\n \nfor\n\n        \nFromBackendRow\n \nSqlite\n \nShippingCarrier\n\n\n\n\n\n\nLet's see if we can write \nDatabase.SQLite.Simple.FromField.FromField\n instance\nfor \nShippingCarrier\n and then let's try re-instantiating \nFromBackendRow\n.\n\n\nimport\n \nDatabase.SQLite.Simple.FromField\n\n\nimport\n \nText.Read\n\n\n\ninstance\n \nFromField\n \nShippingCarrier\n \nwhere\n\n  \nfromField\n \nf\n \n=\n \ndo\n \nx\n \n-\n \nreadMaybe\n \n$\n \nfromField\n \nf\n\n                   \ncase\n \nx\n \nof\n\n                     \nNothing\n \n-\n \nreturnError\n \nConversionFailed\n \nf\n \nCould not \nread\n value for \nShippingCarrier\n\n                     \nJust\n \nx\n \n-\n \npure\n \nx\n\n\ninstance\n \nFromBackendRow\n \nbe\n \nShippingCarrier\n\n\n\n\n\n\nNow, if we try to insert the shipping info again, it works.\n\n\nbettyShippingInfo\n \n-\n \n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \n[\nbettyShippingInfo\n]\n \n-\n\n      \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartShippingInfos\n)\n \n$\n\n      \ninsertValues\n \n[\n \nShippingInfo\n \n(\nAuto\n \nNothing\n)\n \nUSPS\n \n12345790ABCDEFGHI\n \n]\n\n    \npure\n \nbettyShippingInfo\n\n\n\n\n\n\nAnd if we look at the value of \nbettyShippingInfo\n, \nShippingCarrier\n has been\nstored correctly.\n\n\n \nbettyShippingInfo\n\n\nShippingInfo\n \n{\n_shippingInfoId\n \n=\n \nAuto\n \n{\nunAuto\n \n=\n \nJust\n \n1\n},\n \n_shippingInfoCarrier\n \n=\n \nUSPS\n,\n \n_shippingInfoTrackingNumber\n \n=\n \n12345790ABCDEFGHI\n}\n\n\n\n\n\n\nNow, let's insert some orders that just came in. In the previous \nINSERT\n\nexamples, we used \ninsertValues\n to insert arbitrary values into the database.\nNow, we want to insert transactions with the current database timestamp (i.e.,\n\nCURRENT_TIMESTAMP\n in SQL). We can insert rows containing arbitrary expressions\nusing the \ninsertExpressions\n function. As you can see, the resulting rows have\na timestamp set by the database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nConsole\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n[\n \njamesOrder1\n,\n \nbettyOrder1\n,\n \njamesOrder2\n \n]\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n    \nrunInsertReturningList\n \n$\n\n      \ninsertReturning\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n \n$\n\n      \ninsertExpressions\n \n$\n\n      \n[\n \nOrder\n \n(\nval_\n \n(\nAuto\n \nNothing\n))\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \njames\n))\n \n(\nval_\n \n(\npk\n \njamesAddress1\n))\n \nnothing_\n \n      \n,\n \nOrder\n \n(\nval_\n \n(\nAuto\n \nNothing\n))\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \nbetty\n))\n \n(\nval_\n \n(\npk\n \nbettyAddress1\n))\n \n(\njust_\n \n(\nval_\n \n(\npk\n \nbettyShippingInfo\n)))\n \n      \n,\n \nOrder\n \n(\nval_\n \n(\nAuto\n \nNothing\n))\n \ncurrentTimestamp_\n \n(\nval_\n \n(\npk\n \njames\n))\n \n(\nval_\n \n(\npk\n \njamesAddress1\n))\n \nnothing_\n \n]\n\n\n\nprint\n \njamesOrder1\n\n\nprint\n \nbettyOrder1\n\n\nprint\n \njamesOrder2\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \norders\n(\nid\n,\n\n                     \ndate\n,\n\n                     \nfor_user__email\n,\n\n                     \nship_to_address__id\n,\n\n                     \nshipping_info__id\n)\n\n\nVALUES\n \n(\nNULL\n,\n\n        \nCURRENT_TIMESTAMP\n,\n\n        \n?\n,\n\n        \n?\n,\n\n        \nNULL\n),\n \n(\nNULL\n,\n\n                \nCURRENT_TIMESTAMP\n,\n\n                \n?\n,\n\n                \n?\n,\n\n                \n?\n),\n \n(\nNULL\n,\n\n                     \nCURRENT_TIMESTAMP\n,\n\n                     \n?\n,\n\n                     \n?\n,\n\n                     \nNULL\n)\n \n-- With values: [SQLText \njames@example.com\n,SQLInteger 1,SQLText \nbetty@example.com\n,SQLInteger 2,SQLInteger 1,SQLText \njames@example.com\n,SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n            \nOrder {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:27,\n\n\n                                                                        _orderForUser = UserId \njames@example.com\n,\n\n\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n\n\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} --\n\n\nOrder {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:27,\n\n\n                                                                        _orderForUser = UserId \nbetty@example.com\n,\n\n\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 2}),\n\n\n                                                                        _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))} --\n\n\nOrder {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:27,\n\n\n                                                                        _orderForUser = UserId \njames@example.com\n,\n\n\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n\n\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} --\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nFinally, let's add some line items\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \nlineItems\n \n=\n \n[\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nredBall\n)\n \n10\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nmathTextbook\n)\n \n1\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder1\n)\n \n(\npk\n \nintroToHaskell\n)\n \n4\n\n\n                \n,\n \nLineItem\n \n(\npk\n \nbettyOrder1\n)\n \n(\npk\n \nmathTextbook\n)\n \n3\n\n                \n,\n \nLineItem\n \n(\npk\n \nbettyOrder1\n)\n \n(\npk\n \nintroToHaskell\n)\n \n3\n\n\n                \n,\n \nLineItem\n \n(\npk\n \njamesOrder2\n)\n \n(\npk\n \nmathTextbook\n)\n \n1\n \n]\n\n\n\nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n \ndo\n\n  \nrunInsert\n \n$\n \ninsert\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n)\n \n$\n\n    \ninsertValues\n \nlineItems\n\n\n\n\n        \n\n    \n        \n\n            \nINSERT\n \nINTO\n \nline_items\n(\nitem_in_order__id\n,\n\n                         \nitem_for_product__id\n,\n\n                         \nitem_quantity\n)\n\n\nVALUES\n \n(\n?\n,\n\n        \n?\n,\n\n        \n?\n),\n \n(\n?\n,\n\n             \n?\n,\n\n             \n?\n),\n \n(\n?\n,\n\n                  \n?\n,\n\n                  \n?\n),\n \n(\n?\n,\n\n                       \n?\n,\n\n                       \n?\n),\n \n(\n?\n,\n\n                            \n?\n,\n\n                            \n?\n),\n \n(\n?\n,\n\n                                 \n?\n,\n\n                                 \n?\n)\n \n-- With values: [SQLInteger 1,SQLInteger 1,SQLInteger 10,SQLInteger 1,SQLInteger 2,SQLInteger 1,SQLInteger 1,SQLInteger 3,SQLInteger 4,SQLInteger 2,SQLInteger 2,SQLInteger 3,SQLInteger 2,SQLInteger 3,SQLInteger 3,SQLInteger 3,SQLInteger 2,SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nPhew! Let's write some queries on this data!\n\n\nWould you like some left joins with that?\n\n\nSuppose we want to do some analytics on our users, and so we want to know how many orders each user\nhas made in our system. We can write a query to list every user along with the orders they've\nmade. We can use \nleftJoin_\n to include all users in our result set, even those who have no\norders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersAndOrders\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n      \npure\n \n(\nuser\n,\n \norder\n)\n\n\n\nmapM_\n \nprint\n \nusersAndOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nid\n \nAS\n \nres4\n,\n\n       \nt1\n.\ndate\n \nAS\n \nres5\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres6\n,\n\n       \nt1\n.\nship_to_address__id\n \nAS\n \nres7\n,\n\n       \nt1\n.\nshipping_info__id\n \nAS\n \nres8\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId (Auto {unAuto = Just 1}), _orderShippingInfo = ShippingInfoId Nothing})) --\n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId \njames@example.com\n, _orderShipToAddress = AddressId (Auto {unAuto = Just 1}), _orderShippingInfo = ShippingInfoId Nothing})) --\n(User {_userEmail = \nbetty@example.com\n,\n       _userFirstName = \nBetty\n,\n       _userLastName = \nJones\n,\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId \nbetty@example.com\n, _orderShipToAddress = AddressId (Auto {unAuto = Just 2}), _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))})) --\n(User {_userEmail = \nsam@example.com\n,\n       _userFirstName = \nSam\n,\n       _userLastName = \nTaylor\n,\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},Nothing) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that sam is included in the result set, even though he doesn't have any\nassociated orders. Instead of a \nJust (Order ..)\n, \nNothing\n is returned\ninstead.\n\n\nNext, perhaps our marketing team wanted to send e-mails out to all users with no\norders. We can use \nisNothing_\n or \nisJust_\n to determine the status if a\nnullable table or \nQExpr s (Maybe x)\n. The following query uses \nisNothing_\n to\nfind users who have no associated orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersWithNoOrders\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n      \nguard_\n \n(\nisNothing_\n \norder\n)\n\n      \npure\n \nuser\n\n\n\nmapM_\n \nprint\n \nusersWithNoOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nWHERE\n \n(((((\nt1\n.\nid\n)\n \nIS\n \nNULL\n)\n\n         \nAND\n \n((\nt1\n.\ndate\n)\n \nIS\n \nNULL\n))\n\n        \nAND\n \n((\nt1\n.\nfor_user__email\n)\n \nIS\n \nNULL\n))\n\n       \nAND\n \n((\nt1\n.\nship_to_address__id\n)\n \nIS\n \nNULL\n))\n\n  \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n)\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nsam@example.com\n,\n      _userFirstName = \nSam\n,\n      _userLastName = \nTaylor\n,\n      _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe see that beam generates a sensible SQL \nSELECT\n and \nWHERE\n clause.\n\n\nWe can also use the \nexists_\n combinator to utilize the SQL \nEXISTS\n clause.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nusersWithNoOrders\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n \ndo\n\n      \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n      \nguard_\n \n(\nnot_\n \n(\nexists_\n \n(\nfilter_\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)))))\n\n      \npure\n \nuser\n\n\n\nmapM_\n \nprint\n \nusersWithNoOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nWHERE\n \nNOT\n(\nEXISTS\n\n            \n(\nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n \nt0\n.\ndate\n \nAS\n \nres1\n,\n \nt0\n.\nfor_user__email\n \nAS\n \nres2\n,\n \nt0\n.\nship_to_address__id\n \nAS\n \nres3\n,\n \nt0\n.\nshipping_info__id\n \nAS\n \nres4\n\n             \nFROM\n \norders\n \nAS\n \nt0\n\n             \nWHERE\n \n(\nt0\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)))\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nUser {_userEmail = \nsam@example.com\n,\n      _userFirstName = \nSam\n,\n      _userLastName = \nTaylor\n,\n      _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNow suppose we wanted to do some analysis on the orders themselves. To start, we\nwant to get the orders sorted by their portion of revenue. We can use\n\naggregate_\n to list every order and the total amount of all products in that\norder.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nordersWithCostOrdered\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \norderBy_\n \n(\n\\\n(\norder\n,\n \ntotal\n)\n \n-\n \ndesc_\n \ntotal\n)\n \n$\n\n    \naggregate_\n \n(\n\\\n(\norder\n,\n \nlineItem\n,\n \nproduct\n)\n \n-\n\n                   \n(\ngroup_\n \norder\n,\n \nsum_\n \n(\nlineItem\n \n^.\n \nlineItemQuantity\n \n*\n \nproduct\n \n^.\n \nproductPrice\n)))\n \n$\n\n    \ndo\n \nlineItem\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n)\n\n       \norder\n    \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n \n(\n_lineItemInOrder\n \nlineItem\n)\n\n       \nproduct\n  \n-\n \nrelated_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n)\n \n(\n_lineItemForProduct\n \nlineItem\n)\n\n       \npure\n \n(\norder\n,\n \nlineItem\n,\n \nproduct\n)\n\n\n\nmapM_\n \nprint\n \nordersWithCostOrdered\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nid\n \nAS\n \nres0\n,\n\n       \nt1\n.\ndate\n \nAS\n \nres1\n,\n\n       \nt1\n.\nfor_user__email\n \nAS\n \nres2\n,\n\n       \nt1\n.\nship_to_address__id\n \nAS\n \nres3\n,\n\n       \nt1\n.\nshipping_info__id\n \nAS\n \nres4\n,\n\n       \nSUM\n((\nt0\n.\nitem_quantity\n)\n \n*\n \n(\nt2\n.\nprice\n))\n \nAS\n \nres5\n\n\nFROM\n \nline_items\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt0\n.\nitem_in_order__id\n)\n=\n(\nt1\n.\nid\n)\n\n\nINNER\n \nJOIN\n \nproducts\n \nAS\n \nt2\n \nON\n \n(\nt0\n.\nitem_for_product__id\n)\n=\n(\nt2\n.\nid\n)\n\n\nGROUP\n \nBY\n \nt1\n.\nid\n,\n\n         \nt1\n.\ndate\n,\n\n         \nt1\n.\nfor_user__email\n,\n\n         \nt1\n.\nship_to_address__id\n,\n\n         \nt1\n.\nshipping_info__id\n\n\nORDER\n \nBY\n \nSUM\n((\nt0\n.\nitem_quantity\n)\n \n*\n \n(\nt2\n.\nprice\n))\n \nDESC\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(\n Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:49,\n                                                                         _orderForUser = UserId \njames@example.com\n,\n                                                                         _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                         _orderShippingInfo = ShippingInfoId Nothing},24500) --\n(\n                                                                                                                                Order {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:49,\n                                                                                                                                                                                                        _orderForUser = UserId \nbetty@example.com\n,\n                                                                                                                                                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 2}),\n                                                                                                                                                                                                        _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))},16500) --\n(\n                                                                                                                                                                                                                                                                                       Order {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:49,\n                                                                                                                                                                                                                                                                                                                                                               _orderForUser = UserId \njames@example.com\n,\n                                                                                                                                                                                                                                                                                                                                                               _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                                                                                                                                                                                                                                                                                                               _orderShippingInfo = ShippingInfoId Nothing},2500) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWe can also get the total amount spent by each user, even including users with no orders. Notice\nthat we have to use \nmaybe_\n below in order to handle the fact that some tables have been introduced\ninto our query with a left join. \nmaybe_\n is to \nQExpr\n what \nmaybe\n is to normal Haskell\nvalues. \nmaybe_\n is polymorphic to either \nQExpr\ns or full on tables of \nQExpr\ns. For our purposes,\nthe type of \nmaybe_\n is\n\n\nmaybe_\n \n::\n \nQExpr\n \ns\n \na\n \n-\n \n(\nQExpr\n \ns\n \nb\n \n-\n \nQExpr\n \ns\n \na\n)\n \n-\n \nQExpr\n \ns\n \n(\nMaybe\n \nb\n)\n \n-\n \nQExpr\n \ns\n \na\n\n\n\n\n\n\nWith that in mind, we can write the query to get the total spent by user\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallUsersAndTotals\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \norderBy_\n \n(\n\\\n(\nuser\n,\n \ntotal\n)\n \n-\n \ndesc_\n \ntotal\n)\n \n$\n\n    \naggregate_\n \n(\n\\\n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n \n-\n\n                   \n(\ngroup_\n \nuser\n,\n \nsum_\n \n(\nmaybe_\n \n0\n \nid\n \n(\n_lineItemQuantity\n \nlineItem\n)\n \n*\n \nmaybe_\n \n0\n \nid\n \n(\nproduct\n \n^.\n \nproductPrice\n))))\n \n$\n\n    \ndo\n \nuser\n     \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \norder\n    \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                             \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n       \nlineItem\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartLineItems\n))\n\n                             \n(\n\\\nlineItem\n \n-\n \nmaybe_\n \n(\nval_\n \nFalse\n)\n \n(\n\\\norder\n \n-\n \n_lineItemInOrder\n \nlineItem\n \n`\nreferences_\n`\n \norder\n)\n \norder\n)\n\n       \nproduct\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartProducts\n))\n\n                             \n(\n\\\nproduct\n \n-\n \nmaybe_\n \n(\nval_\n \nFalse\n)\n \n(\n\\\nlineItem\n \n-\n \n_lineItemForProduct\n \nlineItem\n \n`\nreferences_\n`\n \nproduct\n)\n \nlineItem\n)\n\n       \npure\n \n(\nuser\n,\n \nlineItem\n,\n \nproduct\n)\n\n\n\nmapM_\n \nprint\n \nallUsersAndTotals\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nSUM\n((\nCASE\n\n                \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                \nELSE\n \n?\n\n            \nEND\n)\n \n*\n \n(\nCASE\n\n                        \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                        \nELSE\n \n?\n\n                    \nEND\n))\n \nAS\n \nres4\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nLEFT\n \nJOIN\n \nline_items\n \nAS\n \nt2\n \nON\n \nCASE\n\n                                      \nWHEN\n \n(((((\nt1\n.\nid\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n                                              \nAND\n \n((\nt1\n.\ndate\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                             \nAND\n \n((\nt1\n.\nfor_user__email\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                            \nAND\n \n((\nt1\n.\nship_to_address__id\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                           \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n \nTHEN\n \n(\nt2\n.\nitem_in_order__id\n)\n=\n(\nt1\n.\nid\n)\n\n                                      \nELSE\n \n?\n\n                                  \nEND\n\n\nLEFT\n \nJOIN\n \nproducts\n \nAS\n \nt3\n \nON\n \nCASE\n\n                                    \nWHEN\n \n(((\nt2\n.\nitem_in_order__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n                                          \nAND\n \n((\nt2\n.\nitem_for_product__id\n)\n \nIS\n \nNOT\n \nNULL\n))\n\n                                         \nAND\n \n((\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n)\n \nTHEN\n \n(\nt2\n.\nitem_for_product__id\n)\n=\n(\nt3\n.\nid\n)\n\n                                    \nELSE\n \n?\n\n                                \nEND\n\n\nGROUP\n \nBY\n \nt0\n.\nemail\n,\n\n         \nt0\n.\nfirst_name\n,\n\n         \nt0\n.\nlast_name\n,\n\n         \nt0\n.\npassword\n\n\nORDER\n \nBY\n \nSUM\n((\nCASE\n\n                  \nWHEN\n \n(\nt2\n.\nitem_quantity\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt2\n.\nitem_quantity\n\n                  \nELSE\n \n?\n\n              \nEND\n)\n \n*\n \n(\nCASE\n\n                          \nWHEN\n \n(\nt3\n.\nprice\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nt3\n.\nprice\n\n                          \nELSE\n \n?\n\n                      \nEND\n))\n \nDESC\n \n-- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n,\n       _userFirstName = \nBetty\n,\n       _userLastName = \nJones\n,\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},16500) --\n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},0) --\n(User {_userEmail = \nsam@example.com\n,\n       _userFirstName = \nSam\n,\n       _userLastName = \nTaylor\n,\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},0) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nQueries with nullable foreign keys\n\n\nRecall that our schema contains a nullable foreign key from \nOrderT\n to \nShippingInfoT\n. Above,\nwe've seen how \nleftJoin_\n introduces nullable tables into our queries. Below, we'll see how to use\nnullable primary keys to optionally include information.\n\n\nSuppose we want to find all orders who have not been shipped. We can do this by simply writing a query over the orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nallUnshippedOrders\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \nfilter_\n \n(\nisNothing_\n \n.\n \n_orderShippingInfo\n)\n \n$\n\n    \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n)\n\n\n\nmapM_\n \nprint\n \nallUnshippedOrders\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nid\n \nAS\n \nres0\n,\n\n       \nt0\n.\ndate\n \nAS\n \nres1\n,\n\n       \nt0\n.\nfor_user__email\n \nAS\n \nres2\n,\n\n       \nt0\n.\nship_to_address__id\n \nAS\n \nres3\n,\n\n       \nt0\n.\nshipping_info__id\n \nAS\n \nres4\n\n\nFROM\n \norders\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nOrder {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:59,\n                                                                        _orderForUser = UserId \njames@example.com\n,\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} --\nOrder {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:59,\n                                                                        _orderForUser = UserId \njames@example.com\n,\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nLet's count up all shipped and unshipped orders by user, including users who have no orders.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \naggregate_\n \n(\n\\\n(\nuser\n,\n \norder\n)\n \n-\n\n                   \nlet\n \nShippingInfoId\n \nshippingInfoId\n \n=\n \n_orderShippingInfo\n \norder\n\n                   \nin\n \n(\n \ngroup_\n \nuser\n\n                      \n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \n(\nas_\n \n@\n(\nMaybe\n \nInt\n)\n \n(\nmaybe_\n \n(\njust_\n \n1\n)\n \n(\n\\\n_\n \n-\n \nnothing_\n)\n \nshippingInfoId\n))\n\n                      \n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \nshippingInfoId\n \n)\n \n)\n \n$\n\n    \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n       \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n)\n\n       \npure\n \n(\nuser\n,\n \norder\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nCOUNT\n(\nCASE\n\n                 \nWHEN\n \n(\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n \nTHEN\n \nNULL\n\n                 \nELSE\n \n?\n\n             \nEND\n)\n \nAS\n \nres4\n,\n\n       \nCOUNT\n(\nt1\n.\nshipping_info__id\n)\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n)\n\n\nGROUP\n \nBY\n \nt0\n.\nemail\n,\n\n         \nt0\n.\nfirst_name\n,\n\n         \nt0\n.\nlast_name\n,\n\n         \nt0\n.\npassword\n \n-- With values: [SQLInteger 1]\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n,\n       _userFirstName = \nBetty\n,\n       _userLastName = \nJones\n,\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},0,\n                                                           1) --\n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,\n                                                           0) --\n(User {_userEmail = \nsam@example.com\n,\n       _userFirstName = \nSam\n,\n       _userLastName = \nTaylor\n,\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,\n                                                           0) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nUh-oh! There's an error in the result set! Sam is reported as having one\nunshipped order, instead of zero.\n\n\nHere we hit one of the limitations of beam's mapping to SQL, and really one of\nthe limitations of SQL itself. Namely, the NULL in the result rows for Sam is\nnot distinguished from the NULL in the shipping info key itself. Beam however\ndoes make the distinction.\n\n\nWhen beam deserializes a \nNULL\n in a \nMaybe\n field, the outermost \nMaybe\n is the\none populated with \nNothing\n. Thus it is impossible to retrieve a value like\n\nJust Nothing\n from the database using the default serializers and\ndeserializers. In general, it's best to avoid highly nested \nMaybe\ns in your\nqueries because it makes them more difficult to understand.\n\n\nOne way to work around this issue in the above query is to use subselects.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n\n       \n(\nuserEmail\n,\n \nunshippedCount\n)\n \n-\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisNothing_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \n(\nuserEmail\n,\n \nshippedCount\n)\n \n-\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisJust_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \npure\n \n(\nuser\n,\n \nunshippedCount\n,\n \nshippedCount\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres4\n,\n\n       \nt2\n.\nres1\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n   \nFROM\n \ncart_users\n \nAS\n \nt0\n\n   \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n   \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n)\n\n   \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n          \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n   \nFROM\n \ncart_users\n \nAS\n \nt0\n\n   \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n   \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n   \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt2\n\n\nWHERE\n \n((\nt1\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n\n  \nAND\n \n((\nt2\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n,\n       _userFirstName = \nBetty\n,\n       _userLastName = \nJones\n,\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},1,\n                                                           1) --\n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,\n                                                           1) --\n(User {_userEmail = \nsam@example.com\n,\n       _userFirstName = \nSam\n,\n       _userLastName = \nTaylor\n,\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,\n                                                           1) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nNotice that the \naggregate_\ns embedded in the \nQ\n monad were automatically\nconverted into sub \nSELECT\ns. This is because beam queries are composable -- you\ncan use them wherever they type check and sensible SQL will result. Of course,\nif you want more control, you can also use the \nsubselect_\n combinator to force\ngeneration of a sub \nSELECT\n.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSql\n\n        \n\n    \n        \n\n            \nOut\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nshippingInformationByUser\n \n-\n\n  \nwithDatabaseDebug\n \nputStrLn\n \nconn\n \n$\n\n    \nrunSelectReturningList\n \n$\n\n    \nselect\n \n$\n\n    \ndo\n \nuser\n \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n\n       \n(\nuserEmail\n,\n \nunshippedCount\n)\n \n-\n\n         \nsubselect_\n \n$\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisNothing_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \n(\nuserEmail\n,\n \nshippedCount\n)\n \n-\n\n         \nsubselect_\n \n$\n\n         \naggregate_\n \n(\n\\\n(\nuserEmail\n,\n \norder\n)\n \n-\n \n(\ngroup_\n \nuserEmail\n,\n \ncountAll_\n))\n \n$\n\n         \ndo\n \nuser\n  \n-\n \nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartUsers\n)\n\n            \norder\n \n-\n \nleftJoin_\n \n(\nall_\n \n(\nshoppingCartDb\n \n^.\n \nshoppingCartOrders\n))\n\n                               \n(\n\\\norder\n \n-\n \n_orderForUser\n \norder\n \n`\nreferences_\n`\n \nuser\n \n.\n \nisJust_\n \n(\n_orderShippingInfo\n \norder\n))\n\n            \npure\n \n(\npk\n \nuser\n,\n \norder\n)\n\n       \nguard_\n \n(\nuserEmail\n \n`\nreferences_\n`\n \nuser\n)\n\n\n       \npure\n \n(\nuser\n,\n \nunshippedCount\n,\n \nshippedCount\n)\n\n\n\nmapM_\n \nprint\n \nshippingInformationByUser\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n       \nt0\n.\nfirst_name\n \nAS\n \nres1\n,\n\n       \nt0\n.\nlast_name\n \nAS\n \nres2\n,\n\n       \nt0\n.\npassword\n \nAS\n \nres3\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres4\n,\n\n       \nt2\n.\nres1\n \nAS\n \nres5\n\n\nFROM\n \ncart_users\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n             \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n      \nFROM\n \ncart_users\n \nAS\n \nt0\n\n      \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n      \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNULL\n)\n\n      \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt0\n)\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nemail\n \nAS\n \nres0\n,\n\n             \nCOUNT\n(\n*\n)\n \nAS\n \nres1\n\n      \nFROM\n \ncart_users\n \nAS\n \nt0\n\n      \nLEFT\n \nJOIN\n \norders\n \nAS\n \nt1\n \nON\n \n((\nt1\n.\nfor_user__email\n)\n=\n(\nt0\n.\nemail\n))\n\n      \nAND\n \n((\nt1\n.\nshipping_info__id\n)\n \nIS\n \nNOT\n \nNULL\n)\n\n      \nGROUP\n \nBY\n \nt0\n.\nemail\n)\n \nAS\n \nt0\n)\n \nAS\n \nt2\n\n\nWHERE\n \n((\nt1\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n\n  \nAND\n \n((\nt2\n.\nres0\n)\n=\n(\nt0\n.\nemail\n))\n \n-- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(User {_userEmail = \nbetty@example.com\n,\n       _userFirstName = \nBetty\n,\n       _userLastName = \nJones\n,\n       _userPassword = \n82b054bd83ffad9b6cf8bdb98ce3cc2f\n},1,\n                                                           1) --\n(User {_userEmail = \njames@example.com\n,\n       _userFirstName = \nJames\n,\n       _userLastName = \nSmith\n,\n       _userPassword = \nb4cc344d25a2efe540adbf2678e2304c\n},2,\n                                                           1) --\n(User {_userEmail = \nsam@example.com\n,\n       _userFirstName = \nSam\n,\n       _userLastName = \nTaylor\n,\n       _userPassword = \n332532dcfaa1cbf61e2a266bd723612c\n},1,\n                                                           1) --\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nConclusion\n\n\nThis tutorial completes our sequence on creating a shopping cart. Throughout the\ntutorials, we saw how to create tables using regular Haskell data types, how to\nlink those tables up using relations, how to query tables using both the monadic\ninterface and the list-like functions on queries. We saw ha few examples of\nusing beam to generate advanced queries. More information on the Beam API is\nhavailable on \nhackage\n. Happy beaming!\n\n\nBeam is a work in progress. Please submit bugs and patches\non \nGitHub\n.", 
            "title": "Part 3"
        }, 
        {
            "location": "/tutorials/tutorial3/#introduction", 
            "text": "In teh last part, we extended our shopping cart database to let users add\nmultiple addresses. We saw how to establish one-to-many relations between two\ntables, and how to use the monadic query interface to write SQL JOINs. In this\ninstallment, we'll be adding support for products and orders to our database\nschema. We'll see how to use an intermediary table to create many-to-many\nrelations and how to write LEFT JOINs. Finally, we'll see how to use  Nullable \nto create optional foreign key references.", 
            "title": "Introduction"
        }, 
        {
            "location": "/tutorials/tutorial3/#creating-tables-is-easy-now", 
            "text": "Let's create our products table. By now, the pattern for adding a new table to\nthe schema should be pretty familiar, so I'm going to skip the explanation.  data   ProductT   f   =   Product \n                 {   _productId            ::   C   f   ( Auto   Int ) \n                 ,   _productTitle         ::   C   f   Text \n                 ,   _productDescription   ::   C   f   Text \n                 ,   _productPrice         ::   C   f   Int   {- Price in cents -}   } \n                   deriving   Generic  type   Product   =   ProductT   Identity  deriving   instance   Show   Product  instance   Table   ProductT   where \n   data   PrimaryKey   ProductT   f   =   ProductId   ( Columnar   f   ( Auto   Int )) \n                                deriving   Generic \n   primaryKey   =   ProductId   .   _productId  instance   Beamable   ProductT  instance   Beamable   ( PrimaryKey   ProductT )   For orders, we want to store an id, date created, and the user who made the\norder. We'd also like to create an optional link to a shipping information\ntable. When the shipping information is created, we'll fill in the shipping\ninformation in the order. In order to create the optional reference, we're going\nto use the  Nullable  tag modifier to modify the column tag.  Nullable  will\nturn all fields of type  x  into  Maybe x . Note that we could also create this\nrelation by installing a primary key on the shipping info table, and this is\narguably the better option. However, we'll go with a nullable foreign key here\nto show the full breadth of beam's features, and because this sort of relation\nexists in many existing databases.  import   Data.Time  deriving   instance   Show   ( PrimaryKey   AddressT   Identity )  data   OrderT   f   =   Order \n               {   _orderId        ::   Columnar   f   ( Auto   Int ) \n               ,   _orderDate      ::   Columnar   f   LocalTime \n               ,   _orderForUser   ::   PrimaryKey   UserT   f \n               ,   _orderShipToAddress   ::   PrimaryKey   AddressT   f \n               ,   _orderShippingInfo   ::   PrimaryKey   ShippingInfoT   ( Nullable   f )   } \n                 deriving   Generic  type   Order   =   OrderT   Identity  deriving   instance   Show   Order  instance   Table   OrderT   where \n     data   PrimaryKey   OrderT   f   =   OrderId   ( Columnar   f   ( Auto   Int )) \n                                deriving   Generic \n     primaryKey   =   OrderId   .   _orderId  instance   Beamable   OrderT  instance   Beamable   ( PrimaryKey   OrderT )  data   ShippingCarrier   =   USPS   |   FedEx   |   UPS   |   DHL \n                        deriving   ( Show ,   Read ,   Eq ,   Ord ,   Enum )  data   ShippingInfoT   f   =   ShippingInfo \n                      {   _shippingInfoId               ::   Columnar   f   ( Auto   Int ) \n                      ,   _shippingInfoCarrier          ::   Columnar   f   ShippingCarrier \n                      ,   _shippingInfoTrackingNumber   ::   Columnar   f   Text   } \n                        deriving   Generic  type   ShippingInfo   =   ShippingInfoT   Identity  deriving   instance   Show   ShippingInfo  instance   Table   ShippingInfoT   where \n     data   PrimaryKey   ShippingInfoT   f   =   ShippingInfoId   ( Columnar   f   ( Auto   Int )) \n                                       deriving   Generic \n     primaryKey   =   ShippingInfoId   .   _shippingInfoId  instance   Beamable   ShippingInfoT  instance   Beamable   ( PrimaryKey   ShippingInfoT )  deriving   instance   Show   ( PrimaryKey   ShippingInfoT   ( Nullable   Identity ))   In the above example, we show how to use a custom data type as a beam column.\nRecall that beam lets you store any Haskell type in a  Columnar . However, at\nsome point, we will need to demonstrate to SQLite how to store values of type ShippingCarrier . We will come back to this later.  We would also like to be able to associate a list of products with each order as\nline items. To do this we will create a table with two foreign keys. This table\nwill establish a many-to-many relationship between orders and products.  deriving   instance   Show   ( PrimaryKey   OrderT   Identity )  deriving   instance   Show   ( PrimaryKey   ProductT   Identity )  data   LineItemT   f   =   LineItem \n                  {   _lineItemInOrder      ::   PrimaryKey   OrderT   f \n                  ,   _lineItemForProduct   ::   PrimaryKey   ProductT   f \n                  ,   _lineItemQuantity     ::   Columnar   f   Int   } \n                    deriving   Generic  type   LineItem   =   LineItemT   Identity  deriving   instance   Show   LineItem  instance   Table   LineItemT   where \n     data   PrimaryKey   LineItemT   f   =   LineItemId   ( PrimaryKey   OrderT   f )   ( PrimaryKey   ProductT   f ) \n                                   deriving   Generic \n     primaryKey   =   LineItemId   $   _lineItemInOrder   *   _lineItemForProduct  instance   Beamable   LineItemT  instance   Beamable   ( PrimaryKey   LineItemT )    Tip  We used the  Applicative  instance for  (- ) a  above to write the primaryKey  function. The  Applicative ((- ) a)  instance operates like an\nunwrapper  Reader  of  a . The applicative actions are then functions from a -  x  that inject values from the  a  into the applicative bind.   Now we'll add all these tables to our database.  -- Some convenience lenses  LineItem   _   _   ( LensFor   lineItemQuantity )   =   tableLenses  Product   ( LensFor   productId )   ( LensFor   productTitle )   ( LensFor   productDescription )   ( LensFor   productPrice )   =   tableLenses  data   ShoppingCartDb   f   =   ShoppingCartDb \n                       {   _shoppingCartUsers           ::   f   ( TableEntity   UserT ) \n                       ,   _shoppingCartUserAddresses   ::   f   ( TableEntity   AddressT ) \n                       ,   _shoppingCartProducts        ::   f   ( TableEntity   ProductT ) \n                       ,   _shoppingCartOrders          ::   f   ( TableEntity   OrderT ) \n                       ,   _shoppingCartShippingInfos   ::   f   ( TableEntity   ShippingInfoT ) \n                       ,   _shoppingCartLineItems       ::   f   ( TableEntity   LineItemT )   } \n                         deriving   Generic  instance   Database   ShoppingCartDb  ShoppingCartDb   ( TableLens   shoppingCartUsers )   ( TableLens   shoppingCartUserAddresses ) \n                ( TableLens   shoppingCartProducts )   ( TableLens   shoppingCartOrders ) \n                ( TableLens   shoppingCartShippingInfos )   ( TableLens   shoppingCartLineItems )   =   dbLenses  shoppingCartDb   ::   DatabaseSettings   be   ShoppingCartDb  shoppingCartDb   =   defaultDbSettings   ` withDbModification ` \n                  dbModification   { \n                    _shoppingCartUserAddresses   = \n                      modifyTable   ( \\ _   -   addresses )   $ \n                      tableModification   { \n                        _addressLine1   =   fieldNamed   address1 , \n                        _addressLine2   =   fieldNamed   address2 \n                      }, \n                    _shoppingCartProducts   =   modifyTable   ( \\ _   -   products )   tableModification , \n                    _shoppingCartOrders   =   modifyTable   ( \\ _   -   orders )   $ \n                                          tableModification   { \n                                            _orderShippingInfo   =   ShippingInfoId   shipping_info__id \n                                          }, \n                    _shoppingCartShippingInfos   =   modifyTable   ( \\ _   -   shipping_info )   $ \n                                                 tableModification   { \n                                                   _shippingInfoId   =   id , \n                                                   _shippingInfoCarrier   =   carrier , \n                                                   _shippingInfoTrackingNumber   =   tracking_number \n                                                 }, \n                    _shoppingCartLineItems   =   modifyTable   ( \\ _   -   line_items )   tableModification \n                  }", 
            "title": "Creating tables is easy now"
        }, 
        {
            "location": "/tutorials/tutorial3/#fixtures", 
            "text": "Let's put some sample data into a new database.  conn   -   open   shoppingcart3.db  execute_   conn   CREATE TABLE cart_users (email VARCHAR NOT NULL, first_name VARCHAR NOT NULL, last_name VARCHAR NOT NULL, password VARCHAR NOT NULL, PRIMARY KEY( email ));  execute_   conn   CREATE TABLE addresses ( id INTEGER PRIMARY KEY AUTOINCREMENT, address1 VARCHAR NOT NULL, address2 VARCHAR, city VARCHAR NOT NULL, state VARCHAR NOT NULL, zip VARCHAR NOT NULL, for_user__email VARCHAR NOT NULL );  execute_   conn   CREATE TABLE products ( id INTEGER PRIMARY KEY AUTOINCREMENT, title VARCHAR NOT NULL, description VARCHAR NOT NULL, price INT NOT NULL );  execute_   conn   CREATE TABLE orders ( id INTEGER PRIMARY KEY AUTOINCREMENT, date TIMESTAMP NOT NULL, for_user__email VARCHAR NOT NULL, ship_to_address__id INT NOT NULL, shipping_info__id INT);  execute_   conn   CREATE TABLE shipping_info ( id INTEGER PRIMARY KEY AUTOINCREMENT, carrier VARCHAR NOT NULL, tracking_number VARCHAR NOT NULL);  execute_   conn   CREATE TABLE line_items (item_in_order__id INTEGER NOT NULL, item_for_product__id INTEGER NOT NULL, item_quantity INTEGER NOT NULL)   Let's put some sample data into our database. Below, we will use the beam-sqlite  functions  insertReturning  and  runInsertReturningList  to insert\nrows  and  retrieve the inserted rows from the database. This will let us see\nwhat values the auto-incremented  id  columns took on, which will allow us to\ncreate references to these inserted rows.  let   users @ [ james ,   betty ,   sam ]   = \n           [   User   james@example.com   James   Smith    b4cc344d25a2efe540adbf2678e2304c   {- james -} \n           ,   User   betty@example.com   Betty   Jones    82b054bd83ffad9b6cf8bdb98ce3cc2f   {- betty -} \n           ,   User   sam@example.com     Sam     Taylor   332532dcfaa1cbf61e2a266bd723612c   {- sam -}   ] \n     addresses   =   [   Address   ( Auto   Nothing )   123 Little Street   Nothing   Boston   MA   12345   ( pk   james ) \n\n                 ,   Address   ( Auto   Nothing )   222 Main Street   ( Just   Ste 1 )   Houston   TX   8888   ( pk   betty ) \n                 ,   Address   ( Auto   Nothing )   9999 Residence Ave   Nothing   Sugarland   TX   8989   ( pk   betty )   ] \n\n     products   =   [   Product   ( Auto   Nothing )   Red Ball   A bright red, very spherical ball   1000 \n                ,   Product   ( Auto   Nothing )   Math Textbook   Contains a lot of important math theorems and formulae   2500 \n                ,   Product   ( Auto   Nothing )   Intro to Haskell   Learn the best programming language in the world   3000 \n                ,   Product   ( Auto   Nothing )   Suitcase   A hard durable suitcase   15000   ]  ( jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ,   redBall ,   mathTextbook ,   introToHaskell ,   suitcase )   - \n   withDatabaseDebug   putStrLn   conn   $   do \n     runInsert   $   insert   ( shoppingCartDb   ^.   shoppingCartUsers )   $ \n                 insertValues   users \n\n     [ jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartUserAddresses )   $   insertValues   addresses \n\n     [ redBall ,   mathTextbook ,   introToHaskell ,   suitcase ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartProducts )   $   insertValues   products \n\n     pure   (   jamesAddress1 ,   bettyAddress1 ,   bettyAddress2 ,   redBall ,   mathTextbook ,   introToHaskell ,   suitcase   )   Now, if we take a look at one of the returned addresses, like  jamesAddress1 ,\nwe see it has had it's  Auto  field assigned correctly.  Prelude   Database . Beam   Database . Beam . Sqlite   Data . Time   Database . SQLite . Simple   Data . Text   Lens . Micro   jamesAddress1  Address   { _addressId   =   Auto   { unAuto   =   Just   1 },   _addressLine1   =   123 Little Street ,   _addressLine2   =   Nothing ,   _addressCity   =   Boston ,   _addressState   =   MA ,   _addressZip   =   12345 ,   _addressForUser   =   UserId   james@example.com }    Note  insertReturning  and  runInsertReturningList  are from the  beam-sqlite \npackage. They emulate the  INSERT .. RETURNING ..  functionatily you may\nexpect in other databases. Because this emulation is backend-specific it is\npart of the backend package, rather than  beam-core .  Other backends may have similar functionality. Please refer to the backend\npackage you're interested in for more information, as well as notes on the\nimplementation.", 
            "title": "Fixtures"
        }, 
        {
            "location": "/tutorials/tutorial3/#marshalling-a-custom-type", 
            "text": "Now we can insert shipping information. Of course, the shipping information\ncontains the  ShippingCarrier  enumeration.  bettyShippingInfo   -  \n   withDatabaseDebug   putStrLn   conn   $   do \n     [ bettyShippingInfo ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartShippingInfos )   $ \n       insertValues   [   ShippingInfo   ( Auto   Nothing )   USPS   12345790ABCDEFGHI   ] \n     pure   bettyShippingInfo   If you run this, you'll get an error from GHCi.  interactive : 263 : 7 :  error : \n     *  No instance  for   ( Database.Beam.Backend.Types.FromBackendRow\n                         Sqlite ShippingCarrier ) \n        arising from a use of  runInsertReturningList \n     *  In a stmt of a  do  block : \n         [ bettyShippingInfo ]   -  runInsertReturningList\n                                $  insertReturning  ( shoppingCartDb  ^ .  shoppingCartShippingInfos ) \n                                  $  insertValues\n                                      [ ShippingInfo  ( Auto Nothing )  USPS  12345790ABCDEFGHI ] \n      In the second argument of  ($) ,  namely\n         do { [bettyShippingInfo]  - runInsertReturningList                                       $ insertReturning (shoppingCartDb ^. shoppingCartShippingInfos)                                         $ insertValues                                             [ShippingInfo (Auto Nothing) USPS  12345790ABCDEFGHI ];                pure bettyShippingInfo }        In the first argument of  GHC.GHCi.ghciStepIO  :: \n                                  forall a. IO a  -  IO a , namely           withDatabaseDebug putStrLn conn\n          $  do  {   [ bettyShippingInfo ]   -  runInsertReturningList\n                                        $  insertReturning\n                                            ( shoppingCartDb  ^ .  shoppingCartShippingInfos ) \n                                          $  insertValues\n                                              [ ShippingInfo  ( Auto Nothing )  USPS  12345790ABCDEFGHI ]; \n                pure bettyShippingInfo  }  interactive :265:7: error:      * No instance for (Database.Beam.Backend.SQL.SQL92.HasSqlValueSyntax                           SqliteValueSyntax ShippingCarrier)          arising from a use of  insertValues      * In the second argument of  ( $ ) , namely           insertValues\n            [ ShippingInfo  ( Auto Nothing )  USPS  12345790ABCDEFGHI ] \n      In the second argument of  ($) ,  namely\n         insertReturning (shoppingCartDb ^. shoppingCartShippingInfos)           $ insertValues               [ShippingInfo (Auto Nothing) USPS  12345790ABCDEFGHI ] \n      In a stmt of a  do  block : \n         [ bettyShippingInfo ]   -  runInsertReturningList\n                                $  insertReturning  ( shoppingCartDb  ^ .  shoppingCartShippingInfos ) \n                                  $  insertValues\n                                      [ ShippingInfo  ( Auto Nothing )  USPS  12345790ABCDEFGHI ]   These errors are because there's no way to express a  ShippingCarrier  in the\nbackend syntax. We can fix this by writing instances for beam. We can re-use the\nfunctionality we already have for  String .  The  HasSqlValueSyntax  class tells us how to convert a Haskell value into a\ncorresponding backend value.  import   Database.Beam.Backend.SQL  : set   - XUndecidableInstances  instance   HasSqlValueSyntax   be   String   =   HasSqlValueSyntax   be   ShippingCarrier   where \n   sqlValueSyntax   =   autoSqlValueSyntax   The  FromBackendRow  class tells us how to convert a value from the database\ninto a corresponding Haskell value. Most often, it is enough to declare an empty\ninstance, so long as there is a backend-specific instance for unmarshaling your\ndata type.  For example,  Prelude   Database . Beam   Database . Beam . Sqlite   Data . Time   Database . SQLite . Simple   Data . Text   Lens . Micro   import   Database.Beam.Backend  Prelude   Database . Beam   Database . Beam . Sqlite   Data . Time   Database . SQLite . Simple   Data . Text   Lens . Micro   Database . Beam . Backend   : set   - XMultiParamTypeClasses  Prelude   Database . Beam   Database . Beam . Sqlite   Data . Time   Database . SQLite . Simple   Data . Text   Lens . Micro   Database . Beam . Backend   instance   FromBackendRow   Sqlite   ShippingCarrier  interactive : 271 : 10 :   error : \n     *   No   instance   for   ( Database . SQLite . Simple . FromField . FromField \n                          ShippingCarrier ) \n         arising   from   a   use   of   Database . Beam . Backend . Types .$ dmfromBackendRow \n     *   In   the   expression : \n         Database . Beam . Backend . Types .$ dmfromBackendRow \n           @ Sqlite   @ ShippingCarrier \n       In   an   equation   for   fromBackendRow : \n           fromBackendRow \n             =   Database . Beam . Backend . Types .$ dmfromBackendRow \n                 @ Sqlite   @ ShippingCarrier \n       In   the   instance   declaration   for \n         FromBackendRow   Sqlite   ShippingCarrier   Let's see if we can write  Database.SQLite.Simple.FromField.FromField  instance\nfor  ShippingCarrier  and then let's try re-instantiating  FromBackendRow .  import   Database.SQLite.Simple.FromField  import   Text.Read  instance   FromField   ShippingCarrier   where \n   fromField   f   =   do   x   -   readMaybe   $   fromField   f \n                    case   x   of \n                      Nothing   -   returnError   ConversionFailed   f   Could not  read  value for  ShippingCarrier \n                      Just   x   -   pure   x  instance   FromBackendRow   be   ShippingCarrier   Now, if we try to insert the shipping info again, it works.  bettyShippingInfo   -  \n   withDatabaseDebug   putStrLn   conn   $   do \n     [ bettyShippingInfo ]   - \n       runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartShippingInfos )   $ \n       insertValues   [   ShippingInfo   ( Auto   Nothing )   USPS   12345790ABCDEFGHI   ] \n     pure   bettyShippingInfo   And if we look at the value of  bettyShippingInfo ,  ShippingCarrier  has been\nstored correctly.    bettyShippingInfo  ShippingInfo   { _shippingInfoId   =   Auto   { unAuto   =   Just   1 },   _shippingInfoCarrier   =   USPS ,   _shippingInfoTrackingNumber   =   12345790ABCDEFGHI }   Now, let's insert some orders that just came in. In the previous  INSERT \nexamples, we used  insertValues  to insert arbitrary values into the database.\nNow, we want to insert transactions with the current database timestamp (i.e., CURRENT_TIMESTAMP  in SQL). We can insert rows containing arbitrary expressions\nusing the  insertExpressions  function. As you can see, the resulting rows have\na timestamp set by the database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Console \n         \n    \n         \n    \n         \n            \n         \n             [   jamesOrder1 ,   bettyOrder1 ,   jamesOrder2   ]   - \n   withDatabaseDebug   putStrLn   conn   $   do \n     runInsertReturningList   $ \n       insertReturning   ( shoppingCartDb   ^.   shoppingCartOrders )   $ \n       insertExpressions   $ \n       [   Order   ( val_   ( Auto   Nothing ))   currentTimestamp_   ( val_   ( pk   james ))   ( val_   ( pk   jamesAddress1 ))   nothing_  \n       ,   Order   ( val_   ( Auto   Nothing ))   currentTimestamp_   ( val_   ( pk   betty ))   ( val_   ( pk   bettyAddress1 ))   ( just_   ( val_   ( pk   bettyShippingInfo )))  \n       ,   Order   ( val_   ( Auto   Nothing ))   currentTimestamp_   ( val_   ( pk   james ))   ( val_   ( pk   jamesAddress1 ))   nothing_   ]  print   jamesOrder1  print   bettyOrder1  print   jamesOrder2  \n\n         \n    \n         \n             INSERT   INTO   orders ( id , \n                      date , \n                      for_user__email , \n                      ship_to_address__id , \n                      shipping_info__id )  VALUES   ( NULL , \n         CURRENT_TIMESTAMP , \n         ? , \n         ? , \n         NULL ),   ( NULL , \n                 CURRENT_TIMESTAMP , \n                 ? , \n                 ? , \n                 ? ),   ( NULL , \n                      CURRENT_TIMESTAMP , \n                      ? , \n                      ? , \n                      NULL )   -- With values: [SQLText  james@example.com ,SQLInteger 1,SQLText  betty@example.com ,SQLInteger 2,SQLInteger 1,SQLText  james@example.com ,SQLInteger 1]  \n\n         \n    \n         \n             Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:27,                                                                          _orderForUser = UserId  james@example.com ,                                                                          _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),                                                                          _orderShippingInfo = ShippingInfoId Nothing} --  Order {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:27,                                                                          _orderForUser = UserId  betty@example.com ,                                                                          _orderShipToAddress = AddressId (Auto {unAuto = Just 2}),                                                                          _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))} --  Order {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:27,                                                                          _orderForUser = UserId  james@example.com ,                                                                          _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),                                                                          _orderShippingInfo = ShippingInfoId Nothing} --  \n\n         \n    \n         \n    \n                 \n                      Finally, let's add some line items  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n    \n         \n            \n         \n             let   lineItems   =   [   LineItem   ( pk   jamesOrder1 )   ( pk   redBall )   10 \n                 ,   LineItem   ( pk   jamesOrder1 )   ( pk   mathTextbook )   1 \n                 ,   LineItem   ( pk   jamesOrder1 )   ( pk   introToHaskell )   4 \n\n                 ,   LineItem   ( pk   bettyOrder1 )   ( pk   mathTextbook )   3 \n                 ,   LineItem   ( pk   bettyOrder1 )   ( pk   introToHaskell )   3 \n\n                 ,   LineItem   ( pk   jamesOrder2 )   ( pk   mathTextbook )   1   ]  withDatabaseDebug   putStrLn   conn   $   do \n   runInsert   $   insert   ( shoppingCartDb   ^.   shoppingCartLineItems )   $ \n     insertValues   lineItems  \n\n         \n    \n         \n             INSERT   INTO   line_items ( item_in_order__id , \n                          item_for_product__id , \n                          item_quantity )  VALUES   ( ? , \n         ? , \n         ? ),   ( ? , \n              ? , \n              ? ),   ( ? , \n                   ? , \n                   ? ),   ( ? , \n                        ? , \n                        ? ),   ( ? , \n                             ? , \n                             ? ),   ( ? , \n                                  ? , \n                                  ? )   -- With values: [SQLInteger 1,SQLInteger 1,SQLInteger 10,SQLInteger 1,SQLInteger 2,SQLInteger 1,SQLInteger 1,SQLInteger 3,SQLInteger 4,SQLInteger 2,SQLInteger 2,SQLInteger 3,SQLInteger 2,SQLInteger 3,SQLInteger 3,SQLInteger 3,SQLInteger 2,SQLInteger 1]  \n\n         \n    \n         \n    \n                 \n                      Phew! Let's write some queries on this data!", 
            "title": "Marshalling a custom type"
        }, 
        {
            "location": "/tutorials/tutorial3/#would-you-like-some-left-joins-with-that", 
            "text": "Suppose we want to do some analytics on our users, and so we want to know how many orders each user\nhas made in our system. We can write a query to list every user along with the orders they've\nmade. We can use  leftJoin_  to include all users in our result set, even those who have no\norders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             usersAndOrders   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n       pure   ( user ,   order )  mapM_   print   usersAndOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . id   AS   res4 , \n        t1 . date   AS   res5 , \n        t1 . for_user__email   AS   res6 , \n        t1 . ship_to_address__id   AS   res7 , \n        t1 . shipping_info__id   AS   res8  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId (Auto {unAuto = Just 1}), _orderShippingInfo = ShippingInfoId Nothing})) --\n(User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId  james@example.com , _orderShipToAddress = AddressId (Auto {unAuto = Just 1}), _orderShippingInfo = ShippingInfoId Nothing})) --\n(User {_userEmail =  betty@example.com ,\n       _userFirstName =  Betty ,\n       _userLastName =  Jones ,\n       _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },Just (\n                                                                 Order {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:34, _orderForUser = UserId  betty@example.com , _orderShipToAddress = AddressId (Auto {unAuto = Just 2}), _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))})) --\n(User {_userEmail =  sam@example.com ,\n       _userFirstName =  Sam ,\n       _userLastName =  Taylor ,\n       _userPassword =  332532dcfaa1cbf61e2a266bd723612c },Nothing) -- \n\n         \n    \n         \n    \n                 \n                      Notice that sam is included in the result set, even though he doesn't have any\nassociated orders. Instead of a  Just (Order ..) ,  Nothing  is returned\ninstead.  Next, perhaps our marketing team wanted to send e-mails out to all users with no\norders. We can use  isNothing_  or  isJust_  to determine the status if a\nnullable table or  QExpr s (Maybe x) . The following query uses  isNothing_  to\nfind users who have no associated orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             usersWithNoOrders   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n       guard_   ( isNothing_   order ) \n       pure   user  mapM_   print   usersWithNoOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  WHERE   ((((( t1 . id )   IS   NULL ) \n          AND   (( t1 . date )   IS   NULL )) \n         AND   (( t1 . for_user__email )   IS   NULL )) \n        AND   (( t1 . ship_to_address__id )   IS   NULL )) \n   AND   (( t1 . shipping_info__id )   IS   NULL )   -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  sam@example.com ,\n      _userFirstName =  Sam ,\n      _userLastName =  Taylor ,\n      _userPassword =  332532dcfaa1cbf61e2a266bd723612c } -- \n\n         \n    \n         \n    \n                 \n                      We see that beam generates a sensible SQL  SELECT  and  WHERE  clause.  We can also use the  exists_  combinator to utilize the SQL  EXISTS  clause.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             usersWithNoOrders   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $   do \n       user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n       guard_   ( not_   ( exists_   ( filter_   ( \\ order   -   _orderForUser   order   ` references_ `   user )   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))))) \n       pure   user  mapM_   print   usersWithNoOrders  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3  FROM   cart_users   AS   t0  WHERE   NOT ( EXISTS \n             ( SELECT   t0 . id   AS   res0 ,   t0 . date   AS   res1 ,   t0 . for_user__email   AS   res2 ,   t0 . ship_to_address__id   AS   res3 ,   t0 . shipping_info__id   AS   res4 \n              FROM   orders   AS   t0 \n              WHERE   ( t0 . for_user__email ) = ( t0 . email )))   -- With values: []  \n\n         \n    \n         \n             User {_userEmail =  sam@example.com ,\n      _userFirstName =  Sam ,\n      _userLastName =  Taylor ,\n      _userPassword =  332532dcfaa1cbf61e2a266bd723612c } -- \n\n         \n    \n         \n    \n                 \n                      Now suppose we wanted to do some analysis on the orders themselves. To start, we\nwant to get the orders sorted by their portion of revenue. We can use aggregate_  to list every order and the total amount of all products in that\norder.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             ordersWithCostOrdered   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     orderBy_   ( \\ ( order ,   total )   -   desc_   total )   $ \n     aggregate_   ( \\ ( order ,   lineItem ,   product )   - \n                    ( group_   order ,   sum_   ( lineItem   ^.   lineItemQuantity   *   product   ^.   productPrice )))   $ \n     do   lineItem   -   all_   ( shoppingCartDb   ^.   shoppingCartLineItems ) \n        order      -   related_   ( shoppingCartDb   ^.   shoppingCartOrders )   ( _lineItemInOrder   lineItem ) \n        product    -   related_   ( shoppingCartDb   ^.   shoppingCartProducts )   ( _lineItemForProduct   lineItem ) \n        pure   ( order ,   lineItem ,   product )  mapM_   print   ordersWithCostOrdered  \n\n         \n    \n         \n             SELECT   t1 . id   AS   res0 , \n        t1 . date   AS   res1 , \n        t1 . for_user__email   AS   res2 , \n        t1 . ship_to_address__id   AS   res3 , \n        t1 . shipping_info__id   AS   res4 , \n        SUM (( t0 . item_quantity )   *   ( t2 . price ))   AS   res5  FROM   line_items   AS   t0  INNER   JOIN   orders   AS   t1   ON   ( t0 . item_in_order__id ) = ( t1 . id )  INNER   JOIN   products   AS   t2   ON   ( t0 . item_for_product__id ) = ( t2 . id )  GROUP   BY   t1 . id , \n          t1 . date , \n          t1 . for_user__email , \n          t1 . ship_to_address__id , \n          t1 . shipping_info__id  ORDER   BY   SUM (( t0 . item_quantity )   *   ( t2 . price ))   DESC   -- With values: []  \n\n         \n    \n         \n             (\n Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:49,\n                                                                         _orderForUser = UserId  james@example.com ,\n                                                                         _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                         _orderShippingInfo = ShippingInfoId Nothing},24500) --\n(\n                                                                                                                                Order {_orderId = Auto {unAuto = Just 2}, _orderDate = 2017-05-09 21:37:49,\n                                                                                                                                                                                                        _orderForUser = UserId  betty@example.com ,\n                                                                                                                                                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 2}),\n                                                                                                                                                                                                        _orderShippingInfo = ShippingInfoId (Just (Auto {unAuto = Just 1}))},16500) --\n(\n                                                                                                                                                                                                                                                                                       Order {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:49,\n                                                                                                                                                                                                                                                                                                                                                               _orderForUser = UserId  james@example.com ,\n                                                                                                                                                                                                                                                                                                                                                               _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                                                                                                                                                                                                                                                                                                               _orderShippingInfo = ShippingInfoId Nothing},2500) -- \n\n         \n    \n         \n    \n                 \n                      We can also get the total amount spent by each user, even including users with no orders. Notice\nthat we have to use  maybe_  below in order to handle the fact that some tables have been introduced\ninto our query with a left join.  maybe_  is to  QExpr  what  maybe  is to normal Haskell\nvalues.  maybe_  is polymorphic to either  QExpr s or full on tables of  QExpr s. For our purposes,\nthe type of  maybe_  is  maybe_   ::   QExpr   s   a   -   ( QExpr   s   b   -   QExpr   s   a )   -   QExpr   s   ( Maybe   b )   -   QExpr   s   a   With that in mind, we can write the query to get the total spent by user  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             allUsersAndTotals   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     orderBy_   ( \\ ( user ,   total )   -   desc_   total )   $ \n     aggregate_   ( \\ ( user ,   lineItem ,   product )   - \n                    ( group_   user ,   sum_   ( maybe_   0   id   ( _lineItemQuantity   lineItem )   *   maybe_   0   id   ( product   ^.   productPrice ))))   $ \n     do   user       -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        order      -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                              ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n        lineItem   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartLineItems )) \n                              ( \\ lineItem   -   maybe_   ( val_   False )   ( \\ order   -   _lineItemInOrder   lineItem   ` references_ `   order )   order ) \n        product    -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartProducts )) \n                              ( \\ product   -   maybe_   ( val_   False )   ( \\ lineItem   -   _lineItemForProduct   lineItem   ` references_ `   product )   lineItem ) \n        pure   ( user ,   lineItem ,   product )  mapM_   print   allUsersAndTotals  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        SUM (( CASE \n                 WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                 ELSE   ? \n             END )   *   ( CASE \n                         WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                         ELSE   ? \n                     END ))   AS   res4  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  LEFT   JOIN   line_items   AS   t2   ON   CASE \n                                       WHEN   ((((( t1 . id )   IS   NOT   NULL ) \n                                               AND   (( t1 . date )   IS   NOT   NULL )) \n                                              AND   (( t1 . for_user__email )   IS   NOT   NULL )) \n                                             AND   (( t1 . ship_to_address__id )   IS   NOT   NULL )) \n                                            AND   (( t1 . shipping_info__id )   IS   NOT   NULL )   THEN   ( t2 . item_in_order__id ) = ( t1 . id ) \n                                       ELSE   ? \n                                   END  LEFT   JOIN   products   AS   t3   ON   CASE \n                                     WHEN   ((( t2 . item_in_order__id )   IS   NOT   NULL ) \n                                           AND   (( t2 . item_for_product__id )   IS   NOT   NULL )) \n                                          AND   (( t2 . item_quantity )   IS   NOT   NULL )   THEN   ( t2 . item_for_product__id ) = ( t3 . id ) \n                                     ELSE   ? \n                                 END  GROUP   BY   t0 . email , \n          t0 . first_name , \n          t0 . last_name , \n          t0 . password  ORDER   BY   SUM (( CASE \n                   WHEN   ( t2 . item_quantity )   IS   NOT   NULL   THEN   t2 . item_quantity \n                   ELSE   ? \n               END )   *   ( CASE \n                           WHEN   ( t3 . price )   IS   NOT   NULL   THEN   t3 . price \n                           ELSE   ? \n                       END ))   DESC   -- With values: [SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0,SQLInteger 0]  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com ,\n       _userFirstName =  Betty ,\n       _userLastName =  Jones ,\n       _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },16500) --\n(User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },0) --\n(User {_userEmail =  sam@example.com ,\n       _userFirstName =  Sam ,\n       _userLastName =  Taylor ,\n       _userPassword =  332532dcfaa1cbf61e2a266bd723612c },0) --", 
            "title": "Would you like some left joins with that?"
        }, 
        {
            "location": "/tutorials/tutorial3/#queries-with-nullable-foreign-keys", 
            "text": "Recall that our schema contains a nullable foreign key from  OrderT  to  ShippingInfoT . Above,\nwe've seen how  leftJoin_  introduces nullable tables into our queries. Below, we'll see how to use\nnullable primary keys to optionally include information.  Suppose we want to find all orders who have not been shipped. We can do this by simply writing a query over the orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             allUnshippedOrders   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     filter_   ( isNothing_   .   _orderShippingInfo )   $ \n     all_   ( shoppingCartDb   ^.   shoppingCartOrders )  mapM_   print   allUnshippedOrders  \n\n         \n    \n         \n             SELECT   t0 . id   AS   res0 , \n        t0 . date   AS   res1 , \n        t0 . for_user__email   AS   res2 , \n        t0 . ship_to_address__id   AS   res3 , \n        t0 . shipping_info__id   AS   res4  FROM   orders   AS   t0  WHERE   ( t0 . shipping_info__id )   IS   NULL   -- With values: []  \n\n         \n    \n         \n             Order {_orderId = Auto {unAuto = Just 1}, _orderDate = 2017-05-09 21:37:59,\n                                                                        _orderForUser = UserId  james@example.com ,\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} --\nOrder {_orderId = Auto {unAuto = Just 3}, _orderDate = 2017-05-09 21:37:59,\n                                                                        _orderForUser = UserId  james@example.com ,\n                                                                        _orderShipToAddress = AddressId (Auto {unAuto = Just 1}),\n                                                                        _orderShippingInfo = ShippingInfoId Nothing} -- \n\n         \n    \n         \n    \n                 \n                      Let's count up all shipped and unshipped orders by user, including users who have no orders.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     aggregate_   ( \\ ( user ,   order )   - \n                    let   ShippingInfoId   shippingInfoId   =   _orderShippingInfo   order \n                    in   (   group_   user \n                       ,   as_   @ Int   $   count_   ( as_   @ ( Maybe   Int )   ( maybe_   ( just_   1 )   ( \\ _   -   nothing_ )   shippingInfoId )) \n                       ,   as_   @ Int   $   count_   shippingInfoId   )   )   $ \n     do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n        order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders ))   ( \\ order   -   _orderForUser   order   ` references_ `   user ) \n        pure   ( user ,   order )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        COUNT ( CASE \n                  WHEN   ( t1 . shipping_info__id )   IS   NOT   NULL   THEN   NULL \n                  ELSE   ? \n              END )   AS   res4 , \n        COUNT ( t1 . shipping_info__id )   AS   res5  FROM   cart_users   AS   t0  LEFT   JOIN   orders   AS   t1   ON   ( t1 . for_user__email ) = ( t0 . email )  GROUP   BY   t0 . email , \n          t0 . first_name , \n          t0 . last_name , \n          t0 . password   -- With values: [SQLInteger 1]  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com ,\n       _userFirstName =  Betty ,\n       _userLastName =  Jones ,\n       _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },0,\n                                                           1) --\n(User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,\n                                                           0) --\n(User {_userEmail =  sam@example.com ,\n       _userFirstName =  Sam ,\n       _userLastName =  Taylor ,\n       _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,\n                                                           0) -- \n\n         \n    \n         \n    \n                 \n                      Uh-oh! There's an error in the result set! Sam is reported as having one\nunshipped order, instead of zero.  Here we hit one of the limitations of beam's mapping to SQL, and really one of\nthe limitations of SQL itself. Namely, the NULL in the result rows for Sam is\nnot distinguished from the NULL in the shipping info key itself. Beam however\ndoes make the distinction.  When beam deserializes a  NULL  in a  Maybe  field, the outermost  Maybe  is the\none populated with  Nothing . Thus it is impossible to retrieve a value like Just Nothing  from the database using the default serializers and\ndeserializers. In general, it's best to avoid highly nested  Maybe s in your\nqueries because it makes them more difficult to understand.  One way to work around this issue in the above query is to use subselects.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n\n        ( userEmail ,   unshippedCount )   - \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isNothing_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n\n        guard_   ( userEmail   ` references_ `   user ) \n\n        ( userEmail ,   shippedCount )   - \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isJust_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n        guard_   ( userEmail   ` references_ `   user ) \n\n        pure   ( user ,   unshippedCount ,   shippedCount )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . res1   AS   res4 , \n        t2 . res1   AS   res5  FROM   cart_users   AS   t0  INNER   JOIN \n   ( SELECT   t0 . email   AS   res0 , \n           COUNT ( * )   AS   res1 \n    FROM   cart_users   AS   t0 \n    LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n    AND   (( t1 . shipping_info__id )   IS   NULL ) \n    GROUP   BY   t0 . email )   AS   t1  INNER   JOIN \n   ( SELECT   t0 . email   AS   res0 , \n           COUNT ( * )   AS   res1 \n    FROM   cart_users   AS   t0 \n    LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n    AND   (( t1 . shipping_info__id )   IS   NOT   NULL ) \n    GROUP   BY   t0 . email )   AS   t2  WHERE   (( t1 . res0 ) = ( t0 . email )) \n   AND   (( t2 . res0 ) = ( t0 . email ))   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com ,\n       _userFirstName =  Betty ,\n       _userLastName =  Jones ,\n       _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },1,\n                                                           1) --\n(User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,\n                                                           1) --\n(User {_userEmail =  sam@example.com ,\n       _userFirstName =  Sam ,\n       _userLastName =  Taylor ,\n       _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,\n                                                           1) -- \n\n         \n    \n         \n    \n                 \n                      Notice that the  aggregate_ s embedded in the  Q  monad were automatically\nconverted into sub  SELECT s. This is because beam queries are composable -- you\ncan use them wherever they type check and sensible SQL will result. Of course,\nif you want more control, you can also use the  subselect_  combinator to force\ngeneration of a sub  SELECT .  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sql \n         \n    \n         \n             Out \n         \n    \n         \n    \n         \n            \n         \n             shippingInformationByUser   - \n   withDatabaseDebug   putStrLn   conn   $ \n     runSelectReturningList   $ \n     select   $ \n     do   user   -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n\n        ( userEmail ,   unshippedCount )   - \n          subselect_   $ \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isNothing_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n\n        guard_   ( userEmail   ` references_ `   user ) \n\n        ( userEmail ,   shippedCount )   - \n          subselect_   $ \n          aggregate_   ( \\ ( userEmail ,   order )   -   ( group_   userEmail ,   countAll_ ))   $ \n          do   user    -   all_   ( shoppingCartDb   ^.   shoppingCartUsers ) \n             order   -   leftJoin_   ( all_   ( shoppingCartDb   ^.   shoppingCartOrders )) \n                                ( \\ order   -   _orderForUser   order   ` references_ `   user   .   isJust_   ( _orderShippingInfo   order )) \n             pure   ( pk   user ,   order ) \n        guard_   ( userEmail   ` references_ `   user ) \n\n        pure   ( user ,   unshippedCount ,   shippedCount )  mapM_   print   shippingInformationByUser  \n\n         \n    \n         \n             SELECT   t0 . email   AS   res0 , \n        t0 . first_name   AS   res1 , \n        t0 . last_name   AS   res2 , \n        t0 . password   AS   res3 , \n        t1 . res1   AS   res4 , \n        t2 . res1   AS   res5  FROM   cart_users   AS   t0  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . email   AS   res0 , \n              COUNT ( * )   AS   res1 \n       FROM   cart_users   AS   t0 \n       LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n       AND   (( t1 . shipping_info__id )   IS   NULL ) \n       GROUP   BY   t0 . email )   AS   t0 )   AS   t1  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . email   AS   res0 , \n              COUNT ( * )   AS   res1 \n       FROM   cart_users   AS   t0 \n       LEFT   JOIN   orders   AS   t1   ON   (( t1 . for_user__email ) = ( t0 . email )) \n       AND   (( t1 . shipping_info__id )   IS   NOT   NULL ) \n       GROUP   BY   t0 . email )   AS   t0 )   AS   t2  WHERE   (( t1 . res0 ) = ( t0 . email )) \n   AND   (( t2 . res0 ) = ( t0 . email ))   -- With values: []  \n\n         \n    \n         \n             (User {_userEmail =  betty@example.com ,\n       _userFirstName =  Betty ,\n       _userLastName =  Jones ,\n       _userPassword =  82b054bd83ffad9b6cf8bdb98ce3cc2f },1,\n                                                           1) --\n(User {_userEmail =  james@example.com ,\n       _userFirstName =  James ,\n       _userLastName =  Smith ,\n       _userPassword =  b4cc344d25a2efe540adbf2678e2304c },2,\n                                                           1) --\n(User {_userEmail =  sam@example.com ,\n       _userFirstName =  Sam ,\n       _userLastName =  Taylor ,\n       _userPassword =  332532dcfaa1cbf61e2a266bd723612c },1,\n                                                           1) --", 
            "title": "Queries with nullable foreign keys"
        }, 
        {
            "location": "/tutorials/tutorial3/#conclusion", 
            "text": "This tutorial completes our sequence on creating a shopping cart. Throughout the\ntutorials, we saw how to create tables using regular Haskell data types, how to\nlink those tables up using relations, how to query tables using both the monadic\ninterface and the list-like functions on queries. We saw ha few examples of\nusing beam to generate advanced queries. More information on the Beam API is\nhavailable on  hackage . Happy beaming!  Beam is a work in progress. Please submit bugs and patches\non  GitHub .", 
            "title": "Conclusion"
        }, 
        {
            "location": "/user-guide/models/", 
            "text": "A beam model is any single-constructer Haskell record type parameterized by a\ntype of kind \n* -\n *\n. The model must have an instance of \nGeneric\n, \nBeamable\n,\nand \nTable\n. \nGeneric\n can be derived using the \nDeriveGeneric\n extension of\nGHC. \nBeamable\n must be given an empty instance declaration (\ninstance Beamable\nTbl\n for a table of type \nTbl\n). \nTable\n is discussed next.\n\n\nEach field in the record type must either be a sub-table (another parameterized\ntype with a \nBeamable\n instance) or an explicit column. A column is specified\nusing the \nColumnar\n type family applied to the type's parameter and the\nunderlying Haskell type of the field.\n\n\nThe \nTable\n type class\n\n\nTable\n is a type class that must be instantiated for all types that you would\nlike to use as a table. It has one associated \ndata\n instance and one function.\n\n\nYou must create a type to represent the primary key of the table. The primary\nkey of a table \nTbl\n is the associated data type \nPrimaryKey Tbl\n. Like \nTbl\n,\nit takes one type parameter of kind \n* -\n *\n. It must have only one constructor\nwhich can hold all fields in the primary key. The constructor need not be a\nrecord constructor (although it can be).\n\n\nYou must also write a function \nprimaryKey\n that takes an instance of \nTbl\n\n(parameterized over any functor \nf\n) and returns the associated \nPrimaryKey\n\ntype. It is sometimes easiest to use the \nApplicative\n instance for \nr -\n to\nwrite this function. For example, if \ntblField1\n and \ntblField2\n are part of the\nprimary key, you can write\n\n\ninstance\n \nTable\n \nTbl\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nTbl\n \nf\n \n=\n \nTblKey\n \n(\nColumnar\n \nf\n \n..\n)\n \n(\nColumnar\n \nf\n \n..\n)\n\n  \nprimaryKey\n \nt\n \n=\n \nTblKey\n \n(\ntblField1\n \nt\n)\n \n(\ntblField2\n \nt\n)\n\n\n\n\n\n\nmore simply as\n\n\ninstance\n \nTable\n \nTbl\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nTbl\n \nf\n \n=\n \nTblKey\n \n(\nColumnar\n \nf\n \n..\n)\n \n(\nColumnar\n \nf\n \n..\n)\n\n  \nprimaryKey\n \n=\n \nTblKey\n \n$\n \ntblField1\n \n*\n \ntblField2\n\n\n\n\n\n\nThe \nIdentity\n trick\n\n\nBeam table types are commonly prefixed by a \nT\n to indicate the name of the\ngeneric table type. Usually, a type synonym named by leaving out the \nT\n is\ndefined by applying the table to \nIdentity\n. Recall each field in the table is\neither another table or an application of \nColumnar\n to the type parameter. When\nthe type is parameterized by \nIdentity\n, every column is also parameterized by\n\nIdentity\n.\n\n\nColumnar\n is a type family defined such that \nColumnar Identity x ~ x\n. Thus,\nwhen parameterized over \nIdentity\n, every field in the table type takes on the\nunderlying Haskell type.\n\n\nSuppose you have a table type \nModelT\n and a type synonym \ntype Model = ModelT\nIdentity\n. Notice that deriving \nShow\n, \nEq\n, and other standard Haskell type\nclasses won't generally work for \nModelT\n. However, you can use the standalone\nderiving mechanism to derive these instances for \nModel\n.\n\n\ndata\n \nModelT\n \nf\n \n=\n \nModel\n \n{\n \n..\n \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nModelT\n\n\n\n-- deriving instance Show (ModelT f) -- Won\nt work because GHC won\nt get the constraints right\n\n\n\ntype\n \nModel\n \n=\n \nModelT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nModel\n\n\nderiving\n \ninstance\n \nEq\n \nModel\n\n\nderiving\n \ninstance\n \nOrd\n \nModel\n\n\n\n\n\n\nAllowed data types\n\n\nAny data type can be used within a \nColumnar\n. Beam does no checking that a\nfield can be used against a particular database when the data type is defined.\nInstead, type errors will occur when the table is being used as a query. For\nexample, the following is allowed, even though many backends will not work with\narray data types.\n\n\nimport\n \nqualified\n \nData.Vector\n \nas\n \nV\n\n\n\ndata\n \nArrayTable\n \nf\n\n    \n=\n \nArrayTable\n\n    \n{\n \narrayTablePoints\n \n::\n \nColumnar\n \nf\n \n(\nV\n.\nVector\n \nInt32\n)\n\n    \n}\n \nderiving\n \nGeneric\n\n\n\n\n\n\nYou can construct values of type \nArrayTable Identity\n and even write queries\nover it (relying on type inference to get the constraints right). However, if\nyou attempt to solve the constraints over a database that doesn't support\ncolumns of type \nV.Vector Int32\n, GHC will throw an error. Thus, it's important\nto understand the limits of your backend when deciding which types to use. In\ngeneral, numeric, floating-point, and text types are well supported.\n\n\nMaybe\n types\n\n\nOptional fields (those that allow a SQL \nNULL\n) can usually be given a \nMaybe\n\ntype. However, you cannot use \nMaybe\n around an embedded table (you will be\nunable to instantiate \nBeamable\n).\n\n\nBeam offers a way around this. Instead of embedding the table applied to the\ntype parameter \nf\n, apply it to \nNullable f\n. \nColumnar (Nullable f) a ~ Maybe\n(Columnar f a)\n for all \na\n. Thus, this will make every column in the embedded\ntable take on the corresponding \nMaybe\n type.\n\n\n\n\nWarning\n\n\nNullable\n will nest \nMaybe\ns. That is \nColumnar (Nullable f) (Maybe a) ~\nMaybe (Maybe a)\n. This is bad from a SQL perspective, since SQL has no\nconcept of a nested optional type. Beam treats a \nNothing\n at any 'layer' of\nthe \nMaybe\n stack as a corresponding SQL \nNULL\n. When marshalling data back,\na SQL \nNULL\n is read in as a top-level \nNothing\n.\n\n\nThe reasons for this misfeature is basically code simplicity. Fixing this is\na top priority of future versions of beam.\n\n\n\n\nColumn tags\n\n\nAbove, we saw that applying \nIdentity\n to a table type results in a type whose\ncolumns are the underlying Haskell type. Beam uses other column tags for\nquerying and describing databases. Below is a table of common column tags and\ntheir meaning.\n\n\nConverting between tags\n\n\nSuppose you have a \nBeamable\n type paramaterized over a tag \nf\n and needed one\nparameterized over a tag \ng\n. Given a function \nconv :: forall a. Columnar f a\n-\n Columnar g a\n, you can use \nchangeBeamRep\n to convert between the tables.\n\n\nThere is one caveat however -- since \nColumnar\n is a type family, the type of\n\nconv\n is actually ambiguous. We need a way to carry the type of \nf\n, \ng\n, and\n\na\n into the code. For this reason, \nconv\n must actually be written over the\n\nColumnar'\n(notice the tick) \nnewtype\n. \nColumnar'\n is a newtype defined as such\n\n\nnewtype\n \nColumnar\n \nf\n \na\n \n=\n \nColumnar\n \n(\nColumnar\n \nf\n \na\n)\n\n\n\n\n\n\nNotice that, unlinke \nColumnar\n (a non-injective type family), \nColumnar'\n is a\nfull type. The type of \nconv' :: forall a. Columnar' f a -\n Columnar' g a\n is\nnow unambiguous. You can easily use \nconv\n to implement \nconv'\n:\n\n\nconv\n \n(\nColumnar\n \na\n)\n \n=\n \nColumnar\n \n(\nconv\n \na\n)\n\n\n\n\n\n\nYou will often need to write explicit type signatures in order to get the\ncompiler to accept your code.\n\n\nThe \nBeamable\n type class\n\n\nAll beam tables, primary keys, and shared data fields must be instances of the\n\nBeamable\n class. You cannot override the methods of \nBeamable\n. Rather, they\nare derived using GHC's generics mechanism. Once you've declared your data type,\nyou can simply write \ninstance Beamable \nyour-type-name\n to instantiate the\ncorrect \nBeamable\n instance for your type.\n\n\nThe \nTable\n type class\n\n\nAll \nBeamable\n data types that you want to include as a \nTableEntity\n in your\ndatabase must be members of the \nTable\n type class. The \nTable\n type class\ndefines one associated type family \nPrimaryKey\n and a function \nprimaryKey\n that\ntakes a table over an arbitrary column tag and produces that table's\n\nPrimaryKey\n. For example, if you have a model\n\n\ndata\n \nPersonT\n \nf\n\n    \n=\n \nPerson\n\n    \n{\n \npersonEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npersonAge\n       \n::\n \nColumnar\n \nf\n \nInt\n\n    \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nPersonT\n\n\n\n\n\n\nand you want the \npersonEmail\n field to form the primary key, you would define a \nTable\n instance as such\n\n\ninstance\n \nTable\n \nPersonT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nPersonT\n \nf\n\n      \n=\n \nPersonKey\n \n(\nColumnar\n \nf\n \nText\n)\n \nderiving\n \nGeneric\n\n  \nprimaryKey\n \nperson\n \n=\n \nPersonKey\n \n$\n \npersonEmail\n\n\ninstance\n \nBeamable\n \n(\nPrimaryKey\n \nPersonT\n)\n \n-- PrimaryKey\ns must be \nBeamable\n  \n\n\n\n\n\n\n\n\nTip\n\n\nMany people find it useful to use the \nApplicative\n instance for \n(-\n) a\n to\nwrite \nprimaryKey\n. For example, we could have written the above \nprimaryKey\nperson = PersonKey (personFirstName person) (personLastName person)\n as\n\nprimaryKey = PersonKey \n$\n personFirstName \n*\n personLastName\n.\n\n\n\n\n\n\nTip\n\n\nTyping \nColumnar\n may become tiresome. \nDatabase.Beam\n also exports \nC\n as a\ntype alias for \nColumnar\n, which may make writing models easier. Since \nC\n\nmay cause name clashes, all examples are given using \nColumnar\n.\n\n\n\n\nMany also like defining type synonyms for their table and primary key types. For\nexample, for the table \nPersonT\n above, a programmer may define.\n\n\ntype\n \nPerson\n \n=\n \nPersonT\n \nIdentity\n\n\ntype\n \nPersonKey\n \n=\n \nPrimaryKey\n \nPersonT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nPerson\n;\n \nderiving\n \ninstance\n \nEq\n \nPerson\n\n\nderiving\n \ninstance\n \nShow\n \nPersonKey\n;\n \nderiving\n \ninstance\n \nEq\n \nPersonKey\n\n\n\n\n\n\nBy convention, beam table types are suffixed with \nT\n to distinguish their type\nnames from the same type parameterized over \nIdentity\n (the 'regular' Haskell\ndata type).\n\n\nWhat about tables without primary keys?\n\n\nTables without primary keys are considered bad style. However, sometimes you\nneed to use beam with a schema that you have no control over. To declare a table\nwithout a primary key, simply instantiate the \nTable\n class and set \nPrimaryKey\ntbl\n to a type with no fields. Then just produce this type in \nprimaryKey\n.\n\n\nFor example\n\n\ndata\n \nBadT\n \nf\n\n  \n=\n \nBadT\n\n  \n{\n \nbadFirstName\n \n::\n \nC\n \nf\n \nText\n\n  \n,\n \nbadLastName\n  \n::\n \nC\n \nf\n \nText\n\n  \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nBadT\n\n\ninstance\n \nTable\n \nBadT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nBadT\n \nf\n \n=\n \nBadNoId\n\n  \nprimaryKey\n \n_\n \n=\n \nBadNoId\n\n\n\n\n\n\nForeign references\n\n\nForeign references are also easily supported in models by simply\nembedding the \nPrimaryKey\n of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.\n\n\ndata\n \nPostT\n \nf\n\n    \n=\n \nPost\n\n    \n{\n \npostId\n       \n::\n \nColumnar\n \nf\n \n(\nAuto\n \nInt\n)\n\n    \n,\n \npostPostedAt\n \n::\n \nColumnar\n \nf\n \nLocalTime\n\n    \n,\n \npostContent\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npostPoster\n   \n::\n \nPrimaryKey\n \nPersonT\n \nf\n\n    \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nPostT\n\n\n\ninstance\n \nTable\n \nPostT\n \nwhere\n\n  \ndata\n \nPrimaryKey\n \nPostT\n \nf\n\n      \n=\n \nPostId\n \n(\nColumnar\n \nf\n \n(\nAuto\n \nInt\n))\n \nderiving\n \nGeneric\n\n  \nprimaryKey\n \n=\n \nPostId\n \n.\n \npostId\n\n\n\ntype\n \nPost\n \n=\n \nPostT\n \nIdentity\n\n\ntype\n \nPostId\n \n=\n \nPrimaryKey\n \nPostT\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \nPost\n;\n \nderiving\n \ninstance\n \nEq\n \nPost\n\n\nderiving\n \ninstance\n \nShow\n \nPostId\n;\n \nderiving\n \ninstance\n \nEq\n \nPostId\n\n\n\n\n\n\nNullable foreign references\n\n\nAbove, any non-bottom value of type \nPostT Identity\n must carry a concrete value\nof \nPrimaryKey PersonT Identity\n. Sometimes, you may want to optionally include\na foreign key. You can make a foreign key nullable by embedding the primary key\nand adding the \nNullable\n column tag modifier.\n\n\nFor example, to make the poster optional above.\n\n\ndata\n \nPostT\n \nf\n\n    \n=\n \nPost\n\n    \n{\n \npostId\n       \n::\n \nColumnar\n \nf\n \n(\nAuto\n \nInt\n)\n\n    \n,\n \npostPostedAt\n \n::\n \nColumnar\n \nf\n \nLocalTime\n\n    \n,\n \npostContent\n  \n::\n \nColumnar\n \nf\n \nText\n\n    \n,\n \npostPoster\n   \n::\n \nPrimaryKey\n \nPersonT\n \n(\nNullable\n \nf\n)\n\n    \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nPostT\n\n\n\n\n\n\nMore complicated relationships\n\n\nThis is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.\n\n\nAlso, notice that beam does not allow you to specify any kind of reference\nconstraints between tables in your data types. This is because references are a\nproperty of the database, not a particular table schema. Such relationships can\nbe defined using \nbeam-migrate\n library.\n\n\nAuto\n fields\n\n\nAbove, \nPost\n used \nAuto Int\n as the type for \npostId\n. `\n\n\nThe \nAuto\n type constructor is provided by \nbeam-core\n for fields that are\nautomatically assigned by the database. Internally, \nAuto x\n is simply a newtype\nover \nMaybe x\n. The guarantee is that all values of type \nAuto x\n returned by\nbeam in the result set will have a value, although this guarantee is not\nenforced at the type level (yet).\n\n\nEmbedding\n\n\nSometimes, we want to declare multiple models with fields in common. Beam allows\nyou to simple embed such fields in common types and embed those directly into\nmodels. For example, in\nthe\n\nChinook example schema\n,\nwe define the following structure for addresses.\n\n\ndata\n \nAddressMixin\n \nf\n\n  \n=\n \nAddress\n\n  \n{\n \naddress\n           \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressCity\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressState\n      \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressCountry\n    \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \naddressPostalCode\n \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nAddressMixin\n\n\ntype\n \nAddress\n \n=\n \nAddressMixin\n \nIdentity\n\n\nderiving\n \ninstance\n \nShow\n \n(\nAddressMixin\n \nIdentity\n)\n\n\n\n\n\n\nWe can then use \nAddressMixin\n in our models.\n\n\ndata\n \nEmployeeT\n \nf\n\n  \n=\n \nEmployee\n\n  \n{\n \nemployeeId\n        \n::\n \nColumnar\n \nf\n \nInt32\n\n  \n,\n \nemployeeLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \nemployeeFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \nemployeeTitle\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeReportsTo\n \n::\n \nPrimaryKey\n \nEmployeeT\n \n(\nNullable\n \nf\n)\n\n  \n,\n \nemployeeBirthDate\n \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nLocalTime\n)\n\n  \n,\n \nemployeeHireDate\n  \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nLocalTime\n)\n\n  \n,\n \nemployeeAddress\n   \n::\n \nAddressMixin\n \nf\n\n  \n,\n \nemployeePhone\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeFax\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \nemployeeEmail\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n}\n \nderiving\n \nGeneric\n\n\n-- ...\n\n\ndata\n \nCustomerT\n \nf\n\n  \n=\n \nCustomer\n\n  \n{\n \ncustomerId\n        \n::\n \nColumnar\n \nf\n \nInt32\n\n  \n,\n \ncustomerFirstName\n \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerLastName\n  \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerCompany\n   \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerAddress\n   \n::\n \nAddressMixin\n \nf\n\n  \n,\n \ncustomerPhone\n     \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerFax\n       \n::\n \nColumnar\n \nf\n \n(\nMaybe\n \nText\n)\n\n  \n,\n \ncustomerEmail\n     \n::\n \nColumnar\n \nf\n \nText\n\n  \n,\n \ncustomerSupportRep\n \n::\n \nPrimaryKey\n \nEmployeeT\n \n(\nNullable\n \nf\n)\n\n  \n}\n \nderiving\n \nGeneric\n\n\n\n\n\n\nDefaults\n\n\nBased on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the\n\npersonFirstName\n field is accessible in SQL as \nfirst_name\n. This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.\n\n\nFor the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.\n\n\nWhen defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.\n\n\n\n\n\n\n\n\nHaskell field name\n\n\nBeam defaulted column name\n\n\n\n\n\n\n\n\n\n\npersonFirstName\n\n\nfirst_name\n\n\n\n\n\n\n_personLastName\n\n\nlast_name\n\n\n\n\n\n\nname\n\n\nname\n\n\n\n\n\n\nfirst_name\n\n\nfirst_name\n\n\n\n\n\n\n_first_name\n\n\nfirst_name\n\n\n\n\n\n\n___\n (three underscores)\n\n\n___\n (no changes)\n\n\n\n\n\n\n\n\nNote that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.\n\n\nFor information on modifying the defaults, see the \nnext section\n.", 
            "title": "Models"
        }, 
        {
            "location": "/user-guide/models/#the-table-type-class", 
            "text": "Table  is a type class that must be instantiated for all types that you would\nlike to use as a table. It has one associated  data  instance and one function.  You must create a type to represent the primary key of the table. The primary\nkey of a table  Tbl  is the associated data type  PrimaryKey Tbl . Like  Tbl ,\nit takes one type parameter of kind  * -  * . It must have only one constructor\nwhich can hold all fields in the primary key. The constructor need not be a\nrecord constructor (although it can be).  You must also write a function  primaryKey  that takes an instance of  Tbl \n(parameterized over any functor  f ) and returns the associated  PrimaryKey \ntype. It is sometimes easiest to use the  Applicative  instance for  r -  to\nwrite this function. For example, if  tblField1  and  tblField2  are part of the\nprimary key, you can write  instance   Table   Tbl   where \n   data   PrimaryKey   Tbl   f   =   TblKey   ( Columnar   f   .. )   ( Columnar   f   .. ) \n   primaryKey   t   =   TblKey   ( tblField1   t )   ( tblField2   t )   more simply as  instance   Table   Tbl   where \n   data   PrimaryKey   Tbl   f   =   TblKey   ( Columnar   f   .. )   ( Columnar   f   .. ) \n   primaryKey   =   TblKey   $   tblField1   *   tblField2", 
            "title": "The Table type class"
        }, 
        {
            "location": "/user-guide/models/#the-identity-trick", 
            "text": "Beam table types are commonly prefixed by a  T  to indicate the name of the\ngeneric table type. Usually, a type synonym named by leaving out the  T  is\ndefined by applying the table to  Identity . Recall each field in the table is\neither another table or an application of  Columnar  to the type parameter. When\nthe type is parameterized by  Identity , every column is also parameterized by Identity .  Columnar  is a type family defined such that  Columnar Identity x ~ x . Thus,\nwhen parameterized over  Identity , every field in the table type takes on the\nunderlying Haskell type.  Suppose you have a table type  ModelT  and a type synonym  type Model = ModelT\nIdentity . Notice that deriving  Show ,  Eq , and other standard Haskell type\nclasses won't generally work for  ModelT . However, you can use the standalone\nderiving mechanism to derive these instances for  Model .  data   ModelT   f   =   Model   {   ..   }   deriving   Generic  instance   Beamable   ModelT  -- deriving instance Show (ModelT f) -- Won t work because GHC won t get the constraints right  type   Model   =   ModelT   Identity  deriving   instance   Show   Model  deriving   instance   Eq   Model  deriving   instance   Ord   Model", 
            "title": "The Identity trick"
        }, 
        {
            "location": "/user-guide/models/#allowed-data-types", 
            "text": "Any data type can be used within a  Columnar . Beam does no checking that a\nfield can be used against a particular database when the data type is defined.\nInstead, type errors will occur when the table is being used as a query. For\nexample, the following is allowed, even though many backends will not work with\narray data types.  import   qualified   Data.Vector   as   V  data   ArrayTable   f \n     =   ArrayTable \n     {   arrayTablePoints   ::   Columnar   f   ( V . Vector   Int32 ) \n     }   deriving   Generic   You can construct values of type  ArrayTable Identity  and even write queries\nover it (relying on type inference to get the constraints right). However, if\nyou attempt to solve the constraints over a database that doesn't support\ncolumns of type  V.Vector Int32 , GHC will throw an error. Thus, it's important\nto understand the limits of your backend when deciding which types to use. In\ngeneral, numeric, floating-point, and text types are well supported.", 
            "title": "Allowed data types"
        }, 
        {
            "location": "/user-guide/models/#maybe-types", 
            "text": "Optional fields (those that allow a SQL  NULL ) can usually be given a  Maybe \ntype. However, you cannot use  Maybe  around an embedded table (you will be\nunable to instantiate  Beamable ).  Beam offers a way around this. Instead of embedding the table applied to the\ntype parameter  f , apply it to  Nullable f .  Columnar (Nullable f) a ~ Maybe\n(Columnar f a)  for all  a . Thus, this will make every column in the embedded\ntable take on the corresponding  Maybe  type.   Warning  Nullable  will nest  Maybe s. That is  Columnar (Nullable f) (Maybe a) ~\nMaybe (Maybe a) . This is bad from a SQL perspective, since SQL has no\nconcept of a nested optional type. Beam treats a  Nothing  at any 'layer' of\nthe  Maybe  stack as a corresponding SQL  NULL . When marshalling data back,\na SQL  NULL  is read in as a top-level  Nothing .  The reasons for this misfeature is basically code simplicity. Fixing this is\na top priority of future versions of beam.", 
            "title": "Maybe types"
        }, 
        {
            "location": "/user-guide/models/#column-tags", 
            "text": "Above, we saw that applying  Identity  to a table type results in a type whose\ncolumns are the underlying Haskell type. Beam uses other column tags for\nquerying and describing databases. Below is a table of common column tags and\ntheir meaning.", 
            "title": "Column tags"
        }, 
        {
            "location": "/user-guide/models/#converting-between-tags", 
            "text": "Suppose you have a  Beamable  type paramaterized over a tag  f  and needed one\nparameterized over a tag  g . Given a function  conv :: forall a. Columnar f a\n-  Columnar g a , you can use  changeBeamRep  to convert between the tables.  There is one caveat however -- since  Columnar  is a type family, the type of conv  is actually ambiguous. We need a way to carry the type of  f ,  g , and a  into the code. For this reason,  conv  must actually be written over the Columnar' (notice the tick)  newtype .  Columnar'  is a newtype defined as such  newtype   Columnar   f   a   =   Columnar   ( Columnar   f   a )   Notice that, unlinke  Columnar  (a non-injective type family),  Columnar'  is a\nfull type. The type of  conv' :: forall a. Columnar' f a -  Columnar' g a  is\nnow unambiguous. You can easily use  conv  to implement  conv' :  conv   ( Columnar   a )   =   Columnar   ( conv   a )   You will often need to write explicit type signatures in order to get the\ncompiler to accept your code.", 
            "title": "Converting between tags"
        }, 
        {
            "location": "/user-guide/models/#the-beamable-type-class", 
            "text": "All beam tables, primary keys, and shared data fields must be instances of the Beamable  class. You cannot override the methods of  Beamable . Rather, they\nare derived using GHC's generics mechanism. Once you've declared your data type,\nyou can simply write  instance Beamable  your-type-name  to instantiate the\ncorrect  Beamable  instance for your type.", 
            "title": "The Beamable type class"
        }, 
        {
            "location": "/user-guide/models/#the-table-type-class_1", 
            "text": "All  Beamable  data types that you want to include as a  TableEntity  in your\ndatabase must be members of the  Table  type class. The  Table  type class\ndefines one associated type family  PrimaryKey  and a function  primaryKey  that\ntakes a table over an arbitrary column tag and produces that table's PrimaryKey . For example, if you have a model  data   PersonT   f \n     =   Person \n     {   personEmail       ::   Columnar   f   Text \n     ,   personFirstName   ::   Columnar   f   Text \n     ,   personLastName    ::   Columnar   f   Text \n     ,   personAge         ::   Columnar   f   Int \n     }   deriving   Generic  instance   Beamable   PersonT   and you want the  personEmail  field to form the primary key, you would define a  Table  instance as such  instance   Table   PersonT   where \n   data   PrimaryKey   PersonT   f \n       =   PersonKey   ( Columnar   f   Text )   deriving   Generic \n   primaryKey   person   =   PersonKey   $   personEmail  instance   Beamable   ( PrimaryKey   PersonT )   -- PrimaryKey s must be  Beamable       Tip  Many people find it useful to use the  Applicative  instance for  (- ) a  to\nwrite  primaryKey . For example, we could have written the above  primaryKey\nperson = PersonKey (personFirstName person) (personLastName person)  as primaryKey = PersonKey  $  personFirstName  *  personLastName .    Tip  Typing  Columnar  may become tiresome.  Database.Beam  also exports  C  as a\ntype alias for  Columnar , which may make writing models easier. Since  C \nmay cause name clashes, all examples are given using  Columnar .   Many also like defining type synonyms for their table and primary key types. For\nexample, for the table  PersonT  above, a programmer may define.  type   Person   =   PersonT   Identity  type   PersonKey   =   PrimaryKey   PersonT   Identity  deriving   instance   Show   Person ;   deriving   instance   Eq   Person  deriving   instance   Show   PersonKey ;   deriving   instance   Eq   PersonKey   By convention, beam table types are suffixed with  T  to distinguish their type\nnames from the same type parameterized over  Identity  (the 'regular' Haskell\ndata type).", 
            "title": "The Table type class"
        }, 
        {
            "location": "/user-guide/models/#what-about-tables-without-primary-keys", 
            "text": "Tables without primary keys are considered bad style. However, sometimes you\nneed to use beam with a schema that you have no control over. To declare a table\nwithout a primary key, simply instantiate the  Table  class and set  PrimaryKey\ntbl  to a type with no fields. Then just produce this type in  primaryKey .  For example  data   BadT   f \n   =   BadT \n   {   badFirstName   ::   C   f   Text \n   ,   badLastName    ::   C   f   Text \n   }   deriving   Generic  instance   Beamable   BadT  instance   Table   BadT   where \n   data   PrimaryKey   BadT   f   =   BadNoId \n   primaryKey   _   =   BadNoId", 
            "title": "What about tables without primary keys?"
        }, 
        {
            "location": "/user-guide/models/#foreign-references", 
            "text": "Foreign references are also easily supported in models by simply\nembedding the  PrimaryKey  of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.  data   PostT   f \n     =   Post \n     {   postId         ::   Columnar   f   ( Auto   Int ) \n     ,   postPostedAt   ::   Columnar   f   LocalTime \n     ,   postContent    ::   Columnar   f   Text \n     ,   postPoster     ::   PrimaryKey   PersonT   f \n     }   deriving   Generic  instance   Beamable   PostT  instance   Table   PostT   where \n   data   PrimaryKey   PostT   f \n       =   PostId   ( Columnar   f   ( Auto   Int ))   deriving   Generic \n   primaryKey   =   PostId   .   postId  type   Post   =   PostT   Identity  type   PostId   =   PrimaryKey   PostT   Identity  deriving   instance   Show   Post ;   deriving   instance   Eq   Post  deriving   instance   Show   PostId ;   deriving   instance   Eq   PostId", 
            "title": "Foreign references"
        }, 
        {
            "location": "/user-guide/models/#nullable-foreign-references", 
            "text": "Above, any non-bottom value of type  PostT Identity  must carry a concrete value\nof  PrimaryKey PersonT Identity . Sometimes, you may want to optionally include\na foreign key. You can make a foreign key nullable by embedding the primary key\nand adding the  Nullable  column tag modifier.  For example, to make the poster optional above.  data   PostT   f \n     =   Post \n     {   postId         ::   Columnar   f   ( Auto   Int ) \n     ,   postPostedAt   ::   Columnar   f   LocalTime \n     ,   postContent    ::   Columnar   f   Text \n     ,   postPoster     ::   PrimaryKey   PersonT   ( Nullable   f ) \n     }   deriving   Generic  instance   Beamable   PostT", 
            "title": "Nullable foreign references"
        }, 
        {
            "location": "/user-guide/models/#more-complicated-relationships", 
            "text": "This is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.  Also, notice that beam does not allow you to specify any kind of reference\nconstraints between tables in your data types. This is because references are a\nproperty of the database, not a particular table schema. Such relationships can\nbe defined using  beam-migrate  library.", 
            "title": "More complicated relationships"
        }, 
        {
            "location": "/user-guide/models/#auto-fields", 
            "text": "Above,  Post  used  Auto Int  as the type for  postId . `  The  Auto  type constructor is provided by  beam-core  for fields that are\nautomatically assigned by the database. Internally,  Auto x  is simply a newtype\nover  Maybe x . The guarantee is that all values of type  Auto x  returned by\nbeam in the result set will have a value, although this guarantee is not\nenforced at the type level (yet).", 
            "title": "Auto fields"
        }, 
        {
            "location": "/user-guide/models/#embedding", 
            "text": "Sometimes, we want to declare multiple models with fields in common. Beam allows\nyou to simple embed such fields in common types and embed those directly into\nmodels. For example, in\nthe Chinook example schema ,\nwe define the following structure for addresses.  data   AddressMixin   f \n   =   Address \n   {   address             ::   Columnar   f   ( Maybe   Text ) \n   ,   addressCity         ::   Columnar   f   ( Maybe   Text ) \n   ,   addressState        ::   Columnar   f   ( Maybe   Text ) \n   ,   addressCountry      ::   Columnar   f   ( Maybe   Text ) \n   ,   addressPostalCode   ::   Columnar   f   ( Maybe   Text ) \n   }   deriving   Generic  instance   Beamable   AddressMixin  type   Address   =   AddressMixin   Identity  deriving   instance   Show   ( AddressMixin   Identity )   We can then use  AddressMixin  in our models.  data   EmployeeT   f \n   =   Employee \n   {   employeeId          ::   Columnar   f   Int32 \n   ,   employeeLastName    ::   Columnar   f   Text \n   ,   employeeFirstName   ::   Columnar   f   Text \n   ,   employeeTitle       ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeReportsTo   ::   PrimaryKey   EmployeeT   ( Nullable   f ) \n   ,   employeeBirthDate   ::   Columnar   f   ( Maybe   LocalTime ) \n   ,   employeeHireDate    ::   Columnar   f   ( Maybe   LocalTime ) \n   ,   employeeAddress     ::   AddressMixin   f \n   ,   employeePhone       ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeFax         ::   Columnar   f   ( Maybe   Text ) \n   ,   employeeEmail       ::   Columnar   f   ( Maybe   Text ) \n   }   deriving   Generic  -- ...  data   CustomerT   f \n   =   Customer \n   {   customerId          ::   Columnar   f   Int32 \n   ,   customerFirstName   ::   Columnar   f   Text \n   ,   customerLastName    ::   Columnar   f   Text \n   ,   customerCompany     ::   Columnar   f   ( Maybe   Text ) \n   ,   customerAddress     ::   AddressMixin   f \n   ,   customerPhone       ::   Columnar   f   ( Maybe   Text ) \n   ,   customerFax         ::   Columnar   f   ( Maybe   Text ) \n   ,   customerEmail       ::   Columnar   f   Text \n   ,   customerSupportRep   ::   PrimaryKey   EmployeeT   ( Nullable   f ) \n   }   deriving   Generic", 
            "title": "Embedding"
        }, 
        {
            "location": "/user-guide/models/#defaults", 
            "text": "Based on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the personFirstName  field is accessible in SQL as  first_name . This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.  For the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.  When defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.     Haskell field name  Beam defaulted column name      personFirstName  first_name    _personLastName  last_name    name  name    first_name  first_name    _first_name  first_name    ___  (three underscores)  ___  (no changes)     Note that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.  For information on modifying the defaults, see the  next section .", 
            "title": "Defaults"
        }, 
        {
            "location": "/user-guide/databases/", 
            "text": "In addition to defining types for each of your tables, beam also\nrequires you to declare your database as a type with fields for\nholding all entities in your database. This includes more than just\ntables. For example, user-defined types that you would like to work\nwith must also be included in your database type.\n\n\nA simple database type\n\n\nLike tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.\n\n\ndata\n \nExampleDb\n \nf\n\n    \n=\n \nExampleDb\n\n    \n{\n \npersons\n \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n,\n \nposts\n   \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nDatabase\n \nExampleDb\n\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nOther database entities\n\n\nViews\n\n\nSome databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.\n\n\ndata\n \nPostAndPosterView\n \nf\n\n    \n=\n \nPostAndPosterView\n\n    \n{\n \npost\n   \n::\n \nPostT\n \nf\n\n    \n,\n \nposter\n \n::\n \nPersonT\n \nf\n\n    \n}\n \nderiving\n \nGeneric\n\n\ninstance\n \nBeamable\n \nPostAndPosterView\n\n\n\n\n\n\nWe can include this in our database:\n\n\ndata\n \nExampleDb\n \nf\n\n    \n=\n \nExampleDb\n\n    \n{\n \npersons\n        \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n,\n \nposts\n          \n::\n \nf\n \n(\nTableEntity\n \nPersonT\n)\n\n    \n,\n \npostAndPosters\n \n::\n \nf\n \n(\nViewEntity\n \nPostAndPosterView\n)\n\n    \n}\n \nderiving\n \nGeneric\n\n\n\n\n\n\nNow we can use \npostAndPosters\n wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations package.\n\n\nNote that the \nall_\n query primitive requires a \nTableEntity\n. Thus, \nall_\n(postAndPosters exampleDb)\n will fail to type-check. Use the \nallFromView_\n\ncombinator instead.\n\n\n\n\nNote\n\n\nYou could also declare a view as a \nTableEntity\n. The main advantage of\ndeclaring an entity as \nViewEntity\n is that you will be prevented by the\nHaskell type system from constructing \nINSERT\ns, \nUPDATE\ns, and \nDELETE\ns\nusing your view. Also, \nbeam-migrate\n will not recognize database schema\nequivalence if a view is declared as a table or vice versa.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain types\n\n\nDomain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.\n\n\nCharacter sets\n\n\nBeam does not yet support character sets. Support is planned in future releases.\n\n\nCollations\n\n\nBeam does not yet support collations. Support is planned in future releases.\n\n\nTranslations\n\n\nBeam does not yet support translations. Support is planned in future releases.\n\n\nOther database entities\n\n\nOther standard SQL database entities (like triggers) are defined by\n\nbeam-migrate\n as they have no effect on query semantics.\n\n\nDatabase descriptors\n\n\nIn order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the\n\ndefaultDbSettings\n function.\n\n\nFor example, to create a backend-agnostic database descriptor for the\n\nExampleDb\n type:\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n\n\n\n\n\n\nThe \ndefaultDbSettings\n function produces a settings value where each entity is\ngiven a default name as explained in the \nprevious section\n.\n\n\nNow, we can use the entities in \nexampleDb\n to write queries. The\nrules for name defaulting for database entities are the same as those\nfor \ntable fields\n\n\nModifying the defaults\n\n\nThe \nwithDbModification\n function can be used to modify the output of the\n\ndefaultDbSettings\n. It combines a database settings value with a \ndatabase\nmodifications value\n. The easiest way to construct a database modification value\nis with the \ndbModification\n function, which produces a modification that makes\nno changes.\n\n\nYou can then use Haskell record syntax to specify table or other entity\nmodifications. For example, the \nmodifyTable\n function can be used to produce a\ntable modification given a modifier function for the table name and a table\nmodification. Like database modifications, an identity table modification can be\nconstructed with the \ntableModification\n function. Modifications to field names\ncon be accomplished using Haskell record syntax on the result of\n\ntableModification\n. The \nfieldNamed\n field modification will give a field an\nexplicit new name.\n\n\nFor example, to rename the \npersons\n table as \npeople\n in the database above,\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nmodifyTable\n \n(\n\\\n_\n \n-\n \npeople\n)\n \ntableModification\n\n            \n}\n\n\n\n\n\n\nOr, to keep the \npersons\n table named as it is, but change the name of the \npersonEmail\n field from \n\"email\"\n to \n\"email_address\"\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nmodifyTable\n \nid\n \n$\n\n                        \ntableModification\n \n{\n\n                          \npersonEmail\n \n=\n \nfieldNamed\n \nemail_address\n\n                        \n}\n\n            \n}\n\n\n\n\n\n\nAn appropriate \nIsString\n instance is also given so you can avoid the use of\n\nfieldNamed\n. For example, the above is equivalent to\n\n\nexampleDb\n \n::\n \nDatabaseSettings\n \nbe\n \nExampleDb\n\n\nexampleDb\n \n=\n \ndefaultDbSettings\n \n`\nwithDbModification\n`\n\n            \ndbModification\n \n{\n\n              \npersons\n \n=\n \nmodifyTable\n \nid\n \n$\n\n                        \ntableModification\n \n{\n\n                          \npersonEmail\n \n=\n \nemail_address\n\n                        \n}\n\n            \n}", 
            "title": "Databases"
        }, 
        {
            "location": "/user-guide/databases/#a-simple-database-type", 
            "text": "Like tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.  data   ExampleDb   f \n     =   ExampleDb \n     {   persons   ::   f   ( TableEntity   PersonT ) \n     ,   posts     ::   f   ( TableEntity   PersonT ) \n     }   deriving   Generic  instance   Database   ExampleDb  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings", 
            "title": "A simple database type"
        }, 
        {
            "location": "/user-guide/databases/#other-database-entities", 
            "text": "", 
            "title": "Other database entities"
        }, 
        {
            "location": "/user-guide/databases/#views", 
            "text": "Some databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.  data   PostAndPosterView   f \n     =   PostAndPosterView \n     {   post     ::   PostT   f \n     ,   poster   ::   PersonT   f \n     }   deriving   Generic  instance   Beamable   PostAndPosterView   We can include this in our database:  data   ExampleDb   f \n     =   ExampleDb \n     {   persons          ::   f   ( TableEntity   PersonT ) \n     ,   posts            ::   f   ( TableEntity   PersonT ) \n     ,   postAndPosters   ::   f   ( ViewEntity   PostAndPosterView ) \n     }   deriving   Generic   Now we can use  postAndPosters  wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations package.  Note that the  all_  query primitive requires a  TableEntity . Thus,  all_\n(postAndPosters exampleDb)  will fail to type-check. Use the  allFromView_ \ncombinator instead.   Note  You could also declare a view as a  TableEntity . The main advantage of\ndeclaring an entity as  ViewEntity  is that you will be prevented by the\nHaskell type system from constructing  INSERT s,  UPDATE s, and  DELETE s\nusing your view. Also,  beam-migrate  will not recognize database schema\nequivalence if a view is declared as a table or vice versa.", 
            "title": "Views"
        }, 
        {
            "location": "/user-guide/databases/#domain-types", 
            "text": "Domain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.", 
            "title": "Domain types"
        }, 
        {
            "location": "/user-guide/databases/#character-sets", 
            "text": "Beam does not yet support character sets. Support is planned in future releases.", 
            "title": "Character sets"
        }, 
        {
            "location": "/user-guide/databases/#collations", 
            "text": "Beam does not yet support collations. Support is planned in future releases.", 
            "title": "Collations"
        }, 
        {
            "location": "/user-guide/databases/#translations", 
            "text": "Beam does not yet support translations. Support is planned in future releases.", 
            "title": "Translations"
        }, 
        {
            "location": "/user-guide/databases/#other-database-entities_1", 
            "text": "Other standard SQL database entities (like triggers) are defined by beam-migrate  as they have no effect on query semantics.", 
            "title": "Other database entities"
        }, 
        {
            "location": "/user-guide/databases/#database-descriptors", 
            "text": "In order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the defaultDbSettings  function.  For example, to create a backend-agnostic database descriptor for the ExampleDb  type:  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   The  defaultDbSettings  function produces a settings value where each entity is\ngiven a default name as explained in the  previous section .  Now, we can use the entities in  exampleDb  to write queries. The\nrules for name defaulting for database entities are the same as those\nfor  table fields", 
            "title": "Database descriptors"
        }, 
        {
            "location": "/user-guide/databases/#modifying-the-defaults", 
            "text": "The  withDbModification  function can be used to modify the output of the defaultDbSettings . It combines a database settings value with a  database\nmodifications value . The easiest way to construct a database modification value\nis with the  dbModification  function, which produces a modification that makes\nno changes.  You can then use Haskell record syntax to specify table or other entity\nmodifications. For example, the  modifyTable  function can be used to produce a\ntable modification given a modifier function for the table name and a table\nmodification. Like database modifications, an identity table modification can be\nconstructed with the  tableModification  function. Modifications to field names\ncon be accomplished using Haskell record syntax on the result of tableModification . The  fieldNamed  field modification will give a field an\nexplicit new name.  For example, to rename the  persons  table as  people  in the database above,  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   modifyTable   ( \\ _   -   people )   tableModification \n             }   Or, to keep the  persons  table named as it is, but change the name of the  personEmail  field from  \"email\"  to  \"email_address\"  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   modifyTable   id   $ \n                         tableModification   { \n                           personEmail   =   fieldNamed   email_address \n                         } \n             }   An appropriate  IsString  instance is also given so you can avoid the use of fieldNamed . For example, the above is equivalent to  exampleDb   ::   DatabaseSettings   be   ExampleDb  exampleDb   =   defaultDbSettings   ` withDbModification ` \n             dbModification   { \n               persons   =   modifyTable   id   $ \n                         tableModification   { \n                           personEmail   =   email_address \n                         } \n             }", 
            "title": "Modifying the defaults"
        }, 
        {
            "location": "/user-guide/backends/", 
            "text": "Beam is backend-agnostic and doesn't provide any means to connect to a\ndatabase. Beam backend libraries usually use well-used Haskell\nlibraries to provide database connectivity. For example, the\n\nbeam-sqlite\n backend uses the \nsqlite-simple\n backend.\n\n\nBeam distinguishes each backend via type indexes. Each backend defines\na type that is used to enable backend-specific behavior. For example,\nthe \nbeam-sqlite\n backend ships with the \nSqlite\n type that is used to\ndistinguish sqlite specific constructs with generic or other\nbackend-specific ones.\n\n\nEach backend can have one or more 'syntaxes', which are particular\nways to query the database. While the \nbeam-core\n library ships with a\nstandard ANSI SQL builder, few real-world database implementations\nfully follow the standard. Most backends use their own custom syntax\ntype. Internally, beam uses a finally-tagless representation for\nsyntax trees that allow straightforward construction against any\nbackend.\n\n\nBeam offers backend-generic functions for the most common operations\nagainst databases. These functions are meant to fit the lowest common\ndenominator. For example, no control is offered over streaming results\nfrom SELECT statements. While these backend-generic functions are\nuseful for ad-hoc querying and development, it is wisest to use\nbackend-specific functions in production for maximum control. Refer to\nbackend-specific documentation for more information.\n\n\nFor our examples, we will use the \nbeam-sqlite\n backend and demonstrate\nusage of the beam standard query functions.\n\n\nConnecting to a database\n\n\nOkay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient \nMonadBeam\n type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However, \nMonadBeam\n\ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the \nbeam-sqlite\n backend.\n\n\nFirst, install \nbeam-sqlite\n with \ncabal\n or \nstack\n:\n\n\n$ cabal install beam-sqlite\n\n# or\n\n$ stack install beam-sqlite\n\n\n\n\n\nNow, load \nbeam-sqlite\n in GHCi. \n\n\nPrelude\n \nimport\n \nDatabase.Beam.Sqlite\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n\n\n\n\n\nNow, in another terminal, load the example database provided. \n\n\n$ sqlite3 basics.db \n beam-sqlite/examples/basics.sql\n\n\n\n\n\nNow, back in GHCi, we can create a connection to this database.\n\n\nPrelude Database.Beam.Sqlite\n basics \n-\n open \nbasics.db\n\nPrelude Database.Beam.Sqlite\n withDatabase basics \n$\n runSelectReturningList \n(\nselect \n(\nall_ \n(\npersons exampleDb\n)))\n\n\n[\n \n..\n \n]\n\n\n\n\n\n\nThe \nrunSelectReturningList\n function takes a \nSqlSelect\n for the given syntax\nand returns the results via a list.\n\n\nVoil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.\n\n\nInserting data\n\n\nFirst, let's connect to a sqlite database, and create our schema. The\n\nbeam-core\n does not offer any support for the SQL DDL language. There\nis a separate core library \nbeam-migrate\n that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.\n\n\nFor our example, we will simply issue a \nCREATE TABLE\n command\ndirectly against the database using \nsqlite-simple\n functionality:\n\n\nPrelude Schema\n execute_ conn \nCREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )\n\n\n\n\n\n\nNow we can insert some data into our database. Beam ships with a\nfunction \nwithDatabase\n, with the following signature:\n\n\nwithDatabase\n \n::\n \nMonadBeam\n \nsyntax\n \nbe\n \nhdl\n \nm\n \n=\n \nhdl\n \n-\n \nm\n \na\n \n-\n \nIO\n \na\n\n\n\n\n\n\nMonadBeam\n is a type class that relates a particular SQL syntax (\nsyntax\n) to a\nbackend (\nbe\n), command monad (\nm\n), and database handle (\nhdl\n) type. Inside\nthe \nm\n monad, we can execute data query and manipulation commands. The \nhdl\n\ntype is usually the type of the connection in the underlying backend library.\n\n\nFor example, \nbeam-sqlite\n uses the \nsqlite-simple\n library, so its handle type\nis \nConnection\n from \nDatabase.SQLite.Simple\n.\n\n\nLet's insert some data into our database. We are going to use the \nrunInsert\n\nfunction from \nMonadBeam\n. INSERTs are discussed in more detail in\nthe \ndata manipulation guide\n.\n\n\nPrelude Schema\n :{\nPrelude Schema| withDatabase conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person \nBob\n \nSmith\n 50\nPrelude Schema|                            , Person \nAlice\n \nWong\n 55\nPrelude Schema|                            , Person \nJohn\n \nQuincy\n 30 ]\nPrelude Schema| :}\n\n\n\n\n\nThe \nrunInsert\n function has the type signature\n\n\nrunInsert\n \n::\n \nMonadBeam\n \nsyntax\n \nbe\n \nhdl\n \nm\n \n=\n \nSqlInsert\n \nsyntax\n \n-\n \nm\n \n()\n\n\n\n\n\n\nSqlInsert syntax\n represents a SQL \nINSERT\n command in the given\n\nsyntax\n. We construct this value using the \ninsert\n function from\n\nDatabase.Beam.Query\n.\n\n\ninsert\n \n::\n \nIsSql92InsertSyntax\n \nsyntax\n \n=\n\n          \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \ntable\n)\n\n       \n-\n \nSql92InsertValuesSyntax\n \nsyntax\n\n       \n-\n \nSqlInsert\n \nsyntax\n\n\n\n\n\n\nIntuitively, \ninsert\n takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values. \nSql92InsertValuesSyntax syntax\n always\nimplements the \nIsSql92InsertValuesSyntax\n typeclass, which is where\nwe get the \ninsertValues\n function from. \nIsSql92InsertValuesSyntax\n\nalso defines the \ninsertSelect\n function for inserting values from the\nresult of a \nSELECT\n statement. Other backends may provide other ways\nof specifying the source of values.\n\n\nNow, we can query the database, using the \nrunSelect\n function. Like \nrunInsert\n\nand \ninsert\n, we use the \nselect\n function to construct a value of type\n\nSqlSelect syntax\n, which can be run inside \nMonadBeam\n.\n\n\nWe can use the \nwithDatabaseDebug\n function to install a hook that beam will\ncall with every SQL command it is about to run. In the following example, beam\nwill print its query to stdout via \nputStrLn\n. You can use this functionality to hook beam in to a logging framework.\n\n\nPrelude Schema\n withDatabaseDebug putStrLn conn $ runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName = \nBob\n, personLastName=\nSmith\n, personAge=50 }, ... ]", 
            "title": "Backends"
        }, 
        {
            "location": "/user-guide/backends/#connecting-to-a-database", 
            "text": "Okay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient  MonadBeam  type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However,  MonadBeam \ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the  beam-sqlite  backend.  First, install  beam-sqlite  with  cabal  or  stack :  $ cabal install beam-sqlite # or \n$ stack install beam-sqlite  Now, load  beam-sqlite  in GHCi.   Prelude   import   Database.Beam.Sqlite  Prelude   Database . Beam . Sqlite    Now, in another terminal, load the example database provided.   $ sqlite3 basics.db   beam-sqlite/examples/basics.sql  Now, back in GHCi, we can create a connection to this database.  Prelude Database.Beam.Sqlite  basics  -  open  basics.db \nPrelude Database.Beam.Sqlite  withDatabase basics  $  runSelectReturningList  ( select  ( all_  ( persons exampleDb )))  [   ..   ]   The  runSelectReturningList  function takes a  SqlSelect  for the given syntax\nand returns the results via a list.  Voil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.", 
            "title": "Connecting to a database"
        }, 
        {
            "location": "/user-guide/backends/#inserting-data", 
            "text": "First, let's connect to a sqlite database, and create our schema. The beam-core  does not offer any support for the SQL DDL language. There\nis a separate core library  beam-migrate  that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.  For our example, we will simply issue a  CREATE TABLE  command\ndirectly against the database using  sqlite-simple  functionality:  Prelude Schema  execute_ conn  CREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )   Now we can insert some data into our database. Beam ships with a\nfunction  withDatabase , with the following signature:  withDatabase   ::   MonadBeam   syntax   be   hdl   m   =   hdl   -   m   a   -   IO   a   MonadBeam  is a type class that relates a particular SQL syntax ( syntax ) to a\nbackend ( be ), command monad ( m ), and database handle ( hdl ) type. Inside\nthe  m  monad, we can execute data query and manipulation commands. The  hdl \ntype is usually the type of the connection in the underlying backend library.  For example,  beam-sqlite  uses the  sqlite-simple  library, so its handle type\nis  Connection  from  Database.SQLite.Simple .  Let's insert some data into our database. We are going to use the  runInsert \nfunction from  MonadBeam . INSERTs are discussed in more detail in\nthe  data manipulation guide .  Prelude Schema  :{\nPrelude Schema| withDatabase conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person  Bob   Smith  50\nPrelude Schema|                            , Person  Alice   Wong  55\nPrelude Schema|                            , Person  John   Quincy  30 ]\nPrelude Schema| :}  The  runInsert  function has the type signature  runInsert   ::   MonadBeam   syntax   be   hdl   m   =   SqlInsert   syntax   -   m   ()   SqlInsert syntax  represents a SQL  INSERT  command in the given syntax . We construct this value using the  insert  function from Database.Beam.Query .  insert   ::   IsSql92InsertSyntax   syntax   = \n           DatabaseEntity   be   db   ( TableEntity   table ) \n        -   Sql92InsertValuesSyntax   syntax \n        -   SqlInsert   syntax   Intuitively,  insert  takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values.  Sql92InsertValuesSyntax syntax  always\nimplements the  IsSql92InsertValuesSyntax  typeclass, which is where\nwe get the  insertValues  function from.  IsSql92InsertValuesSyntax \nalso defines the  insertSelect  function for inserting values from the\nresult of a  SELECT  statement. Other backends may provide other ways\nof specifying the source of values.  Now, we can query the database, using the  runSelect  function. Like  runInsert \nand  insert , we use the  select  function to construct a value of type SqlSelect syntax , which can be run inside  MonadBeam .  We can use the  withDatabaseDebug  function to install a hook that beam will\ncall with every SQL command it is about to run. In the following example, beam\nwill print its query to stdout via  putStrLn . You can use this functionality to hook beam in to a logging framework.  Prelude Schema  withDatabaseDebug putStrLn conn $ runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName =  Bob , personLastName= Smith , personAge=50 }, ... ]", 
            "title": "Inserting data"
        }, 
        {
            "location": "/user-guide/queries/basic/", 
            "text": "Given our database definition and database descriptor, we can query database\nentities and retrieve data. Before we discuss writing queries, we will take a\nlook at some of the important query types.\n\n\nData types\n\n\nThe \nQ\n data type\n\n\nBeam queries are built using the \nQ\n data type. \nQ\n's signature is as follows\n\n\ndata\n \nQ\n \nsyntax\n \ndb\n \ns\n \na\n\n\n\n\n\n\nIn this definition\n\n\n\n\n\n\nsyntax\n is the particular dialect of SQL this \nQ\n monad will evaluate to.\n  Often times, this is any instance of \nIsSql92SelectSyntax\n, but sometimes you\n  use syntax-specific features. For example, if you want to use named windows in\n  postgres, you'll likely have to specialize this to \nPgSelectSyntax\n from\n  \nDatabase.Beam.Postgres.Syntax\n.\n\n\n\n\n\n\ndb\n is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.\n\n\n\n\n\n\ns\n is the scope parameter. For the most part, you'll write your queries so\n  that they work over all \ns\n. Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.\n\n\n\n\n\n\na\n is the type of the result of the query.\n\n\n\n\n\n\nThe \nQGenExpr\n type\n\n\nWhile \nQ\n represents the result of whole queries (entire \nSELECT\ns for example),\n\nQGenExpr\n represents the type of SQL expressions. \nQGenExpr\n also takes some\ntype parameters:\n\n\ndata\n \nQGenExpr\n \ncontext\n \nsyntax\n \ns\n \na\n\n\n\n\n\n\n\n\n\n\ncontext\n is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have \ncontext ~ QAggregateContext\n.\n  Expressions returning scalar values have \ncontext ~ QValueContext\n.\n\n\n\n\n\n\nsyntax\n is the particular SQL dialect this expression is written in. Note\n  that this is usually different than the \nsyntax\n for \nQ\n, because \nQ\n's syntax\n  refers to a particular syntax for \nSELECT\n expressions (a type implementing\n  \nIsSql92SelectSyntax\n), while \nQGenExpr\n's syntax usually refers to an\n  expression syntax (a type implementing \nIsSql92ExpressionSyntax\n). Of course,\n  since syntaxes are related, you can get from a \nQ\n \nSELECT\n syntax to a\n  \nQGenExpr\n \nsyntax\n with the \nSql92SelectExpressionSyntax\n type family.\n\n\n\n\n\n\nThus, a \nQGenExpr\n with syntax \nSql92SelectExpressionSyntax select\n can be\n  used in the \nFILTER\n clause of a query with type \nQ select db s a\n.\n\n\n\n\n\n\ns\n is a scoping parameter, which will match the \ns\n in \nQ\n.\n\n\n\n\n\n\na\n is the type of this expression. For example, expressions returning SQL\n  \nint\n values, will have Haskell type \nInt\n. This ensures that your SQL query\n  won't fail at run-time with a type error.\n\n\n\n\n\n\nBeam defines some specializations of \nQGenExpr\n for common uses.\n\n\ntype\n \nQExpr\n \n=\n \nQGenExpr\n \nQValueContext\n\n\ntype\n \nQAgg\n \n=\n \nQGenExpr\n \nQAggregateContext\n\n\ntype\n \nQOrd\n \n=\n \nQGenExpr\n \nQOrderingContext\n\n\ntype\n \nQWindowExpr\n \n=\n \nQGenExpr\n \nQWindowingContext\n\n\ntype\n \nQWindowFrame\n \n=\n \nQGenExpr\n \nQWindowFrameContext\n\n\ntype\n \nQGroupExpr\n \n=\n \nQGenExpr\n \nQGroupingContext\n\n\n\n\n\n\nThus, value expressions can be given the simpler type of \nQExpr syntax s a\n.\nExpressions containing aggregates are typed as \nQAgg syntax s a\n.\n\n\nA note on type inference\n\n\nThese types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.\n\n\nBut alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example, \nSELECT\ning just the literal \n1\n may cause an ambiguity, because\nthe compiler won't know which \nIntegral\n type to use. Beam provides an easy\nutility function \nas_\n for this. With \n-XTypeApplications\n enabled,\n\n\nas_\n \n@\nInt\n \n(\nambiguous\n \nexpression\n)\n\n\n\n\n\n\nensures that \nambiguous expression\n has the type \nQGenExpr ctxt syntax s Int\n\nwith the \nctxt\n, \nsyntax\n, and \ns\n types appropriately inferred.\n\n\nSimple queries\n\n\nThe easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type \nDatabaseSettings be db\n) with some\ntable or view entities, you can use the \nall_\n function to retrieve all rows in\na specific table or view.\n\n\nFor example, to retrieve all \nPersonT\n entries in the \nexampleDb\n we defined in\nthe last section, we can say \n\n\nall_\n \n(\npersons\n \nexampleDb\n)\n \n::\n \nQ\n \nsyntax\n \nExampleDb\n \ns\n \n(\nPersonT\n \n(\nQExpr\n \ns\n))\n\n\n\n\n\n\n\n\nNote\n\n\nWe give the full type of the query here for illustrative purposes only. There \nis no need to do so in your own code\n\n\n\n\nTwo things to note. Firstly, here \nPersonT\n is parameterized over the \nQExpr s\n\nhigher-kinded type. This means that each field in \nPersonT\n now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.\n\n\nThus,\n\n\npersonFirstName\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n \n::\n \nQExpr\n \ns\n \nText\n\n\n\n\n\n\nand\n\n\npersonFirstName\n \n(\nPerson\n \nJohn\n \nSmith\n \n23\n \njohn.smith@example.com\n \n8888888888\n \n::\n \nPerson\n)\n \n::\n \nText\n\n\n\n\n\n\nSecondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of \ns\n from outside \nQ\n.\n\n\nOnce we have a query in terms of \nQ\n, we can use the \nselect\n function from\n\nDatabase.Beam.Query\n to turn it into a select statement that can be run against\nthe backend. \nselect\n takes an expression of type \nQ\n, and converts it into a\nSQL statement, ready to be executed against the database.\n\n\nThe output of the query passed to \nselect\n must follow some conventions, so that\nbeam knows how to serialize, deserialize, and project the appropriate values\nfrom the query. In particular, the return type of your query must be either\n\n\n\n\na plain expression (i.e., type \nQExpr\n),\n\n\na \nBeamable\n type (i.e., a table or primary key, defined as above), or\n\n\nany combination of tuples of the above (Beam supports up to 8-tuples by\n  default). Higher-order tuples can be formed by nested tuples. For example, for\n  16 return values, you can return a 2-tuple of 8-tuples or an 8-tuple of\n  2-tuples or a 4-tuple of 4-tuples, etc.\n\n\n\n\nWith this in mind, we can use \nselect\n to get a query statement against our\ndatabase. The return type of \nall_\n is just the table we ask for. In this case,\nwe're interested in the \npersons\n table. The \npersons\n table has the \nBeamable\n\ntype \nPersonT\n. As expected, the \nSqlSelect\n will return us concrete \nPerson\n\nvalues (recall that \nPerson\n is equivalent to \nPersonT Identity\n).\n\n\nselect\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n \n::\n \n(\n...\n)\n \n=\n \nSqlSelect\n \nsyntax\n \nPerson\n\n\n\n\n\n\nThe \n...\n in the context represents a bunch of requirements for \nsyntax\n that\nGHC will generate.\n\n\nNormally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.\n\n\ndumpSqlSelect\n \n(\nall_\n \n(\npersons\n \nexampleDb\n))\n\n\nSELECT\n \nt0\n.\nfirst_name\n \nAS\n \nres0\n,\n \nt0\n.\nlast_name\n \nAS\n \nres1\n,\n \nt0\n.\nage\n \nAS\n \nres2\n,\n \nt0\n.\nemail\n \nAS\n \nres3\n,\n \nt0\n.\nphone\n \nAS\n \nres4\n \nFROM\n \nperson\n \nAS\n \nt0\n\n\n\n\n\n\nInternally, \ndumpSqlSelect\n uses a \nbeam-core\n provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.\n\n\n\n\nTip\n\n\nall_\n only works for \nTableEntity\ns. Use \nallFromView_\n for \nViewEntity\ns.\n\n\n\n\nA note on composability\n\n\nAll beam queries are \ncomposable\n. This means that you can freely mix values of\ntype \nQ\n in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.\n\n\nFor example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, limit the amount of rows returned and then join these rows with\nanother table. In SQL, you'd have to write explicit subselects, take care of\nhandling projections, etc. This is because this query doesn't fit into the\n'standard' SQL query structure.\n\n\nHowever, in beam, you can simply write this query. Beam will take care of\ngenerating explicit subselects and handling projections. Scoping rules enforced\nby the Haskell type system ensure that the query is constructed correctly.\n\n\nFor example, we can write the following (meaningless) query, and things will work as expected.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ntbl1\n \n-\n \n     \nlimit_\n \n10\n \n$\n\n     \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                           \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n             \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n   \ntbl2\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \npure\n \n(\ntbl1\n,\n \ntbl2\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nres2\n AS \nres2\n,\n\n\n       \nt0\n.\nres3\n AS \nres3\n,\n\n\n       \nt0\n.\nres4\n AS \nres4\n,\n\n\n       \nt0\n.\nres5\n AS \nres5\n,\n\n\n       \nt0\n.\nres6\n AS \nres6\n,\n\n\n       \nt0\n.\nres7\n AS \nres7\n,\n\n\n       \nt0\n.\nres8\n AS \nres8\n,\n\n\n       \nt0\n.\nres9\n AS \nres9\n,\n\n\n       \nt0\n.\nres10\n AS \nres10\n,\n\n\n       \nt0\n.\nres11\n AS \nres11\n,\n\n\n       \nt0\n.\nres12\n AS \nres12\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres13\n,\n\n\n       \nt1\n.\nName\n AS \nres14\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres15\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres16\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres17\n,\n\n\n       \nt1\n.\nComposer\n AS \nres18\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres19\n,\n\n\n       \nt1\n.\nBytes\n AS \nres20\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres21\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n          \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n          \nt0\n.\nLastName\n AS \nres2\n,\n\n\n          \nt0\n.\nCompany\n AS \nres3\n,\n\n\n          \nt0\n.\nAddress\n AS \nres4\n,\n\n\n          \nt0\n.\nCity\n AS \nres5\n,\n\n\n          \nt0\n.\nState\n AS \nres6\n,\n\n\n          \nt0\n.\nCountry\n AS \nres7\n,\n\n\n          \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n          \nt0\n.\nPhone\n AS \nres9\n,\n\n\n          \nt0\n.\nFax\n AS \nres10\n,\n\n\n          \nt0\n.\nEmail\n AS \nres11\n,\n\n\n          \nt0\n.\nSupportRepId\n AS \nres12\n\n\n   FROM \nCustomer\n AS \nt0\n\n\n   WHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n\n\n          AND ((\nt0\n.\nLastName\n) LIKE (?)))\n\n\n     AND (((\nt0\n.\nState\n)=(?))\n\n\n          OR ((\nt0\n.\nState\n)=(?)))\n\n\n   LIMIT 10) AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n -- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n(((\nt0\n.\nState\n)\n \n=\n \n(\nCA\n))\n\n          \nOR\n \n((\nt0\n.\nState\n)\n \n=\n \n(\nWA\n)))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThis allows you to easily factor out queries. This means you can build a query\nlibrary in your application and then freely mix and match these queries as\nnecessary. This allows you to offload as much processing to the database as\npossible, rather than shipping data to your application pre-processing.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- \ncomplicatedQuery\n could be declared and imported from an external module here. The generated query is the same regardless\n\n\nlet\n \ncomplicatedQuery\n \n=\n \n       \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                             \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n               \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\nin\n \ndo\n \ntbl1\n \n-\n \nlimit_\n \n10\n \n$\n \ncomplicatedQuery\n\n      \ntbl2\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n      \npure\n \n(\ntbl1\n,\n \ntbl2\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nres2\n AS \nres2\n,\n\n\n       \nt0\n.\nres3\n AS \nres3\n,\n\n\n       \nt0\n.\nres4\n AS \nres4\n,\n\n\n       \nt0\n.\nres5\n AS \nres5\n,\n\n\n       \nt0\n.\nres6\n AS \nres6\n,\n\n\n       \nt0\n.\nres7\n AS \nres7\n,\n\n\n       \nt0\n.\nres8\n AS \nres8\n,\n\n\n       \nt0\n.\nres9\n AS \nres9\n,\n\n\n       \nt0\n.\nres10\n AS \nres10\n,\n\n\n       \nt0\n.\nres11\n AS \nres11\n,\n\n\n       \nt0\n.\nres12\n AS \nres12\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres13\n,\n\n\n       \nt1\n.\nName\n AS \nres14\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres15\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres16\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres17\n,\n\n\n       \nt1\n.\nComposer\n AS \nres18\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres19\n,\n\n\n       \nt1\n.\nBytes\n AS \nres20\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres21\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n          \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n          \nt0\n.\nLastName\n AS \nres2\n,\n\n\n          \nt0\n.\nCompany\n AS \nres3\n,\n\n\n          \nt0\n.\nAddress\n AS \nres4\n,\n\n\n          \nt0\n.\nCity\n AS \nres5\n,\n\n\n          \nt0\n.\nState\n AS \nres6\n,\n\n\n          \nt0\n.\nCountry\n AS \nres7\n,\n\n\n          \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n          \nt0\n.\nPhone\n AS \nres9\n,\n\n\n          \nt0\n.\nFax\n AS \nres10\n,\n\n\n          \nt0\n.\nEmail\n AS \nres11\n,\n\n\n          \nt0\n.\nSupportRepId\n AS \nres12\n\n\n   FROM \nCustomer\n AS \nt0\n\n\n   WHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n\n\n          AND ((\nt0\n.\nLastName\n) LIKE (?)))\n\n\n     AND (((\nt0\n.\nState\n)=(?))\n\n\n          OR ((\nt0\n.\nState\n)=(?)))\n\n\n   LIMIT 10) AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n -- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt0\n.\nres9\n \nAS\n \nres9\n,\n\n       \nt0\n.\nres10\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres11\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres12\n \nAS\n \nres12\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres13\n,\n\n       \nt1\n.\nName\n \nAS\n \nres14\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres15\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres16\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres17\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres18\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres19\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres20\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres21\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n          \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n          \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n          \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n          \nt0\n.\nState\n \nAS\n \nres6\n,\n\n          \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n          \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n          \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n          \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n          \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n          \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n\n   \nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n          \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n     \nAND\n \n(((\nt0\n.\nState\n)\n \n=\n \n(\nCA\n))\n\n          \nOR\n \n((\nt0\n.\nState\n)\n \n=\n \n(\nWA\n)))\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1", 
            "title": "Basic Queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#data-types", 
            "text": "", 
            "title": "Data types"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-q-data-type", 
            "text": "Beam queries are built using the  Q  data type.  Q 's signature is as follows  data   Q   syntax   db   s   a   In this definition    syntax  is the particular dialect of SQL this  Q  monad will evaluate to.\n  Often times, this is any instance of  IsSql92SelectSyntax , but sometimes you\n  use syntax-specific features. For example, if you want to use named windows in\n  postgres, you'll likely have to specialize this to  PgSelectSyntax  from\n   Database.Beam.Postgres.Syntax .    db  is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.    s  is the scope parameter. For the most part, you'll write your queries so\n  that they work over all  s . Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.    a  is the type of the result of the query.", 
            "title": "The Q data type"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-qgenexpr-type", 
            "text": "While  Q  represents the result of whole queries (entire  SELECT s for example), QGenExpr  represents the type of SQL expressions.  QGenExpr  also takes some\ntype parameters:  data   QGenExpr   context   syntax   s   a     context  is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have  context ~ QAggregateContext .\n  Expressions returning scalar values have  context ~ QValueContext .    syntax  is the particular SQL dialect this expression is written in. Note\n  that this is usually different than the  syntax  for  Q , because  Q 's syntax\n  refers to a particular syntax for  SELECT  expressions (a type implementing\n   IsSql92SelectSyntax ), while  QGenExpr 's syntax usually refers to an\n  expression syntax (a type implementing  IsSql92ExpressionSyntax ). Of course,\n  since syntaxes are related, you can get from a  Q   SELECT  syntax to a\n   QGenExpr   syntax  with the  Sql92SelectExpressionSyntax  type family.    Thus, a  QGenExpr  with syntax  Sql92SelectExpressionSyntax select  can be\n  used in the  FILTER  clause of a query with type  Q select db s a .    s  is a scoping parameter, which will match the  s  in  Q .    a  is the type of this expression. For example, expressions returning SQL\n   int  values, will have Haskell type  Int . This ensures that your SQL query\n  won't fail at run-time with a type error.    Beam defines some specializations of  QGenExpr  for common uses.  type   QExpr   =   QGenExpr   QValueContext  type   QAgg   =   QGenExpr   QAggregateContext  type   QOrd   =   QGenExpr   QOrderingContext  type   QWindowExpr   =   QGenExpr   QWindowingContext  type   QWindowFrame   =   QGenExpr   QWindowFrameContext  type   QGroupExpr   =   QGenExpr   QGroupingContext   Thus, value expressions can be given the simpler type of  QExpr syntax s a .\nExpressions containing aggregates are typed as  QAgg syntax s a .", 
            "title": "The QGenExpr type"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-type-inference", 
            "text": "These types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.  But alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example,  SELECT ing just the literal  1  may cause an ambiguity, because\nthe compiler won't know which  Integral  type to use. Beam provides an easy\nutility function  as_  for this. With  -XTypeApplications  enabled,  as_   @ Int   ( ambiguous   expression )   ensures that  ambiguous expression  has the type  QGenExpr ctxt syntax s Int \nwith the  ctxt ,  syntax , and  s  types appropriately inferred.", 
            "title": "A note on type inference"
        }, 
        {
            "location": "/user-guide/queries/basic/#simple-queries", 
            "text": "The easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type  DatabaseSettings be db ) with some\ntable or view entities, you can use the  all_  function to retrieve all rows in\na specific table or view.  For example, to retrieve all  PersonT  entries in the  exampleDb  we defined in\nthe last section, we can say   all_   ( persons   exampleDb )   ::   Q   syntax   ExampleDb   s   ( PersonT   ( QExpr   s ))    Note  We give the full type of the query here for illustrative purposes only. There \nis no need to do so in your own code   Two things to note. Firstly, here  PersonT  is parameterized over the  QExpr s \nhigher-kinded type. This means that each field in  PersonT  now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.  Thus,  personFirstName   ( all_   ( persons   exampleDb ))   ::   QExpr   s   Text   and  personFirstName   ( Person   John   Smith   23   john.smith@example.com   8888888888   ::   Person )   ::   Text   Secondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of  s  from outside  Q .  Once we have a query in terms of  Q , we can use the  select  function from Database.Beam.Query  to turn it into a select statement that can be run against\nthe backend.  select  takes an expression of type  Q , and converts it into a\nSQL statement, ready to be executed against the database.  The output of the query passed to  select  must follow some conventions, so that\nbeam knows how to serialize, deserialize, and project the appropriate values\nfrom the query. In particular, the return type of your query must be either   a plain expression (i.e., type  QExpr ),  a  Beamable  type (i.e., a table or primary key, defined as above), or  any combination of tuples of the above (Beam supports up to 8-tuples by\n  default). Higher-order tuples can be formed by nested tuples. For example, for\n  16 return values, you can return a 2-tuple of 8-tuples or an 8-tuple of\n  2-tuples or a 4-tuple of 4-tuples, etc.   With this in mind, we can use  select  to get a query statement against our\ndatabase. The return type of  all_  is just the table we ask for. In this case,\nwe're interested in the  persons  table. The  persons  table has the  Beamable \ntype  PersonT . As expected, the  SqlSelect  will return us concrete  Person \nvalues (recall that  Person  is equivalent to  PersonT Identity ).  select   ( all_   ( persons   exampleDb ))   ::   ( ... )   =   SqlSelect   syntax   Person   The  ...  in the context represents a bunch of requirements for  syntax  that\nGHC will generate.  Normally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.  dumpSqlSelect   ( all_   ( persons   exampleDb ))  SELECT   t0 . first_name   AS   res0 ,   t0 . last_name   AS   res1 ,   t0 . age   AS   res2 ,   t0 . email   AS   res3 ,   t0 . phone   AS   res4   FROM   person   AS   t0   Internally,  dumpSqlSelect  uses a  beam-core  provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.   Tip  all_  only works for  TableEntity s. Use  allFromView_  for  ViewEntity s.", 
            "title": "Simple queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-composability", 
            "text": "All beam queries are  composable . This means that you can freely mix values of\ntype  Q  in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.  For example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, limit the amount of rows returned and then join these rows with\nanother table. In SQL, you'd have to write explicit subselects, take care of\nhandling projections, etc. This is because this query doesn't fit into the\n'standard' SQL query structure.  However, in beam, you can simply write this query. Beam will take care of\ngenerating explicit subselects and handling projections. Scoping rules enforced\nby the Haskell type system ensure that the query is constructed correctly.  For example, we can write the following (meaningless) query, and things will work as expected.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   tbl1   -  \n      limit_   10   $ \n      filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                            ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n              all_   ( customer   chinookDb ) \n    tbl2   -   all_   ( track   chinookDb ) \n    pure   ( tbl1 ,   tbl2 )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t0 . res2  AS  res2 ,          t0 . res3  AS  res3 ,          t0 . res4  AS  res4 ,          t0 . res5  AS  res5 ,          t0 . res6  AS  res6 ,          t0 . res7  AS  res7 ,          t0 . res8  AS  res8 ,          t0 . res9  AS  res9 ,          t0 . res10  AS  res10 ,          t0 . res11  AS  res11 ,          t0 . res12  AS  res12 ,          t1 . TrackId  AS  res13 ,          t1 . Name  AS  res14 ,          t1 . AlbumId  AS  res15 ,          t1 . MediaTypeId  AS  res16 ,          t1 . GenreId  AS  res17 ,          t1 . Composer  AS  res18 ,          t1 . Milliseconds  AS  res19 ,          t1 . Bytes  AS  res20 ,          t1 . UnitPrice  AS  res21  FROM    (SELECT  t0 . CustomerId  AS  res0 ,             t0 . FirstName  AS  res1 ,             t0 . LastName  AS  res2 ,             t0 . Company  AS  res3 ,             t0 . Address  AS  res4 ,             t0 . City  AS  res5 ,             t0 . State  AS  res6 ,             t0 . Country  AS  res7 ,             t0 . PostalCode  AS  res8 ,             t0 . Phone  AS  res9 ,             t0 . Fax  AS  res10 ,             t0 . Email  AS  res11 ,             t0 . SupportRepId  AS  res12     FROM  Customer  AS  t0     WHERE ((( t0 . FirstName ) LIKE (?))            AND (( t0 . LastName ) LIKE (?)))       AND ((( t0 . State )=(?))            OR (( t0 . State )=(?)))     LIMIT 10) AS  t0  INNER JOIN  Track  AS  t1  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n           AND   (( t0 . LastName )   LIKE   ( S% ))) \n      AND   ((( t0 . State )   =   ( CA )) \n           OR   (( t0 . State )   =   ( WA ))) \n    LIMIT   10 )   AS   t0  INNER   JOIN   Track   AS   t1  \n\n         \n    \n         \n    \n                 \n                      This allows you to easily factor out queries. This means you can build a query\nlibrary in your application and then freely mix and match these queries as\nnecessary. This allows you to offload as much processing to the database as\npossible, rather than shipping data to your application pre-processing.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             --  complicatedQuery  could be declared and imported from an external module here. The generated query is the same regardless  let   complicatedQuery   =  \n        filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                              ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n                all_   ( customer   chinookDb )  in   do   tbl1   -   limit_   10   $   complicatedQuery \n       tbl2   -   all_   ( track   chinookDb ) \n       pure   ( tbl1 ,   tbl2 )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t0 . res2  AS  res2 ,          t0 . res3  AS  res3 ,          t0 . res4  AS  res4 ,          t0 . res5  AS  res5 ,          t0 . res6  AS  res6 ,          t0 . res7  AS  res7 ,          t0 . res8  AS  res8 ,          t0 . res9  AS  res9 ,          t0 . res10  AS  res10 ,          t0 . res11  AS  res11 ,          t0 . res12  AS  res12 ,          t1 . TrackId  AS  res13 ,          t1 . Name  AS  res14 ,          t1 . AlbumId  AS  res15 ,          t1 . MediaTypeId  AS  res16 ,          t1 . GenreId  AS  res17 ,          t1 . Composer  AS  res18 ,          t1 . Milliseconds  AS  res19 ,          t1 . Bytes  AS  res20 ,          t1 . UnitPrice  AS  res21  FROM    (SELECT  t0 . CustomerId  AS  res0 ,             t0 . FirstName  AS  res1 ,             t0 . LastName  AS  res2 ,             t0 . Company  AS  res3 ,             t0 . Address  AS  res4 ,             t0 . City  AS  res5 ,             t0 . State  AS  res6 ,             t0 . Country  AS  res7 ,             t0 . PostalCode  AS  res8 ,             t0 . Phone  AS  res9 ,             t0 . Fax  AS  res10 ,             t0 . Email  AS  res11 ,             t0 . SupportRepId  AS  res12     FROM  Customer  AS  t0     WHERE ((( t0 . FirstName ) LIKE (?))            AND (( t0 . LastName ) LIKE (?)))       AND ((( t0 . State )=(?))            OR (( t0 . State )=(?)))     LIMIT 10) AS  t0  INNER JOIN  Track  AS  t1  -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t0 . res9   AS   res9 , \n        t0 . res10   AS   res10 , \n        t0 . res11   AS   res11 , \n        t0 . res12   AS   res12 , \n        t1 . TrackId   AS   res13 , \n        t1 . Name   AS   res14 , \n        t1 . AlbumId   AS   res15 , \n        t1 . MediaTypeId   AS   res16 , \n        t1 . GenreId   AS   res17 , \n        t1 . Composer   AS   res18 , \n        t1 . Milliseconds   AS   res19 , \n        t1 . Bytes   AS   res20 , \n        t1 . UnitPrice   AS   res21  FROM \n   ( SELECT   t0 . CustomerId   AS   res0 , \n           t0 . FirstName   AS   res1 , \n           t0 . LastName   AS   res2 , \n           t0 . Company   AS   res3 , \n           t0 . Address   AS   res4 , \n           t0 . City   AS   res5 , \n           t0 . State   AS   res6 , \n           t0 . Country   AS   res7 , \n           t0 . PostalCode   AS   res8 , \n           t0 . Phone   AS   res9 , \n           t0 . Fax   AS   res10 , \n           t0 . Email   AS   res11 , \n           t0 . SupportRepId   AS   res12 \n    FROM   Customer   AS   t0 \n    WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n           AND   (( t0 . LastName )   LIKE   ( S% ))) \n      AND   ((( t0 . State )   =   ( CA )) \n           OR   (( t0 . State )   =   ( WA ))) \n    LIMIT   10 )   AS   t0  INNER   JOIN   Track   AS   t1", 
            "title": "A note on composability"
        }, 
        {
            "location": "/user-guide/queries/select/", 
            "text": "We've seen how to create simple queries from our schema. Beam supports other\nclauses in the SQL SELECT statement.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database. The Chinook database schema is modeled after a\nfictional record store. It provides several tables containing information on the\nmusic as well as the billing operations. Thus, it provides a good 'real-world'\ndemonstration of beam's capabalities.\n\n\nFirst, create a SQLite database from the included example.\n\n\n$\n sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n:\nload\n \nbeam\n-\nsqlite\n/\nexamples\n/\nChinook\n/\nSchema\n.\nhs\n\n\nPrelude\n \nChinook\n.\nSchema\n \nchinook\n \n-\n \nopen\n \nchinook.db\n\n\n\n\n\n\nOne more thing, before we see more complex examples, let's define a quick\nutility function.\n\n\nPrelude\n \nChinook\n.\nSchema\n \nlet\n \nwithConnectionTutorial\n \n=\n \nwithDatabaseDebug\n \nputStrLn\n \nchinook\n\n\n\n\n\n\nLet's test it!\n\n\nWe can run all our queries like:\n\n\nwithConnectionTutorial\n \n$\n \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nquery\n\n\n\n\n\n\nLet's select all the tracks.\n\n\nwithConnectionTutorial\n \n$\n \nrunSelectReturningList\n \n$\n \nselect\n \n$\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n\n\nFor the rest of the guide, we will also show the generated SQL code for both\nsqlite and postgres.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nTrackId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       \nt0\n.\nAlbumId\n AS \nres2\n,\n\n\n       \nt0\n.\nMediaTypeId\n AS \nres3\n,\n\n\n       \nt0\n.\nGenreId\n AS \nres4\n,\n\n\n       \nt0\n.\nComposer\n AS \nres5\n,\n\n\n       \nt0\n.\nMilliseconds\n AS \nres6\n,\n\n\n       \nt0\n.\nBytes\n AS \nres7\n,\n\n\n       \nt0\n.\nUnitPrice\n AS \nres8\n\n\nFROM \nTrack\n AS \nt0\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nTrackId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres3\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres5\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres7\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres8\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWHERE\n clause\n\n\nWe've seen how to use \nall_\n to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the \nfilter_\n function.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ncustomer\n \n-\n \ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n$\n\n\nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n       \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n       \nt0\n.\nLastName\n AS \nres2\n,\n\n\n       \nt0\n.\nCompany\n AS \nres3\n,\n\n\n       \nt0\n.\nAddress\n AS \nres4\n,\n\n\n       \nt0\n.\nCity\n AS \nres5\n,\n\n\n       \nt0\n.\nState\n AS \nres6\n,\n\n\n       \nt0\n.\nCountry\n AS \nres7\n,\n\n\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n       \nt0\n.\nPhone\n AS \nres9\n,\n\n\n       \nt0\n.\nFax\n AS \nres10\n,\n\n\n       \nt0\n.\nEmail\n AS \nres11\n,\n\n\n       \nt0\n.\nSupportRepId\n AS \nres12\n\n\nFROM \nCustomer\n AS \nt0\n\n\nWHERE (\nt0\n.\nFirstName\n) LIKE (?) -- With values: [SQLText \nJo%\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can use \n(\n.)\n and \n(||.)\n to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n       \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n       \nt0\n.\nLastName\n AS \nres2\n,\n\n\n       \nt0\n.\nCompany\n AS \nres3\n,\n\n\n       \nt0\n.\nAddress\n AS \nres4\n,\n\n\n       \nt0\n.\nCity\n AS \nres5\n,\n\n\n       \nt0\n.\nState\n AS \nres6\n,\n\n\n       \nt0\n.\nCountry\n AS \nres7\n,\n\n\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n       \nt0\n.\nPhone\n AS \nres9\n,\n\n\n       \nt0\n.\nFax\n AS \nres10\n,\n\n\n       \nt0\n.\nEmail\n AS \nres11\n,\n\n\n       \nt0\n.\nSupportRepId\n AS \nres12\n\n\nFROM \nCustomer\n AS \nt0\n\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n\n\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n\n\n  AND (((\nt0\n.\nState\n)=(?))\n\n\n       OR ((\nt0\n.\nState\n)=(?))) -- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \n=\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \n=\n \n(\nWA\n)))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nWe had to use the \njust_\n function above to compare\n\naddressState (customerAddress customer)\n. This is because \naddressState\n(customerAddress customer)\n represents a nullable column which beam types as\n\nMaybe Text\n. Just as in Haskell, we need to explicitly unwrap the \nMaybe\n\ntype. This is an example of beam offering stronger typing than SQL itself.\n\n\n\n\nLIMIT\n/\nOFFSET\n support\n\n\nThe \nlimit_\n and \noffset_\n functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe \nLIMIT\n and \nOFFSET\n SQL constructs.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n \noffset_\n \n100\n \n$\n\n\nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n       \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n       \nt0\n.\nLastName\n AS \nres2\n,\n\n\n       \nt0\n.\nCompany\n AS \nres3\n,\n\n\n       \nt0\n.\nAddress\n AS \nres4\n,\n\n\n       \nt0\n.\nCity\n AS \nres5\n,\n\n\n       \nt0\n.\nState\n AS \nres6\n,\n\n\n       \nt0\n.\nCountry\n AS \nres7\n,\n\n\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n       \nt0\n.\nPhone\n AS \nres9\n,\n\n\n       \nt0\n.\nFax\n AS \nres10\n,\n\n\n       \nt0\n.\nEmail\n AS \nres11\n,\n\n\n       \nt0\n.\nSupportRepId\n AS \nres12\n\n\nFROM \nCustomer\n AS \nt0\n\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n\n\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n\n\n  AND (((\nt0\n.\nState\n)=(?))\n\n\n       OR ((\nt0\n.\nState\n)=(?)))\n\n\nLIMIT 10\n\n\nOFFSET 100 -- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \n=\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \n=\n \n(\nWA\n)))\n\n\nLIMIT\n \n10\n\n\nOFFSET\n \n100\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nNested \nlimit_\ns and \noffset_\ns compose in the way you'd expect without\ngenerating extraneous subqueries.\n\n\n\n\n\n\nWarning\n\n\nNote that the order of the \nlimit_\n and \noffset_\n functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \noffset_\n \n100\n \n$\n \nlimit_\n \n10\n \n$\n\n\nfilter_\n \n(\n\\\ncustomer\n \n-\n \n((\ncustomerFirstName\n \ncustomer\n \n`\nlike_\n`\n \nJo%\n)\n \n.\n \n(\ncustomerLastName\n \ncustomer\n \n`\nlike_\n`\n \nS%\n))\n \n.\n\n                      \n(\naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nCA\n \n||.\n \naddressState\n \n(\ncustomerAddress\n \ncustomer\n)\n \n==.\n \njust_\n \nWA\n))\n \n$\n\n        \nall_\n \n(\ncustomer\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n\n\n       \nt0\n.\nFirstName\n AS \nres1\n,\n\n\n       \nt0\n.\nLastName\n AS \nres2\n,\n\n\n       \nt0\n.\nCompany\n AS \nres3\n,\n\n\n       \nt0\n.\nAddress\n AS \nres4\n,\n\n\n       \nt0\n.\nCity\n AS \nres5\n,\n\n\n       \nt0\n.\nState\n AS \nres6\n,\n\n\n       \nt0\n.\nCountry\n AS \nres7\n,\n\n\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n\n\n       \nt0\n.\nPhone\n AS \nres9\n,\n\n\n       \nt0\n.\nFax\n AS \nres10\n,\n\n\n       \nt0\n.\nEmail\n AS \nres11\n,\n\n\n       \nt0\n.\nSupportRepId\n AS \nres12\n\n\nFROM \nCustomer\n AS \nt0\n\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n\n\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n\n\n  AND (((\nt0\n.\nState\n)=(?))\n\n\n       OR ((\nt0\n.\nState\n)=(?)))\n\n\nLIMIT 0\n\n\nOFFSET 100 -- With values: [SQLText \nJo%\n,SQLText \nS%\n,SQLText \nCA\n,SQLText \nWA\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nCompany\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres4\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres5\n,\n\n       \nt0\n.\nState\n \nAS\n \nres6\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres7\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres8\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres9\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres10\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres11\n,\n\n       \nt0\n.\nSupportRepId\n \nAS\n \nres12\n\n\nFROM\n \nCustomer\n \nAS\n \nt0\n\n\nWHERE\n \n(((\nt0\n.\nFirstName\n)\n \nLIKE\n \n(\nJo%\n))\n\n       \nAND\n \n((\nt0\n.\nLastName\n)\n \nLIKE\n \n(\nS%\n)))\n\n  \nAND\n \n(((\nt0\n.\nState\n)\n \n=\n \n(\nCA\n))\n\n       \nOR\n \n((\nt0\n.\nState\n)\n \n=\n \n(\nWA\n)))\n\n\nLIMIT\n \n0\n\n\nOFFSET\n \n100", 
            "title": "More complex SELECTs"
        }, 
        {
            "location": "/user-guide/queries/select/#where-clause", 
            "text": "We've seen how to use  all_  to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the  filter_  function.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ customer   -   customerFirstName   customer   ` like_ `   Jo% )   $  all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,          t0 . FirstName  AS  res1 ,          t0 . LastName  AS  res2 ,          t0 . Company  AS  res3 ,          t0 . Address  AS  res4 ,          t0 . City  AS  res5 ,          t0 . State  AS  res6 ,          t0 . Country  AS  res7 ,          t0 . PostalCode  AS  res8 ,          t0 . Phone  AS  res9 ,          t0 . Fax  AS  res10 ,          t0 . Email  AS  res11 ,          t0 . SupportRepId  AS  res12  FROM  Customer  AS  t0  WHERE ( t0 . FirstName ) LIKE (?) -- With values: [SQLText  Jo% ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ( t0 . FirstName )   LIKE   ( Jo% )  \n\n         \n    \n         \n    \n                 \n                      You can use  ( .)  and  (||.)  to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,          t0 . FirstName  AS  res1 ,          t0 . LastName  AS  res2 ,          t0 . Company  AS  res3 ,          t0 . Address  AS  res4 ,          t0 . City  AS  res5 ,          t0 . State  AS  res6 ,          t0 . Country  AS  res7 ,          t0 . PostalCode  AS  res8 ,          t0 . Phone  AS  res9 ,          t0 . Fax  AS  res10 ,          t0 . Email  AS  res11 ,          t0 . SupportRepId  AS  res12  FROM  Customer  AS  t0  WHERE ((( t0 . FirstName ) LIKE (?))         AND (( t0 . LastName ) LIKE (?)))    AND ((( t0 . State )=(?))         OR (( t0 . State )=(?))) -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   =   ( CA )) \n        OR   (( t0 . State )   =   ( WA )))  \n\n         \n    \n         \n    \n                 \n                       Note  We had to use the  just_  function above to compare addressState (customerAddress customer) . This is because  addressState\n(customerAddress customer)  represents a nullable column which beam types as Maybe Text . Just as in Haskell, we need to explicitly unwrap the  Maybe \ntype. This is an example of beam offering stronger typing than SQL itself.", 
            "title": "WHERE clause"
        }, 
        {
            "location": "/user-guide/queries/select/#limitoffset-support", 
            "text": "The  limit_  and  offset_  functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe  LIMIT  and  OFFSET  SQL constructs.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $   offset_   100   $  filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,          t0 . FirstName  AS  res1 ,          t0 . LastName  AS  res2 ,          t0 . Company  AS  res3 ,          t0 . Address  AS  res4 ,          t0 . City  AS  res5 ,          t0 . State  AS  res6 ,          t0 . Country  AS  res7 ,          t0 . PostalCode  AS  res8 ,          t0 . Phone  AS  res9 ,          t0 . Fax  AS  res10 ,          t0 . Email  AS  res11 ,          t0 . SupportRepId  AS  res12  FROM  Customer  AS  t0  WHERE ((( t0 . FirstName ) LIKE (?))         AND (( t0 . LastName ) LIKE (?)))    AND ((( t0 . State )=(?))         OR (( t0 . State )=(?)))  LIMIT 10  OFFSET 100 -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   =   ( CA )) \n        OR   (( t0 . State )   =   ( WA )))  LIMIT   10  OFFSET   100  \n\n         \n    \n         \n    \n                 \n                       Note  Nested  limit_ s and  offset_ s compose in the way you'd expect without\ngenerating extraneous subqueries.    Warning  Note that the order of the  limit_  and  offset_  functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             offset_   100   $   limit_   10   $  filter_   ( \\ customer   -   (( customerFirstName   customer   ` like_ `   Jo% )   .   ( customerLastName   customer   ` like_ `   S% ))   . \n                       ( addressState   ( customerAddress   customer )   ==.   just_   CA   ||.   addressState   ( customerAddress   customer )   ==.   just_   WA ))   $ \n         all_   ( customer   chinookDb )  \n\n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,          t0 . FirstName  AS  res1 ,          t0 . LastName  AS  res2 ,          t0 . Company  AS  res3 ,          t0 . Address  AS  res4 ,          t0 . City  AS  res5 ,          t0 . State  AS  res6 ,          t0 . Country  AS  res7 ,          t0 . PostalCode  AS  res8 ,          t0 . Phone  AS  res9 ,          t0 . Fax  AS  res10 ,          t0 . Email  AS  res11 ,          t0 . SupportRepId  AS  res12  FROM  Customer  AS  t0  WHERE ((( t0 . FirstName ) LIKE (?))         AND (( t0 . LastName ) LIKE (?)))    AND ((( t0 . State )=(?))         OR (( t0 . State )=(?)))  LIMIT 0  OFFSET 100 -- With values: [SQLText  Jo% ,SQLText  S% ,SQLText  CA ,SQLText  WA ]  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        t0 . FirstName   AS   res1 , \n        t0 . LastName   AS   res2 , \n        t0 . Company   AS   res3 , \n        t0 . Address   AS   res4 , \n        t0 . City   AS   res5 , \n        t0 . State   AS   res6 , \n        t0 . Country   AS   res7 , \n        t0 . PostalCode   AS   res8 , \n        t0 . Phone   AS   res9 , \n        t0 . Fax   AS   res10 , \n        t0 . Email   AS   res11 , \n        t0 . SupportRepId   AS   res12  FROM   Customer   AS   t0  WHERE   ((( t0 . FirstName )   LIKE   ( Jo% )) \n        AND   (( t0 . LastName )   LIKE   ( S% ))) \n   AND   ((( t0 . State )   =   ( CA )) \n        OR   (( t0 . State )   =   ( WA )))  LIMIT   0  OFFSET   100", 
            "title": "LIMIT/OFFSET support"
        }, 
        {
            "location": "/user-guide/queries/ordering/", 
            "text": "Usually, queries are ordered before \nLIMIT\n and \nOFFSET\n are applied. Beam\nsupports the standard SQL \nORDER BY\n construct through the \norderBy_\n function.\n\n\norderBy_\n works like the Haskell function \nsortBy\n, with some restructions. Its\nfirst argument is a function which takes as input the output of the given query.\nThe function should return a sorting key, which is either a single sort ordering\nor a tuple of them. A sort ordering specifies an expression and a direction by\nwhich to sort. The result is then sorted lexicographically based on these sort\nexpressions. The second argument to \norderBy_\n is the query whose results to\nsort.\n\n\nUse the \nasc_\n and \ndesc_\n functions to specify the sort ordering over an\narbitrary expression.\n\n\nFor example, to get the first ten albums when sorted lexicographically, use\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n  \n$\n\n\norderBy_\n \n(\nasc_\n \n.\n \nalbumTitle\n)\n \n$\n\n\nall_\n \n(\nalbum\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nAlbumId\n AS \nres0\n,\n\n\n       \nt0\n.\nTitle\n AS \nres1\n,\n\n\n       \nt0\n.\nArtistId\n AS \nres2\n\n\nFROM \nAlbum\n AS \nt0\n\n\nORDER BY \nt0\n.\nTitle\n ASC\n\n\nLIMIT 10 -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n       \nt0\n.\nArtistId\n \nAS\n \nres2\n\n\nFROM\n \nAlbum\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nTitle\n \nASC\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAgain, note that the ordering in which you apply the \nlimit_\n and \norderBy_\n\nmatters. In general, you want to sort before you limit or offset, to keep your\nresult set stable. However, if you really want to sort a limited number of\narbitrarily chosen rows, you can use a different ordering.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \norderBy_\n \n(\nasc_\n \n.\n \nalbumTitle\n)\n \n$\n\n\nlimit_\n \n10\n \n$\n\n\nall_\n \n(\nalbum\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nres2\n AS \nres2\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nAlbumId\n AS \nres0\n,\n\n\n          \nt0\n.\nTitle\n AS \nres1\n,\n\n\n          \nt0\n.\nArtistId\n AS \nres2\n\n\n   FROM \nAlbum\n AS \nt0\n\n\n   LIMIT 10) AS \nt0\n\n\nORDER BY \nt0\n.\nres1\n ASC -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nAlbumId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nTitle\n \nAS\n \nres1\n,\n\n          \nt0\n.\nArtistId\n \nAS\n \nres2\n\n   \nFROM\n \nAlbum\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nres1\n \nASC\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nMultiple ordering keys\n\n\nYou can specify multiple keys to order by as well. Keys are sorted\nlexicographically in the given direction, as specified in the SQL standard.\n\n\nFor example, we can sort all employees by their state of residence in ascending\norder and by their city name in descending order.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_\n \n10\n \n$\n\n\norderBy_\n \n(\n\\\ne\n \n-\n \n(\nasc_\n \n(\naddressState\n \n(\nemployeeAddress\n \ne\n)),\n \ndesc_\n \n(\naddressCity\n \n(\nemployeeAddress\n \ne\n))))\n \n$\n\n\nall_\n \n(\nemployee\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nEmployeeId\n AS \nres0\n,\n\n\n       \nt0\n.\nLastName\n AS \nres1\n,\n\n\n       \nt0\n.\nFirstName\n AS \nres2\n,\n\n\n       \nt0\n.\nTitle\n AS \nres3\n,\n\n\n       \nt0\n.\nReportsTo\n AS \nres4\n,\n\n\n       \nt0\n.\nBirthDate\n AS \nres5\n,\n\n\n       \nt0\n.\nHireDate\n AS \nres6\n,\n\n\n       \nt0\n.\nAddress\n AS \nres7\n,\n\n\n       \nt0\n.\nCity\n AS \nres8\n,\n\n\n       \nt0\n.\nState\n AS \nres9\n,\n\n\n       \nt0\n.\nCountry\n AS \nres10\n,\n\n\n       \nt0\n.\nPostalCode\n AS \nres11\n,\n\n\n       \nt0\n.\nPhone\n AS \nres12\n,\n\n\n       \nt0\n.\nFax\n AS \nres13\n,\n\n\n       \nt0\n.\nEmail\n AS \nres14\n\n\nFROM \nEmployee\n AS \nt0\n\n\nORDER BY \nt0\n.\nState\n ASC,\n\n\n         \nt0\n.\nCity\n DESC\n\n\nLIMIT 10 -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nEmployeeId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nLastName\n \nAS\n \nres1\n,\n\n       \nt0\n.\nFirstName\n \nAS\n \nres2\n,\n\n       \nt0\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt0\n.\nReportsTo\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBirthDate\n \nAS\n \nres5\n,\n\n       \nt0\n.\nHireDate\n \nAS\n \nres6\n,\n\n       \nt0\n.\nAddress\n \nAS\n \nres7\n,\n\n       \nt0\n.\nCity\n \nAS\n \nres8\n,\n\n       \nt0\n.\nState\n \nAS\n \nres9\n,\n\n       \nt0\n.\nCountry\n \nAS\n \nres10\n,\n\n       \nt0\n.\nPostalCode\n \nAS\n \nres11\n,\n\n       \nt0\n.\nPhone\n \nAS\n \nres12\n,\n\n       \nt0\n.\nFax\n \nAS\n \nres13\n,\n\n       \nt0\n.\nEmail\n \nAS\n \nres14\n\n\nFROM\n \nEmployee\n \nAS\n \nt0\n\n\nORDER\n \nBY\n \nt0\n.\nState\n \nASC\n,\n\n         \nt0\n.\nCity\n \nDESC\n\n\nLIMIT\n \n10", 
            "title": "Ordering"
        }, 
        {
            "location": "/user-guide/queries/ordering/#multiple-ordering-keys", 
            "text": "You can specify multiple keys to order by as well. Keys are sorted\nlexicographically in the given direction, as specified in the SQL standard.  For example, we can sort all employees by their state of residence in ascending\norder and by their city name in descending order.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             limit_   10   $  orderBy_   ( \\ e   -   ( asc_   ( addressState   ( employeeAddress   e )),   desc_   ( addressCity   ( employeeAddress   e ))))   $  all_   ( employee   chinookDb )  \n\n         \n    \n         \n             SELECT  t0 . EmployeeId  AS  res0 ,          t0 . LastName  AS  res1 ,          t0 . FirstName  AS  res2 ,          t0 . Title  AS  res3 ,          t0 . ReportsTo  AS  res4 ,          t0 . BirthDate  AS  res5 ,          t0 . HireDate  AS  res6 ,          t0 . Address  AS  res7 ,          t0 . City  AS  res8 ,          t0 . State  AS  res9 ,          t0 . Country  AS  res10 ,          t0 . PostalCode  AS  res11 ,          t0 . Phone  AS  res12 ,          t0 . Fax  AS  res13 ,          t0 . Email  AS  res14  FROM  Employee  AS  t0  ORDER BY  t0 . State  ASC,            t0 . City  DESC  LIMIT 10 -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . EmployeeId   AS   res0 , \n        t0 . LastName   AS   res1 , \n        t0 . FirstName   AS   res2 , \n        t0 . Title   AS   res3 , \n        t0 . ReportsTo   AS   res4 , \n        t0 . BirthDate   AS   res5 , \n        t0 . HireDate   AS   res6 , \n        t0 . Address   AS   res7 , \n        t0 . City   AS   res8 , \n        t0 . State   AS   res9 , \n        t0 . Country   AS   res10 , \n        t0 . PostalCode   AS   res11 , \n        t0 . Phone   AS   res12 , \n        t0 . Fax   AS   res13 , \n        t0 . Email   AS   res14  FROM   Employee   AS   t0  ORDER   BY   t0 . State   ASC , \n          t0 . City   DESC  LIMIT   10", 
            "title": "Multiple ordering keys"
        }, 
        {
            "location": "/user-guide/queries/relationships/", 
            "text": "Relational databases are so-named because they're good at expressing relations\namong data and providing related data in queries. Beam exposes these features in\nits DSL.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database.\n\n\nFirst, create a SQLite database from the included example.\n\n\n sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude\n \nDatabase\n.\nBeam\n.\nSqlite\n \n:\nload\n \nbeam\n-\nsqlite\n/\nexamples\n/\nChinook\n/\nSchema\n.\nhs\n\n\nPrelude\n \nChinook\n.\nSchema\n \nchinook\n \n-\n \nopen\n \nchinook.db\n\n\n\n\n\n\nOne more thing, before we explore how beam handles relationships. Before we do, let's define a quick utility function.\n\n\nPrelude\n \nChinook\n.\nSchema\n \nlet\n \nwithConnectionTutorial\n \n=\n \nwithDatabaseDebug\n \nputStrLn\n \nchinook\n\n\n\n\n\n\nThis function prints each of our queries to standard output before running them.\nUsing this function will let us see what SQL is executing.\n\n\nOne-to-many\n\n\nBeam supports querying for one-to-many joins. For example, to get every\n\nInvoiceLine\n for each \nInvoice\n, use the \noneToMany_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \ni\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n\n\n       \nt0\n.\nCustomerId\n AS \nres1\n,\n\n\n       \nt0\n.\nInvoiceDate\n AS \nres2\n,\n\n\n       \nt0\n.\nBillingAddress\n AS \nres3\n,\n\n\n       \nt0\n.\nBillingCity\n AS \nres4\n,\n\n\n       \nt0\n.\nBillingState\n AS \nres5\n,\n\n\n       \nt0\n.\nBillingCountry\n AS \nres6\n,\n\n\n       \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n\n\n       \nt0\n.\nTotal\n AS \nres8\n,\n\n\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n\n\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres11\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n\n\n       \nt1\n.\nQuantity\n AS \nres13\n\n\nFROM \nInvoice\n AS \nt0\n\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nInvoiceId\n) -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nInvoiceId\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr, if you have an actual \nInvoice\n (called \noneInvoice\n) and you want all the\nassociated \nInvoiceLine\ns, you can use \nval_\n to convert \noneInvoice\n to the SQL\nexpression level.\n\n\noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \n(\nval_\n \ni\n)\n\n\n\n\n\n\nIf you find yourself repeating yourself constantly, you can define a helper.\n\n\ninvoiceLines_\n \n::\n \nOneToMany\n \nInvoiceT\n \nInvoiceLineT\n\n\ninvoiceLines_\n \n=\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n\n\n\n\n\n\nThen the above queries become\n\n\ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \ninvoiceLines_\n \ni\n\n\n\n\n\n\nand\n\n\ninvoiceLines\n \n(\nval_\n \ni\n)\n\n\n\n\n\n\nNullable columns\n\n\nIf you have a nullable foreign key in your many table, you can use\n\noneToManyOptional_\n and \nOneToManyOptional\n, respectively. For example, \n\n\nOne-to-one\n\n\nOne to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.\n\n\nFor convenience, \noneToOne_\n and \nOneToOne\n are equivalent to \noneToMany_\n and\n\nOneToMany\n. Additionally, \noneToMaybe_\n and \nOneToMaybe\n correspond to\n\noneToManyOptional_\n and \nOneToManyOptional\n.\n\n\nMany-to-many\n\n\nMany to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.\n\n\nThe \nmanyToMany_\n construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.\n\n\nmanyToMany_\n\n  \n::\n \n(\n \nDatabase\n \ndb\n,\n \nTable\n \njoinThrough\n\n     \n,\n \nTable\n \nleft\n,\n \nTable\n \nright\n\n     \n,\n \nSql92SelectSanityCheck\n \nsyntax\n\n     \n,\n \nIsSql92SelectSyntax\n \nsyntax\n\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n)\n\n  \n=\n \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \njoinThrough\n)\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n),\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n\n\n\n\n\nThis reads: for any database \ndb\n; tables \njoinThrough\n, \nleft\n, and \nright\n;\nand sane select syntax \nsyntax\n, where the primary keys of \nleft\n and \nright\n\nare comparable as value expressions and we have some way of extracting a primary\nkey of \nleft\n and \nright\n from \njoinThrough\n, associate all entries of \nleft\n\nwith those of \nright\n through \njoinThrough\n and return the results of \nleft\n and\n\nright\n.\n\n\nThe Chinook database associates multiple tracks with a playlist via the\n\nplaylist_track\n table. For example, to get all tracks from the playlists named\neither \"Movies\" or \"Music\".\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nmanyToMany_\n \n(\nplaylistTrack\n \nchinookDb\n)\n\n            \nplaylistTrackPlaylistId\n \nplaylistTrackTrackId\n\n\n            \n(\nfilter_\n \n(\n\\\np\n \n-\n \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMusic\n)\n \n||.\n\n                            \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMovies\n))\n\n                     \n(\nall_\n \n(\nplaylist\n \nchinookDb\n)))\n\n\n            \n(\nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nPlaylistId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt1\n.\nName\n AS \nres3\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt1\n.\nComposer\n AS \nres7\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt1\n.\nBytes\n AS \nres9\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres10\n\n\nFROM \nPlaylist\n AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n\n\nINNER JOIN \nPlaylistTrack\n AS \nt2\n ON ((\nt2\n.\nPlaylistId\n)=(\nt0\n.\nPlaylistId\n))\n\n\nAND ((\nt2\n.\nTrackId\n)=(\nt1\n.\nTrackId\n))\n\n\nWHERE ((\nt0\n.\nName\n)=(?))\n\n\n  OR ((\nt0\n.\nName\n)=(?)) -- With values: [SQLText \nMusic\n,SQLText \nMovies\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n \n=\n \n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n \n=\n \n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n((\nt0\n.\nName\n)\n \n=\n \n(\nMusic\n))\n\n  \nOR\n \n((\nt0\n.\nName\n)\n \n=\n \n(\nMovies\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nMany-to-many with arbitrary data\n\n\nSometimes you want to have additional data for each relationship. For this, use\n\nmanyToManyPassthrough_\n.\n\n\nmanyToManyPassthrough_\n\n  \n::\n \n(\n \nDatabase\n \ndb\n,\n \nTable\n \njoinThrough\n\n     \n,\n \nTable\n \nleft\n,\n \nTable\n \nright\n\n     \n,\n \nSql92SelectSanityCheck\n \nsyntax\n\n     \n,\n \nIsSql92SelectSyntax\n \nsyntax\n\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n     \n,\n \nSqlEq\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n(\nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n \n)\n\n  \n=\n \nDatabaseEntity\n \nbe\n \ndb\n \n(\nTableEntity\n \njoinThrough\n)\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \n(\njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n \n-\n \nPrimaryKey\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n  \n-\n \nQ\n \nsyntax\n \ndb\n \ns\n \n(\n \njoinThrough\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n\n                   \n,\n \nleft\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n)\n\n                   \n,\n \nright\n \n(\nQExpr\n \n(\nSql92SelectExpressionSyntax\n \nsyntax\n)\n \ns\n))\n\n\n\n\n\n\nUnder the hood \nmanyToMany_\n is defined simply as \n\n\nmanyToMany_\n \n=\n \nfmap\n \n(\n\\\n(\n_\n,\n \nleft\n,\n \nright\n)\n \n-\n \n(\nleft\n,\n \nright\n))\n \nmanyToManyPassthrough_\n\n\n\n\n\n\nDeclaring many-to-many relationships\n\n\nLike one-to-many relationships, beam allows you to extract commonly used\nmany-to-many relationships, via the \nManyToMany\n type.\n\n\nFor example, the playlist/track relationship above can be defined as follows\n\n\nplaylistTrackRelationship\n \n::\n \nManyToMany\n \nChinookDb\n \nPlaylistT\n \nTrackT\n\n\nplaylistTrackRelationshipu\n \n=\n\n  \nmanyToMany_\n \n(\nplaylistTrack\n \nchinookDb\n)\n \nplaylistTrackPlaylistId\n \nplaylistTrackTrackId\n\n\n\n\n\n\nAnd we can use it as expected:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nplaylistTrackRelationship\n\n    \n(\nfilter_\n \n(\n\\\np\n \n-\n \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMusic\n)\n \n||.\n\n                    \nplaylistName\n \np\n \n==.\n \njust_\n \n(\nval_\n \nMovies\n))\n\n             \n(\nall_\n \n(\nplaylist\n \nchinookDb\n)))\n\n\n    \n(\nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nPlaylistId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt1\n.\nName\n AS \nres3\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt1\n.\nComposer\n AS \nres7\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt1\n.\nBytes\n AS \nres9\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres10\n\n\nFROM \nPlaylist\n AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n\n\nINNER JOIN \nPlaylistTrack\n AS \nt2\n ON ((\nt2\n.\nPlaylistId\n)=(\nt0\n.\nPlaylistId\n))\n\n\nAND ((\nt2\n.\nTrackId\n)=(\nt1\n.\nTrackId\n))\n\n\nWHERE ((\nt0\n.\nName\n)=(?))\n\n\n  OR ((\nt0\n.\nName\n)=(?)) -- With values: [SQLText \nMusic\n,SQLText \nMovies\n]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nPlaylistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n\n\nFROM\n \nPlaylist\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nINNER\n \nJOIN\n \nPlaylistTrack\n \nAS\n \nt2\n \nON\n \n((\nt2\n.\nPlaylistId\n)\n \n=\n \n(\nt0\n.\nPlaylistId\n))\n\n\nAND\n \n((\nt2\n.\nTrackId\n)\n \n=\n \n(\nt1\n.\nTrackId\n))\n\n\nWHERE\n \n((\nt0\n.\nName\n)\n \n=\n \n(\nMusic\n))\n\n  \nOR\n \n((\nt0\n.\nName\n)\n \n=\n \n(\nMovies\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nManyToManyThrough\n is the equivalent for \nmanyToManyThrough_\n, except it takes\nanother table parameter for the 'through' table.\n\n\nArbitrary Joins\n\n\nJoins with arbitrary conditions can be specified using the \njoin_\n construct.\nFor example, \noneToMany_\n is implemented as\n\n\noneToMany_\n \nrel\n \ngetKey\n \ntbl\n \n=\n\n  \njoin_\n \nrel\n \n(\n\\\nrel\n \n-\n \ngetKey\n \nrel\n \n==.\n \npk\n \ntbl\n)\n\n\n\n\n\n\nThus, the invoice example above could be rewritten. For example, instead of \n\n\ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \noneToMany_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \ninvoiceLineInvoice\n \ni\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n\n\nWe could write\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nln\n \n-\n \njoin_\n \n(\ninvoiceLine\n \nchinookDb\n)\n \n(\n\\\nline\n \n-\n \ninvoiceLineInvoice\n \nline\n \n==.\n \nprimaryKey\n \ni\n)\n\n   \npure\n \n(\ni\n,\n \nln\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n\n\n       \nt0\n.\nCustomerId\n AS \nres1\n,\n\n\n       \nt0\n.\nInvoiceDate\n AS \nres2\n,\n\n\n       \nt0\n.\nBillingAddress\n AS \nres3\n,\n\n\n       \nt0\n.\nBillingCity\n AS \nres4\n,\n\n\n       \nt0\n.\nBillingState\n AS \nres5\n,\n\n\n       \nt0\n.\nBillingCountry\n AS \nres6\n,\n\n\n       \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n\n\n       \nt0\n.\nTotal\n AS \nres8\n,\n\n\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n\n\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres11\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n\n\n       \nt1\n.\nQuantity\n AS \nres13\n\n\nFROM \nInvoice\n AS \nt0\n\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nInvoiceId\n) -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nInvoiceId\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOuter joins\n\n\nLeft and right joins\n\n\nLeft joins with arbitrary conditions can be specified with the \nleftJoin_\n\nconstruct. \nleftJoin_\n takes an arbitrary query and a join condition. It\nassociates each result record with a record of the table given or a fully NULL\nrow of that table in case no row matches. For this reason, the result of\n\nleftJoin_\n has an extra \nNullable\n column tag, which converts each field into\nthe corresponding \nMaybe\n type.\n\n\n\n\nNote\n\n\nThe table parameter passed in as the join condition does not have a \n\nNullable\n column tag. The join condition should be written as if a \nconcrete row from that table exists.\n\n\n\n\nFor example, to get every artist along with their albums, but always including\nevery artist, use \nleftJoin_\n as follows.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \nartist\n \n-\n \nall_\n \n(\nartist\n \nchinookDb\n)\n\n   \nalbum\n  \n-\n \nleftJoin_\n \n(\nall_\n \n(\nalbum\n \nchinookDb\n))\n \n(\n\\\nalbum\n \n-\n \nalbumArtist\n \nalbum\n \n==.\n \nprimaryKey\n \nartist\n)\n\n   \npure\n \n(\nartist\n,\n \nalbum\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nArtistId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres2\n,\n\n\n       \nt1\n.\nTitle\n AS \nres3\n,\n\n\n       \nt1\n.\nArtistId\n AS \nres4\n\n\nFROM \nArtist\n AS \nt0\n\n\nLEFT JOIN \nAlbum\n AS \nt1\n ON (\nt1\n.\nArtistId\n)=(\nt0\n.\nArtistId\n) -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nArtistId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nTitle\n \nAS\n \nres3\n,\n\n       \nt1\n.\nArtistId\n \nAS\n \nres4\n\n\nFROM\n \nArtist\n \nAS\n \nt0\n\n\nLEFT\n \nJOIN\n \nAlbum\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nArtistId\n)\n \n=\n \n(\nt0\n.\nArtistId\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nRight joins are not yet supported. They can always be rewritten as left joins.\nIf you have a compelling use case, please file an issue!\n\n\nFull Outer joins\n\n\n\n\nTODO\n\n\nouterJoin_\n not yet supported\n\n\n\n\nFull outer joins are supported via the \nouterJoin_\n construct.\n\n\nSubqueries\n\n\nSometimes you want to join against a \nsubquery\n rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.\n\n\nFor example, the following query generates the code you'd expect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo\n \ni\n \n-\n \nlimit_\n \n10\n \n$\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nline\n \n-\n \ninvoiceLines\n \ni\n\n   \npure\n \n(\ni\n,\n \nline\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nres2\n AS \nres2\n,\n\n\n       \nt0\n.\nres3\n AS \nres3\n,\n\n\n       \nt0\n.\nres4\n AS \nres4\n,\n\n\n       \nt0\n.\nres5\n AS \nres5\n,\n\n\n       \nt0\n.\nres6\n AS \nres6\n,\n\n\n       \nt0\n.\nres7\n AS \nres7\n,\n\n\n       \nt0\n.\nres8\n AS \nres8\n,\n\n\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n\n\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres11\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n\n\n       \nt1\n.\nQuantity\n AS \nres13\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n\n\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n\n\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n\n\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n\n\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n\n\n          \nt0\n.\nBillingState\n AS \nres5\n,\n\n\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n\n\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n\n\n          \nt0\n.\nTotal\n AS \nres8\n\n\n   FROM \nInvoice\n AS \nt0\n\n\n   LIMIT 10) AS \nt0\n\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nres0\n) -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using \nsubselect_\n. The \nsubselect_\n will force a new query to be\noutput in most cases. For simple queries, such as \nall_\n, \nsubselect_\n will have\nno effect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Same as above, but with explicit sub select\n\n\ndo\n \ni\n \n-\n \nsubselect_\n \n$\n \nlimit_\n \n10\n \n$\n \nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n   \nline\n \n-\n \ninvoiceLines\n \ni\n\n   \npure\n \n(\ni\n,\n \nline\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nres2\n AS \nres2\n,\n\n\n       \nt0\n.\nres3\n AS \nres3\n,\n\n\n       \nt0\n.\nres4\n AS \nres4\n,\n\n\n       \nt0\n.\nres5\n AS \nres5\n,\n\n\n       \nt0\n.\nres6\n AS \nres6\n,\n\n\n       \nt0\n.\nres7\n AS \nres7\n,\n\n\n       \nt0\n.\nres8\n AS \nres8\n,\n\n\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n\n\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres11\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n\n\n       \nt1\n.\nQuantity\n AS \nres13\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n\n\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n\n\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n\n\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n\n\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n\n\n          \nt0\n.\nBillingState\n AS \nres5\n,\n\n\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n\n\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n\n\n          \nt0\n.\nTotal\n AS \nres8\n\n\n   FROM \nInvoice\n AS \nt0\n\n\n   LIMIT 10) AS \nt0\n\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nres0\n) -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres3\n,\n\n       \nt0\n.\nres4\n \nAS\n \nres4\n,\n\n       \nt0\n.\nres5\n \nAS\n \nres5\n,\n\n       \nt0\n.\nres6\n \nAS\n \nres6\n,\n\n       \nt0\n.\nres7\n \nAS\n \nres7\n,\n\n       \nt0\n.\nres8\n \nAS\n \nres8\n,\n\n       \nt1\n.\nInvoiceLineId\n \nAS\n \nres9\n,\n\n       \nt1\n.\nInvoiceId\n \nAS\n \nres10\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres11\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres12\n,\n\n       \nt1\n.\nQuantity\n \nAS\n \nres13\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n\n   \nLIMIT\n \n10\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nInvoiceLine\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nInvoiceId\n)\n \n=\n \n(\nt0\n.\nres0\n)", 
            "title": "Relationships"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-many", 
            "text": "Beam supports querying for one-to-many joins. For example, to get every InvoiceLine  for each  Invoice , use the  oneToMany_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   i \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT  t0 . InvoiceId  AS  res0 ,          t0 . CustomerId  AS  res1 ,          t0 . InvoiceDate  AS  res2 ,          t0 . BillingAddress  AS  res3 ,          t0 . BillingCity  AS  res4 ,          t0 . BillingState  AS  res5 ,          t0 . BillingCountry  AS  res6 ,          t0 . BillingPostalCode  AS  res7 ,          t0 . Total  AS  res8 ,          t1 . InvoiceLineId  AS  res9 ,          t1 . InvoiceId  AS  res10 ,          t1 . TrackId  AS  res11 ,          t1 . UnitPrice  AS  res12 ,          t1 . Quantity  AS  res13  FROM  Invoice  AS  t0  INNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . InvoiceId ) -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . InvoiceId )  \n\n         \n    \n         \n    \n                 \n                      Or, if you have an actual  Invoice  (called  oneInvoice ) and you want all the\nassociated  InvoiceLine s, you can use  val_  to convert  oneInvoice  to the SQL\nexpression level.  oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   ( val_   i )   If you find yourself repeating yourself constantly, you can define a helper.  invoiceLines_   ::   OneToMany   InvoiceT   InvoiceLineT  invoiceLines_   =   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   Then the above queries become  do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   invoiceLines_   i   and  invoiceLines   ( val_   i )", 
            "title": "One-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#nullable-columns", 
            "text": "If you have a nullable foreign key in your many table, you can use oneToManyOptional_  and  OneToManyOptional , respectively. For example,", 
            "title": "Nullable columns"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-one", 
            "text": "One to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.  For convenience,  oneToOne_  and  OneToOne  are equivalent to  oneToMany_  and OneToMany . Additionally,  oneToMaybe_  and  OneToMaybe  correspond to oneToManyOptional_  and  OneToManyOptional .", 
            "title": "One-to-one"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many", 
            "text": "Many to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.  The  manyToMany_  construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.  manyToMany_ \n   ::   (   Database   db ,   Table   joinThrough \n      ,   Table   left ,   Table   right \n      ,   Sql92SelectSanityCheck   syntax \n      ,   IsSql92SelectSyntax   syntax \n\n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   ) \n   =   DatabaseEntity   be   db   ( TableEntity   joinThrough ) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   -   Q   syntax   db   s   ( right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ),   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   This reads: for any database  db ; tables  joinThrough ,  left , and  right ;\nand sane select syntax  syntax , where the primary keys of  left  and  right \nare comparable as value expressions and we have some way of extracting a primary\nkey of  left  and  right  from  joinThrough , associate all entries of  left \nwith those of  right  through  joinThrough  and return the results of  left  and right .  The Chinook database associates multiple tracks with a playlist via the playlist_track  table. For example, to get all tracks from the playlists named\neither \"Movies\" or \"Music\".  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             manyToMany_   ( playlistTrack   chinookDb ) \n             playlistTrackPlaylistId   playlistTrackTrackId \n\n             ( filter_   ( \\ p   -   playlistName   p   ==.   just_   ( val_   Music )   ||. \n                             playlistName   p   ==.   just_   ( val_   Movies )) \n                      ( all_   ( playlist   chinookDb ))) \n\n             ( all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT  t0 . PlaylistId  AS  res0 ,          t0 . Name  AS  res1 ,          t1 . TrackId  AS  res2 ,          t1 . Name  AS  res3 ,          t1 . AlbumId  AS  res4 ,          t1 . MediaTypeId  AS  res5 ,          t1 . GenreId  AS  res6 ,          t1 . Composer  AS  res7 ,          t1 . Milliseconds  AS  res8 ,          t1 . Bytes  AS  res9 ,          t1 . UnitPrice  AS  res10  FROM  Playlist  AS  t0  INNER JOIN  Track  AS  t1  INNER JOIN  PlaylistTrack  AS  t2  ON (( t2 . PlaylistId )=( t0 . PlaylistId ))  AND (( t2 . TrackId )=( t1 . TrackId ))  WHERE (( t0 . Name )=(?))    OR (( t0 . Name )=(?)) -- With values: [SQLText  Music ,SQLText  Movies ]  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  INNER   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId )   =   ( t0 . PlaylistId ))  AND   (( t2 . TrackId )   =   ( t1 . TrackId ))  WHERE   (( t0 . Name )   =   ( Music )) \n   OR   (( t0 . Name )   =   ( Movies ))", 
            "title": "Many-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many-with-arbitrary-data", 
            "text": "Sometimes you want to have additional data for each relationship. For this, use manyToManyPassthrough_ .  manyToManyPassthrough_ \n   ::   (   Database   db ,   Table   joinThrough \n      ,   Table   left ,   Table   right \n      ,   Sql92SelectSanityCheck   syntax \n      ,   IsSql92SelectSyntax   syntax \n\n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n      ,   SqlEq   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   ( PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   ) \n   =   DatabaseEntity   be   db   ( TableEntity   joinThrough ) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   ( joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )   -   PrimaryKey   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   ( right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s )) \n   -   Q   syntax   db   s   (   joinThrough   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ) \n                    ,   left   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ) \n                    ,   right   ( QExpr   ( Sql92SelectExpressionSyntax   syntax )   s ))   Under the hood  manyToMany_  is defined simply as   manyToMany_   =   fmap   ( \\ ( _ ,   left ,   right )   -   ( left ,   right ))   manyToManyPassthrough_", 
            "title": "Many-to-many with arbitrary data"
        }, 
        {
            "location": "/user-guide/queries/relationships/#declaring-many-to-many-relationships", 
            "text": "Like one-to-many relationships, beam allows you to extract commonly used\nmany-to-many relationships, via the  ManyToMany  type.  For example, the playlist/track relationship above can be defined as follows  playlistTrackRelationship   ::   ManyToMany   ChinookDb   PlaylistT   TrackT  playlistTrackRelationshipu   = \n   manyToMany_   ( playlistTrack   chinookDb )   playlistTrackPlaylistId   playlistTrackTrackId   And we can use it as expected:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             playlistTrackRelationship \n     ( filter_   ( \\ p   -   playlistName   p   ==.   just_   ( val_   Music )   ||. \n                     playlistName   p   ==.   just_   ( val_   Movies )) \n              ( all_   ( playlist   chinookDb ))) \n\n     ( all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT  t0 . PlaylistId  AS  res0 ,          t0 . Name  AS  res1 ,          t1 . TrackId  AS  res2 ,          t1 . Name  AS  res3 ,          t1 . AlbumId  AS  res4 ,          t1 . MediaTypeId  AS  res5 ,          t1 . GenreId  AS  res6 ,          t1 . Composer  AS  res7 ,          t1 . Milliseconds  AS  res8 ,          t1 . Bytes  AS  res9 ,          t1 . UnitPrice  AS  res10  FROM  Playlist  AS  t0  INNER JOIN  Track  AS  t1  INNER JOIN  PlaylistTrack  AS  t2  ON (( t2 . PlaylistId )=( t0 . PlaylistId ))  AND (( t2 . TrackId )=( t1 . TrackId ))  WHERE (( t0 . Name )=(?))    OR (( t0 . Name )=(?)) -- With values: [SQLText  Music ,SQLText  Movies ]  \n\n         \n    \n         \n             SELECT   t0 . PlaylistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10  FROM   Playlist   AS   t0  INNER   JOIN   Track   AS   t1  INNER   JOIN   PlaylistTrack   AS   t2   ON   (( t2 . PlaylistId )   =   ( t0 . PlaylistId ))  AND   (( t2 . TrackId )   =   ( t1 . TrackId ))  WHERE   (( t0 . Name )   =   ( Music )) \n   OR   (( t0 . Name )   =   ( Movies ))  \n\n         \n    \n         \n    \n                 \n                      ManyToManyThrough  is the equivalent for  manyToManyThrough_ , except it takes\nanother table parameter for the 'through' table.", 
            "title": "Declaring many-to-many relationships"
        }, 
        {
            "location": "/user-guide/queries/relationships/#arbitrary-joins", 
            "text": "Joins with arbitrary conditions can be specified using the  join_  construct.\nFor example,  oneToMany_  is implemented as  oneToMany_   rel   getKey   tbl   = \n   join_   rel   ( \\ rel   -   getKey   rel   ==.   pk   tbl )   Thus, the invoice example above could be rewritten. For example, instead of   do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   oneToMany_   ( invoiceLine   chinookDb )   invoiceLineInvoice   i \n    pure   ( i ,   ln )   We could write  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   all_   ( invoice   chinookDb ) \n    ln   -   join_   ( invoiceLine   chinookDb )   ( \\ line   -   invoiceLineInvoice   line   ==.   primaryKey   i ) \n    pure   ( i ,   ln )  \n\n         \n    \n         \n             SELECT  t0 . InvoiceId  AS  res0 ,          t0 . CustomerId  AS  res1 ,          t0 . InvoiceDate  AS  res2 ,          t0 . BillingAddress  AS  res3 ,          t0 . BillingCity  AS  res4 ,          t0 . BillingState  AS  res5 ,          t0 . BillingCountry  AS  res6 ,          t0 . BillingPostalCode  AS  res7 ,          t0 . Total  AS  res8 ,          t1 . InvoiceLineId  AS  res9 ,          t1 . InvoiceId  AS  res10 ,          t1 . TrackId  AS  res11 ,          t1 . UnitPrice  AS  res12 ,          t1 . Quantity  AS  res13  FROM  Invoice  AS  t0  INNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . InvoiceId ) -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM   Invoice   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . InvoiceId )", 
            "title": "Arbitrary Joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#outer-joins", 
            "text": "", 
            "title": "Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#left-and-right-joins", 
            "text": "Left joins with arbitrary conditions can be specified with the  leftJoin_ \nconstruct.  leftJoin_  takes an arbitrary query and a join condition. It\nassociates each result record with a record of the table given or a fully NULL\nrow of that table in case no row matches. For this reason, the result of leftJoin_  has an extra  Nullable  column tag, which converts each field into\nthe corresponding  Maybe  type.   Note  The table parameter passed in as the join condition does not have a  Nullable  column tag. The join condition should be written as if a \nconcrete row from that table exists.   For example, to get every artist along with their albums, but always including\nevery artist, use  leftJoin_  as follows.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   artist   -   all_   ( artist   chinookDb ) \n    album    -   leftJoin_   ( all_   ( album   chinookDb ))   ( \\ album   -   albumArtist   album   ==.   primaryKey   artist ) \n    pure   ( artist ,   album )  \n\n         \n    \n         \n             SELECT  t0 . ArtistId  AS  res0 ,          t0 . Name  AS  res1 ,          t1 . AlbumId  AS  res2 ,          t1 . Title  AS  res3 ,          t1 . ArtistId  AS  res4  FROM  Artist  AS  t0  LEFT JOIN  Album  AS  t1  ON ( t1 . ArtistId )=( t0 . ArtistId ) -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . ArtistId   AS   res0 , \n        t0 . Name   AS   res1 , \n        t1 . AlbumId   AS   res2 , \n        t1 . Title   AS   res3 , \n        t1 . ArtistId   AS   res4  FROM   Artist   AS   t0  LEFT   JOIN   Album   AS   t1   ON   ( t1 . ArtistId )   =   ( t0 . ArtistId )  \n\n         \n    \n         \n    \n                 \n                      Right joins are not yet supported. They can always be rewritten as left joins.\nIf you have a compelling use case, please file an issue!", 
            "title": "Left and right joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#full-outer-joins", 
            "text": "TODO  outerJoin_  not yet supported   Full outer joins are supported via the  outerJoin_  construct.", 
            "title": "Full Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#subqueries", 
            "text": "Sometimes you want to join against a  subquery  rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.  For example, the following query generates the code you'd expect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do   i   -   limit_   10   $   all_   ( invoice   chinookDb ) \n    line   -   invoiceLines   i \n    pure   ( i ,   line )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t0 . res2  AS  res2 ,          t0 . res3  AS  res3 ,          t0 . res4  AS  res4 ,          t0 . res5  AS  res5 ,          t0 . res6  AS  res6 ,          t0 . res7  AS  res7 ,          t0 . res8  AS  res8 ,          t1 . InvoiceLineId  AS  res9 ,          t1 . InvoiceId  AS  res10 ,          t1 . TrackId  AS  res11 ,          t1 . UnitPrice  AS  res12 ,          t1 . Quantity  AS  res13  FROM    (SELECT  t0 . InvoiceId  AS  res0 ,             t0 . CustomerId  AS  res1 ,             t0 . InvoiceDate  AS  res2 ,             t0 . BillingAddress  AS  res3 ,             t0 . BillingCity  AS  res4 ,             t0 . BillingState  AS  res5 ,             t0 . BillingCountry  AS  res6 ,             t0 . BillingPostalCode  AS  res7 ,             t0 . Total  AS  res8     FROM  Invoice  AS  t0     LIMIT 10) AS  t0  INNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . res0 ) -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . res0 )  \n\n         \n    \n         \n    \n                 \n                      If you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using  subselect_ . The  subselect_  will force a new query to be\noutput in most cases. For simple queries, such as  all_ ,  subselect_  will have\nno effect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Same as above, but with explicit sub select  do   i   -   subselect_   $   limit_   10   $   all_   ( invoice   chinookDb ) \n    line   -   invoiceLines   i \n    pure   ( i ,   line )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t0 . res2  AS  res2 ,          t0 . res3  AS  res3 ,          t0 . res4  AS  res4 ,          t0 . res5  AS  res5 ,          t0 . res6  AS  res6 ,          t0 . res7  AS  res7 ,          t0 . res8  AS  res8 ,          t1 . InvoiceLineId  AS  res9 ,          t1 . InvoiceId  AS  res10 ,          t1 . TrackId  AS  res11 ,          t1 . UnitPrice  AS  res12 ,          t1 . Quantity  AS  res13  FROM    (SELECT  t0 . InvoiceId  AS  res0 ,             t0 . CustomerId  AS  res1 ,             t0 . InvoiceDate  AS  res2 ,             t0 . BillingAddress  AS  res3 ,             t0 . BillingCity  AS  res4 ,             t0 . BillingState  AS  res5 ,             t0 . BillingCountry  AS  res6 ,             t0 . BillingPostalCode  AS  res7 ,             t0 . Total  AS  res8     FROM  Invoice  AS  t0     LIMIT 10) AS  t0  INNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . res0 ) -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t0 . res2   AS   res2 , \n        t0 . res3   AS   res3 , \n        t0 . res4   AS   res4 , \n        t0 . res5   AS   res5 , \n        t0 . res6   AS   res6 , \n        t0 . res7   AS   res7 , \n        t0 . res8   AS   res8 , \n        t1 . InvoiceLineId   AS   res9 , \n        t1 . InvoiceId   AS   res10 , \n        t1 . TrackId   AS   res11 , \n        t1 . UnitPrice   AS   res12 , \n        t1 . Quantity   AS   res13  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 \n    FROM   Invoice   AS   t0 \n    LIMIT   10 )   AS   t0  INNER   JOIN   InvoiceLine   AS   t1   ON   ( t1 . InvoiceId )   =   ( t0 . res0 )", 
            "title": "Subqueries"
        }, 
        {
            "location": "/user-guide/queries/aggregates/", 
            "text": "You can use the \naggregate_\n function to group your result set and compute\naggregates within the group. You can think of \naggregate_\n as a souped up\nversion of Haskell's \ngroupBy\n.\n\n\nYou use \naggregate_\n by specifying an underlying query to run and a function\nthat produces an aggregation projection. An aggregation projection is either a\nvalue of type \nQAgg syntax s a\n, a value of type \nQGroupExpr syntax s a\n, or a\ntuple of such values. Any \nQGenExpr\n that uses an aggregate function is\nautomatically assigned the \nQAgg syntax s a\n type. Any \nQGenExpr\n that contains\nthe \ngroup_\n combinator is given the type \nQGroupExpr\n.\n\n\nDuring query generation, the expressions of type \nQGroupExpr\n are added to the\n\nGROUP BY\n clause, and expressions of type \nQAgg\n are treated as aggregation to\nbe computed.\n\n\nThe result of the \naggregate_\n lifts all the \nQAgg\ns and \nQGroupExpr\ns to\n'regular' value-level \nQExpr\ns, so the result of \naggregate_\n can be used in\nexpressions as usual.\n\n\nSimple aggregate usage\n\n\nSuppose we wanted to count the number of genres in our database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n_\n \n-\n \ncountAll_\n)\n \n(\nall_\n \n(\ngenre\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT COUNT(*) AS \nres0\n\n\nFROM \nGenre\n AS \nt0\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nCOUNT\n(\n*\n)\n \nAS\n \nres0\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAdding a GROUP BY clause\n\n\nAbove, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the \ngroup_\n function to\ngroup by the genre.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n \n(\ngroup_\n \ngenre\n,\n \nas_\n \n@\nInt\n \n$\n \ncount_\n \n(\ntrackId\n \ntrack\n)))\n\n           \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       COUNT(\nt1\n.\nTrackId\n) AS \nres2\n\n\nFROM \nGenre\n AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n\n\nGROUP BY \nt0\n.\nGenreId\n,\n\n\n         \nt0\n.\nName\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nt1\n.\nTrackId\n)\n \nAS\n \nres2\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\ncount_\n can return any \nIntegral\n type. Adding the explicit \nas_ @Int\n above \nprevents an ambiguous type error.\n\n\n\n\nSQL compatibility\n\n\nAbove, we demonstrated the use of \ncount_\n and \ncountAll_\n which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.\n\n\nIn general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example, \nsum_\n\ncorresponds to the SQL aggregate \nSUM\n.\n\n\nSQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by \nOver\n. For example \nSUM(DISTINCT x)\n can be\nwritten \nsumOver_ distinctInGroup_ x\n. The universally quantified version of\neach aggregate is obtained by using the \nallInGroup_\n quantifier. Thus, \nsum_ ==\nsumOver_ allInGroup_\n. Because \nALL\n is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the \nallInGroupExplicitly_\n quantifier.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n              \n(\n \ngroup_\n \ngenre\n\n              \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n              \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n           \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\nFROM \nGenre\n AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n\n\nGROUP BY \nt0\n.\nGenreId\n,\n\n\n         \nt0\n.\nName\n -- With values: [SQLInteger 1000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe \nbeam-core\n library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).\n\n\n\n\n\n\n\n\nSQL Aggregate\n\n\nRelevant standard\n\n\nUnquantified beam function\n\n\nQuantified beam function\n\n\n\n\n\n\n\n\n\n\nSUM\n\n\nSQL92\n\n\nsum_\n\n\nsumOver_\n\n\n\n\n\n\nMIN\n\n\nSQL92\n\n\nmin_\n\n\nminOver_\n\n\n\n\n\n\nMAX\n\n\nSQL92\n\n\nmax_\n\n\nmaxOver_\n\n\n\n\n\n\nAVG\n\n\nSQL92\n\n\navg_\n\n\navgOver_\n\n\n\n\n\n\nCOUNT(x)\n\n\nSQL92\n\n\ncount_\n\n\ncountOver_\n\n\n\n\n\n\nCOUNT(*)\n\n\nSQL92\n\n\ncountAll_\n\n\nN/A\n\n\n\n\n\n\nEVERY(x)\n\n\nSQL99\n\n\nevery_\n\n\neveryOver_\n\n\n\n\n\n\nANY(x)/SOME(x)\n\n\nSQL99\n\n\nany_\n, \nsome_\n\n\nanyOver_\n, \nsomeOver_\n\n\n\n\n\n\n\n\nThe \nHAVING\n clause\n\n\nSQL allows users to specify a \nHAVING\n condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports \nHAVIVG\n clauses, but does\nnot use any special syntax. Simply use \nfilter_\n or \nguard_\n as usual, and beam\nwill add a \nHAVING\n clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a \nWHERE\n clause. Either way, this is transparent to the user.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n\naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n              \n(\n \ngroup_\n \ngenre\n\n              \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n              \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n           \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n       \nt0\n.\nName\n AS \nres1\n,\n\n\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\nFROM \nGenre\n AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n\n\nGROUP BY \nt0\n.\nGenreId\n,\n\n\n         \nt0\n.\nName\n\n\nHAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nName\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n       \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n\nFROM\n \nGenre\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n\nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n         \nt0\n.\nName\n\n\nHAVING\n \n((\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBeam will also handle the \nfilter_\n correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\nfilter_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n\ndo\n \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \ntrack\n \n-\n \njoin_\n \n(\ntrack\n \nchinookDb\n)\n \n(\n\\\ntrack\n \n-\n \ntrackGenreId\n \ntrack\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt1\n.\nName\n AS \nres3\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt1\n.\nComposer\n AS \nres7\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt1\n.\nBytes\n AS \nres9\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n\n\n       \nt0\n.\nres2\n AS \nres11\n,\n\n\n       \nt0\n.\nres3\n AS \nres12\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n          \nt0\n.\nName\n AS \nres1\n,\n\n\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\n   FROM \nGenre\n AS \nt0\n\n\n   INNER JOIN \nTrack\n AS \nt1\n\n\n   GROUP BY \nt0\n.\nGenreId\n,\n\n\n            \nt0\n.\nName\n) AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n)=(\nt0\n.\nres0\n)\n\n\nWHERE (\nt0\n.\nres3\n)\n=(?) -- With values: [SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \n=\n \n(\nt0\n.\nres0\n)\n\n\nWHERE\n \n(\nt0\n.\nres3\n)\n \n=\n \n(\n300000\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe position of \nfilter_\n changes the code generated. Above, the \nfilter_\n\nproduced a \nWHERE\n clause on the outermost \nSELECT\n. If instead, we put the\n\nfilter_\n clause right outside the \naggregate_\n, beam will produce a \nHAVING\n clause instead.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n\n   \ntrack\n \n-\n \njoin_\n \n(\ntrack\n \nchinookDb\n)\n \n(\n\\\ntrack\n \n-\n \ntrackGenreId\n \ntrack\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n,\n\n\n       \nt1\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt1\n.\nName\n AS \nres3\n,\n\n\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt1\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt1\n.\nComposer\n AS \nres7\n,\n\n\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt1\n.\nBytes\n AS \nres9\n,\n\n\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n\n\n       \nt0\n.\nres2\n AS \nres11\n,\n\n\n       \nt0\n.\nres3\n AS \nres12\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n          \nt0\n.\nName\n AS \nres1\n,\n\n\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\n   FROM \nGenre\n AS \nt0\n\n\n   INNER JOIN \nTrack\n AS \nt1\n\n\n   GROUP BY \nt0\n.\nGenreId\n,\n\n\n            \nt0\n.\nName\n\n\n   HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?)) AS \nt0\n\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n)=(\nt0\n.\nres0\n) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt1\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt1\n.\nName\n \nAS\n \nres3\n,\n\n       \nt1\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt1\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt1\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt1\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt1\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt1\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt1\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt0\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt0\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n\n   \nHAVING\n \n((\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n \nON\n \n(\nt1\n.\nGenreId\n)\n \n=\n \n(\nt0\n.\nres0\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDue to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \ntrack_\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n \n   \nguard_\n \n(\ntrackGenreId\n \ntrack_\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack_\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n\n\n       \nt1\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt0\n.\nName\n AS \nres3\n,\n\n\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt0\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt0\n.\nComposer\n AS \nres7\n,\n\n\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt0\n.\nBytes\n AS \nres9\n,\n\n\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n\n\n       \nt1\n.\nres2\n AS \nres11\n,\n\n\n       \nt1\n.\nres3\n AS \nres12\n\n\nFROM \nTrack\n AS \nt0\n\n\nINNER JOIN\n\n\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n          \nt0\n.\nName\n AS \nres1\n,\n\n\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\n   FROM \nGenre\n AS \nt0\n\n\n   INNER JOIN \nTrack\n AS \nt1\n\n\n   GROUP BY \nt0\n.\nGenreId\n,\n\n\n            \nt0\n.\nName\n) AS \nt1\n\n\nWHERE ((\nt1\n.\nres3\n)\n=(?))\n\n\n  AND ((\nt0\n.\nGenreId\n)=(\nt1\n.\nres0\n)) -- With values: [SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nName\n \nAS\n \nres1\n,\n\n          \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n          \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n   \nFROM\n \nGenre\n \nAS\n \nt0\n\n   \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n   \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n            \nt0\n.\nName\n)\n \nAS\n \nt1\n\n\nWHERE\n \n((\nt1\n.\nres3\n)\n \n=\n \n(\n300000\n))\n\n  \nAND\n \n((\nt0\n.\nGenreId\n)\n \n=\n \n(\nt1\n.\nres0\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can prove to the compiler that the \nfilter_\n should generate a having by\nusing the \nsubselect_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\n\n\ndo\n \ntrack_\n \n-\n \nall_\n \n(\ntrack\n \nchinookDb\n)\n\n   \n(\ngenre\n,\n \npriceCnt\n,\n \ntrackLength\n)\n \n-\n\n            \nsubselect_\n \n$\n\n            \nfilter_\n \n(\n\\\n(\ngenre\n,\n \ndistinctPriceCount\n,\n \ntotalTrackLength\n)\n \n-\n \ntotalTrackLength\n \n=.\n \n300000\n)\n \n$\n\n            \naggregate_\n \n(\n\\\n(\ngenre\n,\n \ntrack\n)\n \n-\n\n                          \n(\n \ngroup_\n \ngenre\n\n                          \n,\n \nas_\n \n@\nInt\n \n$\n \ncountOver_\n \ndistinctInGroup_\n \n(\ntrackUnitPrice\n \ntrack\n)\n\n                          \n,\n \nsumOver_\n \nallInGroupExplicitly_\n \n(\ntrackMilliseconds\n \ntrack\n)\n \n`\ndiv_\n`\n \n1000\n \n))\n \n$\n\n            \n((,)\n \n$\n \nall_\n \n(\ngenre\n \nchinookDb\n)\n \n*\n \nall_\n \n(\ntrack\n \nchinookDb\n))\n \n   \nguard_\n \n(\ntrackGenreId\n \ntrack_\n \n==.\n \njust_\n \n(\npk\n \ngenre\n))\n\n   \npure\n \n(\ngenre\n,\n \ntrack_\n,\n \npriceCnt\n,\n \ntrackLength\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n\n\n       \nt1\n.\nres1\n AS \nres1\n,\n\n\n       \nt0\n.\nTrackId\n AS \nres2\n,\n\n\n       \nt0\n.\nName\n AS \nres3\n,\n\n\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n\n\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n\n\n       \nt0\n.\nGenreId\n AS \nres6\n,\n\n\n       \nt0\n.\nComposer\n AS \nres7\n,\n\n\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n\n\n       \nt0\n.\nBytes\n AS \nres9\n,\n\n\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n\n\n       \nt1\n.\nres2\n AS \nres11\n,\n\n\n       \nt1\n.\nres3\n AS \nres12\n\n\nFROM \nTrack\n AS \nt0\n\n\nINNER JOIN\n\n\n  (SELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n          \nt0\n.\nres1\n AS \nres1\n,\n\n\n          \nt0\n.\nres2\n AS \nres2\n,\n\n\n          \nt0\n.\nres3\n AS \nres3\n\n\n   FROM\n\n\n     (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n\n\n             \nt0\n.\nName\n AS \nres1\n,\n\n\n             COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n\n\n             (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n\n      FROM \nGenre\n AS \nt0\n\n\n      INNER JOIN \nTrack\n AS \nt1\n\n\n      GROUP BY \nt0\n.\nGenreId\n,\n\n\n               \nt0\n.\nName\n\n\n      HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?)) AS \nt0\n) AS \nt1\n\n\nWHERE (\nt0\n.\nGenreId\n)=(\nt1\n.\nres0\n) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt1\n.\nres0\n \nAS\n \nres0\n,\n\n       \nt1\n.\nres1\n \nAS\n \nres1\n,\n\n       \nt0\n.\nTrackId\n \nAS\n \nres2\n,\n\n       \nt0\n.\nName\n \nAS\n \nres3\n,\n\n       \nt0\n.\nAlbumId\n \nAS\n \nres4\n,\n\n       \nt0\n.\nMediaTypeId\n \nAS\n \nres5\n,\n\n       \nt0\n.\nGenreId\n \nAS\n \nres6\n,\n\n       \nt0\n.\nComposer\n \nAS\n \nres7\n,\n\n       \nt0\n.\nMilliseconds\n \nAS\n \nres8\n,\n\n       \nt0\n.\nBytes\n \nAS\n \nres9\n,\n\n       \nt0\n.\nUnitPrice\n \nAS\n \nres10\n,\n\n       \nt1\n.\nres2\n \nAS\n \nres11\n,\n\n       \nt1\n.\nres3\n \nAS\n \nres12\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\nINNER\n \nJOIN\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n,\n\n          \nt0\n.\nres2\n \nAS\n \nres2\n,\n\n          \nt0\n.\nres3\n \nAS\n \nres3\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nGenreId\n \nAS\n \nres0\n,\n\n             \nt0\n.\nName\n \nAS\n \nres1\n,\n\n             \nCOUNT\n(\nDISTINCT\n \nt1\n.\nUnitPrice\n)\n \nAS\n \nres2\n,\n\n             \n(\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n)\n \nAS\n \nres3\n\n      \nFROM\n \nGenre\n \nAS\n \nt0\n\n      \nINNER\n \nJOIN\n \nTrack\n \nAS\n \nt1\n\n      \nGROUP\n \nBY\n \nt0\n.\nGenreId\n,\n\n               \nt0\n.\nName\n\n      \nHAVING\n \n((\nSUM\n(\nALL\n \nt1\n.\nMilliseconds\n))\n \n/\n \n(\n1000\n))\n \n=\n \n(\n300000\n))\n \nAS\n \nt0\n)\n \nAS\n \nt1\n\n\nWHERE\n \n(\nt0\n.\nGenreId\n)\n \n=\n \n(\nt1\n.\nres0\n)", 
            "title": "Aggregates"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#simple-aggregate-usage", 
            "text": "Suppose we wanted to count the number of genres in our database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ _   -   countAll_ )   ( all_   ( genre   chinookDb ))  \n\n         \n    \n         \n             SELECT COUNT(*) AS  res0  FROM  Genre  AS  t0  -- With values: []  \n\n         \n    \n         \n             SELECT   COUNT ( * )   AS   res0  FROM   Genre   AS   t0", 
            "title": "Simple aggregate usage"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#adding-a-group-by-clause", 
            "text": "Above, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the  group_  function to\ngroup by the genre.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ ( genre ,   track )   -   ( group_   genre ,   as_   @ Int   $   count_   ( trackId   track ))) \n            ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,          t0 . Name  AS  res1 ,         COUNT( t1 . TrackId ) AS  res2  FROM  Genre  AS  t0  INNER JOIN  Track  AS  t1  GROUP BY  t0 . GenreId ,            t0 . Name  -- With values: []  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( t1 . TrackId )   AS   res2  FROM   Genre   AS   t0  INNER   JOIN   Track   AS   t1  GROUP   BY   t0 . GenreId , \n          t0 . Name  \n\n         \n    \n         \n    \n                 \n                       Tip  count_  can return any  Integral  type. Adding the explicit  as_ @Int  above \nprevents an ambiguous type error.", 
            "title": "Adding a GROUP BY clause"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#sql-compatibility", 
            "text": "Above, we demonstrated the use of  count_  and  countAll_  which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.  In general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example,  sum_ \ncorresponds to the SQL aggregate  SUM .  SQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by  Over . For example  SUM(DISTINCT x)  can be\nwritten  sumOver_ distinctInGroup_ x . The universally quantified version of\neach aggregate is obtained by using the  allInGroup_  quantifier. Thus,  sum_ ==\nsumOver_ allInGroup_ . Because  ALL  is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the  allInGroupExplicitly_  quantifier.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ ( genre ,   track )   - \n               (   group_   genre \n               ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n               ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n            ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,          t0 . Name  AS  res1 ,         COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,         (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3  FROM  Genre  AS  t0  INNER JOIN  Track  AS  t1  GROUP BY  t0 . GenreId ,            t0 . Name  -- With values: [SQLInteger 1000]  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3  FROM   Genre   AS   t0  INNER   JOIN   Track   AS   t1  GROUP   BY   t0 . GenreId , \n          t0 . Name  \n\n         \n    \n         \n    \n                 \n                      The  beam-core  library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).     SQL Aggregate  Relevant standard  Unquantified beam function  Quantified beam function      SUM  SQL92  sum_  sumOver_    MIN  SQL92  min_  minOver_    MAX  SQL92  max_  maxOver_    AVG  SQL92  avg_  avgOver_    COUNT(x)  SQL92  count_  countOver_    COUNT(*)  SQL92  countAll_  N/A    EVERY(x)  SQL99  every_  everyOver_    ANY(x)/SOME(x)  SQL99  any_ ,  some_  anyOver_ ,  someOver_", 
            "title": "SQL compatibility"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#the-having-clause", 
            "text": "SQL allows users to specify a  HAVING  condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports  HAVIVG  clauses, but does\nnot use any special syntax. Simply use  filter_  or  guard_  as usual, and beam\nwill add a  HAVING  clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a  WHERE  clause. Either way, this is transparent to the user.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $  aggregate_   ( \\ ( genre ,   track )   - \n               (   group_   genre \n               ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n               ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n            ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n\n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,          t0 . Name  AS  res1 ,         COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,         (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3  FROM  Genre  AS  t0  INNER JOIN  Track  AS  t1  GROUP BY  t0 . GenreId ,            t0 . Name  HAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t0 . GenreId   AS   res0 , \n        t0 . Name   AS   res1 , \n        COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n        ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3  FROM   Genre   AS   t0  INNER   JOIN   Track   AS   t1  GROUP   BY   t0 . GenreId , \n          t0 . Name  HAVING   (( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 ))   =   ( 300000 )  \n\n         \n    \n         \n    \n                 \n                      Beam will also handle the  filter_  correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  filter_   ( \\ ( genre ,   track ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $  do   ( genre ,   priceCnt ,   trackLength )   - \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    track   -   join_   ( track   chinookDb )   ( \\ track   -   trackGenreId   track   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t1 . TrackId  AS  res2 ,          t1 . Name  AS  res3 ,          t1 . AlbumId  AS  res4 ,          t1 . MediaTypeId  AS  res5 ,          t1 . GenreId  AS  res6 ,          t1 . Composer  AS  res7 ,          t1 . Milliseconds  AS  res8 ,          t1 . Bytes  AS  res9 ,          t1 . UnitPrice  AS  res10 ,          t0 . res2  AS  res11 ,          t0 . res3  AS  res12  FROM    (SELECT  t0 . GenreId  AS  res0 ,             t0 . Name  AS  res1 ,            COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,            (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3     FROM  Genre  AS  t0     INNER JOIN  Track  AS  t1     GROUP BY  t0 . GenreId ,               t0 . Name ) AS  t0  INNER JOIN  Track  AS  t1  ON ( t1 . GenreId )=( t0 . res0 )  WHERE ( t0 . res3 ) =(?) -- With values: [SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t0  INNER   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   =   ( t0 . res0 )  WHERE   ( t0 . res3 )   =   ( 300000 )  \n\n         \n    \n         \n    \n                 \n                      The position of  filter_  changes the code generated. Above, the  filter_ \nproduced a  WHERE  clause on the outermost  SELECT . If instead, we put the filter_  clause right outside the  aggregate_ , beam will produce a  HAVING  clause instead.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   ( genre ,   priceCnt ,   trackLength )   - \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb )) \n    track   -   join_   ( track   chinookDb )   ( \\ track   -   trackGenreId   track   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1 ,          t1 . TrackId  AS  res2 ,          t1 . Name  AS  res3 ,          t1 . AlbumId  AS  res4 ,          t1 . MediaTypeId  AS  res5 ,          t1 . GenreId  AS  res6 ,          t1 . Composer  AS  res7 ,          t1 . Milliseconds  AS  res8 ,          t1 . Bytes  AS  res9 ,          t1 . UnitPrice  AS  res10 ,          t0 . res2  AS  res11 ,          t0 . res3  AS  res12  FROM    (SELECT  t0 . GenreId  AS  res0 ,             t0 . Name  AS  res1 ,            COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,            (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3     FROM  Genre  AS  t0     INNER JOIN  Track  AS  t1     GROUP BY  t0 . GenreId ,               t0 . Name     HAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?)) AS  t0  INNER JOIN  Track  AS  t1  ON ( t1 . GenreId )=( t0 . res0 ) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t0 . res0   AS   res0 , \n        t0 . res1   AS   res1 , \n        t1 . TrackId   AS   res2 , \n        t1 . Name   AS   res3 , \n        t1 . AlbumId   AS   res4 , \n        t1 . MediaTypeId   AS   res5 , \n        t1 . GenreId   AS   res6 , \n        t1 . Composer   AS   res7 , \n        t1 . Milliseconds   AS   res8 , \n        t1 . Bytes   AS   res9 , \n        t1 . UnitPrice   AS   res10 , \n        t0 . res2   AS   res11 , \n        t0 . res3   AS   res12  FROM \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name \n    HAVING   (( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 ))   =   ( 300000 ))   AS   t0  INNER   JOIN   Track   AS   t1   ON   ( t1 . GenreId )   =   ( t0 . res0 )  \n\n         \n    \n         \n    \n                 \n                      Due to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   track_   -   all_   ( track   chinookDb ) \n    ( genre ,   priceCnt ,   trackLength )   - \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n    guard_   ( trackGenreId   track_   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track_ ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,          t1 . res1  AS  res1 ,          t0 . TrackId  AS  res2 ,          t0 . Name  AS  res3 ,          t0 . AlbumId  AS  res4 ,          t0 . MediaTypeId  AS  res5 ,          t0 . GenreId  AS  res6 ,          t0 . Composer  AS  res7 ,          t0 . Milliseconds  AS  res8 ,          t0 . Bytes  AS  res9 ,          t0 . UnitPrice  AS  res10 ,          t1 . res2  AS  res11 ,          t1 . res3  AS  res12  FROM  Track  AS  t0  INNER JOIN    (SELECT  t0 . GenreId  AS  res0 ,             t0 . Name  AS  res1 ,            COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,            (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3     FROM  Genre  AS  t0     INNER JOIN  Track  AS  t1     GROUP BY  t0 . GenreId ,               t0 . Name ) AS  t1  WHERE (( t1 . res3 ) =(?))    AND (( t0 . GenreId )=( t1 . res0 )) -- With values: [SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  INNER   JOIN \n   ( SELECT   t0 . GenreId   AS   res0 , \n           t0 . Name   AS   res1 , \n           COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n           ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3 \n    FROM   Genre   AS   t0 \n    INNER   JOIN   Track   AS   t1 \n    GROUP   BY   t0 . GenreId , \n             t0 . Name )   AS   t1  WHERE   (( t1 . res3 )   =   ( 300000 )) \n   AND   (( t0 . GenreId )   =   ( t1 . res0 ))  \n\n         \n    \n         \n    \n                 \n                      You can prove to the compiler that the  filter_  should generate a having by\nusing the  subselect_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes  do   track_   -   all_   ( track   chinookDb ) \n    ( genre ,   priceCnt ,   trackLength )   - \n             subselect_   $ \n             filter_   ( \\ ( genre ,   distinctPriceCount ,   totalTrackLength )   -   totalTrackLength   =.   300000 )   $ \n             aggregate_   ( \\ ( genre ,   track )   - \n                           (   group_   genre \n                           ,   as_   @ Int   $   countOver_   distinctInGroup_   ( trackUnitPrice   track ) \n                           ,   sumOver_   allInGroupExplicitly_   ( trackMilliseconds   track )   ` div_ `   1000   ))   $ \n             ((,)   $   all_   ( genre   chinookDb )   *   all_   ( track   chinookDb ))  \n    guard_   ( trackGenreId   track_   ==.   just_   ( pk   genre )) \n    pure   ( genre ,   track_ ,   priceCnt ,   trackLength )  \n\n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,          t1 . res1  AS  res1 ,          t0 . TrackId  AS  res2 ,          t0 . Name  AS  res3 ,          t0 . AlbumId  AS  res4 ,          t0 . MediaTypeId  AS  res5 ,          t0 . GenreId  AS  res6 ,          t0 . Composer  AS  res7 ,          t0 . Milliseconds  AS  res8 ,          t0 . Bytes  AS  res9 ,          t0 . UnitPrice  AS  res10 ,          t1 . res2  AS  res11 ,          t1 . res3  AS  res12  FROM  Track  AS  t0  INNER JOIN    (SELECT  t0 . res0  AS  res0 ,             t0 . res1  AS  res1 ,             t0 . res2  AS  res2 ,             t0 . res3  AS  res3     FROM       (SELECT  t0 . GenreId  AS  res0 ,                t0 . Name  AS  res1 ,               COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,               (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3        FROM  Genre  AS  t0        INNER JOIN  Track  AS  t1        GROUP BY  t0 . GenreId ,                  t0 . Name        HAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?)) AS  t0 ) AS  t1  WHERE ( t0 . GenreId )=( t1 . res0 ) -- With values: [SQLInteger 1000,SQLInteger 1000,SQLInteger 300000]  \n\n         \n    \n         \n             SELECT   t1 . res0   AS   res0 , \n        t1 . res1   AS   res1 , \n        t0 . TrackId   AS   res2 , \n        t0 . Name   AS   res3 , \n        t0 . AlbumId   AS   res4 , \n        t0 . MediaTypeId   AS   res5 , \n        t0 . GenreId   AS   res6 , \n        t0 . Composer   AS   res7 , \n        t0 . Milliseconds   AS   res8 , \n        t0 . Bytes   AS   res9 , \n        t0 . UnitPrice   AS   res10 , \n        t1 . res2   AS   res11 , \n        t1 . res3   AS   res12  FROM   Track   AS   t0  INNER   JOIN \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 , \n           t0 . res2   AS   res2 , \n           t0 . res3   AS   res3 \n    FROM \n      ( SELECT   t0 . GenreId   AS   res0 , \n              t0 . Name   AS   res1 , \n              COUNT ( DISTINCT   t1 . UnitPrice )   AS   res2 , \n              ( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 )   AS   res3 \n       FROM   Genre   AS   t0 \n       INNER   JOIN   Track   AS   t1 \n       GROUP   BY   t0 . GenreId , \n                t0 . Name \n       HAVING   (( SUM ( ALL   t1 . Milliseconds ))   /   ( 1000 ))   =   ( 300000 ))   AS   t0 )   AS   t1  WHERE   ( t0 . GenreId )   =   ( t1 . res0 )", 
            "title": "The HAVING clause"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/", 
            "text": "SQL lets you combine the results of multiple \nSELECT\n statements using the\n\nUNION\n, \nINTERSECT\n, and \nEXCEPT\n clauses.\n\n\nSQL Set operations\n\n\nThe SQL Set operations are provided as the \nunion_\n, \nintersect_\n, and \nexcept_\n\nfunctions. SQL also allows an optional \nALL\n clause to be specified with each of\nthese. Beam implements these as \nunionAll_\n, \nintersectAll_\n, and \nexceptAll_\n\nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.\n\n\nFor example, suppose we wanted the first and last names of both customers and\nemployees.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nunion_\n \ncustomerNames\n \nemployeeNames\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n       \nt0\n.\nLastName\n AS \nres1\n\n\nFROM \nCustomer\n AS \nt0\n\n\nUNION\n\n\nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n       \nt0\n.\nLastName\n AS \nres1\n\n\nFROM \nEmployee\n AS \nt0\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nCombining arbitrary set expressions\n\n\nSuppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use \nUNION\n to combine the\nresults of a query over the first names of employees and customers, and an\n\nEXCEPT\n to get all customer last names that were not employee ones. Finally, an\n\nINTERSECT\n would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.\n\n\nOn backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerFirstNames\n \n=\n\n      \nfmap\n \ncustomerFirstName\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeFirstNames\n \n=\n\n      \nfmap\n \nemployeeFirstName\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n    \ncustomerLastNames\n \n=\n\n      \nfmap\n \ncustomerLastName\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeLastNames\n \n=\n\n      \nfmap\n \nemployeeLastName\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \n(\ncustomerFirstNames\n \n`\nunion_\n`\nemployeeFirstNames\n)\n \n`\nintersect_\n`\n\n   \n(\ncustomerLastNames\n \n`\nexcept_\n`\n \nemployeeLastNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n\n\n   FROM \nCustomer\n AS \nt0\n\n\n   UNION SELECT \nt0\n.\nFirstName\n AS \nres0\n\n\n   FROM \nEmployee\n AS \nt0\n) AS \nt0\n INTERSECT\n\n\nSELECT \nt0\n.\nres0\n AS \nres0\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nLastName\n AS \nres0\n\n\n   FROM \nCustomer\n AS \nt0\n\n\n   EXCEPT SELECT \nt0\n.\nLastName\n AS \nres0\n\n\n   FROM \nEmployee\n AS \nt0\n) AS \nt0\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n(\n\n   \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n    \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n \nUNION\n\n   \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n\n    \nFROM\n \nEmployee\n \nAS\n \nt0\n))\n \nINTERSECT\n \n(\n\n                                           \n(\nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n                                            \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n                                         \nEXCEPT\n\n                                           \n(\nSELECT\n \nt0\n.\nLastName\n \nAS\n \nres0\n\n                                            \nFROM\n \nEmployee\n \nAS\n \nt0\n))\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nLIMIT\n/\nOFFSET\n and set operations\n\n\nThe \nLIMIT\n and \nOFFSET\n clauses generated by \nlimit_\n and \noffset_\n apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the \nLIMIT\n and \nOFFSET\n at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.\n\n\nFor example, to get the second ten full names in common.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nlimit_\n \n10\n \n(\nunion_\n \ncustomerNames\n \nemployeeNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n       \nt0\n.\nLastName\n AS \nres1\n\n\nFROM \nCustomer\n AS \nt0\n\n\nUNION\n\n\nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n       \nt0\n.\nLastName\n AS \nres1\n\n\nFROM \nEmployee\n AS \nt0\n\n\nLIMIT 10 -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nCustomer\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n          \nt0\n.\nLastName\n \nAS\n \nres1\n\n   \nFROM\n \nEmployee\n \nAS\n \nt0\n)\n\n\nLIMIT\n \n10\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf we only wanted the union of the first 10 names of each.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet\n \ncustomerNames\n \n=\n\n      \nfmap\n \n(\n\\\nc\n \n-\n \n(\ncustomerFirstName\n \nc\n,\n \ncustomerLastName\n \nc\n))\n\n           \n(\nall_\n \n(\ncustomer\n \nchinookDb\n))\n\n    \nemployeeNames\n \n=\n\n      \nfmap\n \n(\n\\\ne\n \n-\n \n(\nemployeeFirstName\n \ne\n,\n \nemployeeLastName\n \ne\n))\n\n           \n(\nall_\n \n(\nemployee\n \nchinookDb\n))\n\n\nin\n \nunion_\n \n(\nlimit_\n \n10\n \ncustomerNames\n)\n \n(\nlimit_\n \n10\n \nemployeeNames\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n          \nt0\n.\nLastName\n AS \nres1\n\n\n   FROM \nCustomer\n AS \nt0\n\n\n   LIMIT 10) AS \nt0\n\n\nUNION\n\n\nSELECT \nt0\n.\nres0\n AS \nres0\n,\n\n\n       \nt0\n.\nres1\n AS \nres1\n\n\nFROM\n\n\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n\n\n          \nt0\n.\nLastName\n AS \nres1\n\n\n   FROM \nEmployee\n AS \nt0\n\n\n   LIMIT 10) AS \nt0\n -- With values: []\n\n\n\n\n        \n\n    \n        \n\n            \n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n             \nt0\n.\nLastName\n \nAS\n \nres1\n\n      \nFROM\n \nCustomer\n \nAS\n \nt0\n\n      \nLIMIT\n \n10\n)\n \nAS\n \nt0\n)\n\n\nUNION\n\n  \n(\nSELECT\n \nt0\n.\nres0\n \nAS\n \nres0\n,\n\n          \nt0\n.\nres1\n \nAS\n \nres1\n\n   \nFROM\n\n     \n(\nSELECT\n \nt0\n.\nFirstName\n \nAS\n \nres0\n,\n\n             \nt0\n.\nLastName\n \nAS\n \nres1\n\n      \nFROM\n \nEmployee\n \nAS\n \nt0\n\n      \nLIMIT\n \n10\n)\n \nAS\n \nt0\n)", 
            "title": "Combining queries"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#sql-set-operations", 
            "text": "The SQL Set operations are provided as the  union_ ,  intersect_ , and  except_ \nfunctions. SQL also allows an optional  ALL  clause to be specified with each of\nthese. Beam implements these as  unionAll_ ,  intersectAll_ , and  exceptAll_ \nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.  For example, suppose we wanted the first and last names of both customers and\nemployees.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   union_   customerNames   employeeNames  \n\n         \n    \n         \n             SELECT  t0 . FirstName  AS  res0 ,          t0 . LastName  AS  res1  FROM  Customer  AS  t0  UNION  SELECT  t0 . FirstName  AS  res0 ,          t0 . LastName  AS  res1  FROM  Employee  AS  t0  -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Customer   AS   t0 )  UNION \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Employee   AS   t0 )", 
            "title": "SQL Set operations"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#combining-arbitrary-set-expressions", 
            "text": "Suppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use  UNION  to combine the\nresults of a query over the first names of employees and customers, and an EXCEPT  to get all customer last names that were not employee ones. Finally, an INTERSECT  would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.  On backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   customerFirstNames   = \n       fmap   customerFirstName \n            ( all_   ( customer   chinookDb )) \n     employeeFirstNames   = \n       fmap   employeeFirstName \n            ( all_   ( employee   chinookDb )) \n     customerLastNames   = \n       fmap   customerLastName \n            ( all_   ( customer   chinookDb )) \n     employeeLastNames   = \n       fmap   employeeLastName \n            ( all_   ( employee   chinookDb ))  in   ( customerFirstNames   ` union_ ` employeeFirstNames )   ` intersect_ ` \n    ( customerLastNames   ` except_ `   employeeLastNames )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0  FROM    (SELECT  t0 . FirstName  AS  res0     FROM  Customer  AS  t0     UNION SELECT  t0 . FirstName  AS  res0     FROM  Employee  AS  t0 ) AS  t0  INTERSECT  SELECT  t0 . res0  AS  res0  FROM    (SELECT  t0 . LastName  AS  res0     FROM  Customer  AS  t0     EXCEPT SELECT  t0 . LastName  AS  res0     FROM  Employee  AS  t0 ) AS  t0  -- With values: []  \n\n         \n    \n         \n             ( \n    ( SELECT   t0 . FirstName   AS   res0 \n     FROM   Customer   AS   t0 ) \n  UNION \n    ( SELECT   t0 . FirstName   AS   res0 \n     FROM   Employee   AS   t0 ))   INTERSECT   ( \n                                            ( SELECT   t0 . LastName   AS   res0 \n                                             FROM   Customer   AS   t0 ) \n                                          EXCEPT \n                                            ( SELECT   t0 . LastName   AS   res0 \n                                             FROM   Employee   AS   t0 ))", 
            "title": "Combining arbitrary set expressions"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#limitoffset-and-set-operations", 
            "text": "The  LIMIT  and  OFFSET  clauses generated by  limit_  and  offset_  apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the  LIMIT  and  OFFSET  at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.  For example, to get the second ten full names in common.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   limit_   10   ( union_   customerNames   employeeNames )  \n\n         \n    \n         \n             SELECT  t0 . FirstName  AS  res0 ,          t0 . LastName  AS  res1  FROM  Customer  AS  t0  UNION  SELECT  t0 . FirstName  AS  res0 ,          t0 . LastName  AS  res1  FROM  Employee  AS  t0  LIMIT 10 -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Customer   AS   t0 )  UNION \n   ( SELECT   t0 . FirstName   AS   res0 , \n           t0 . LastName   AS   res1 \n    FROM   Employee   AS   t0 )  LIMIT   10  \n\n         \n    \n         \n    \n                 \n                      If we only wanted the union of the first 10 names of each.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let   customerNames   = \n       fmap   ( \\ c   -   ( customerFirstName   c ,   customerLastName   c )) \n            ( all_   ( customer   chinookDb )) \n     employeeNames   = \n       fmap   ( \\ e   -   ( employeeFirstName   e ,   employeeLastName   e )) \n            ( all_   ( employee   chinookDb ))  in   union_   ( limit_   10   customerNames )   ( limit_   10   employeeNames )  \n\n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1  FROM    (SELECT  t0 . FirstName  AS  res0 ,             t0 . LastName  AS  res1     FROM  Customer  AS  t0     LIMIT 10) AS  t0  UNION  SELECT  t0 . res0  AS  res0 ,          t0 . res1  AS  res1  FROM    (SELECT  t0 . FirstName  AS  res0 ,             t0 . LastName  AS  res1     FROM  Employee  AS  t0     LIMIT 10) AS  t0  -- With values: []  \n\n         \n    \n         \n                ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . FirstName   AS   res0 , \n              t0 . LastName   AS   res1 \n       FROM   Customer   AS   t0 \n       LIMIT   10 )   AS   t0 )  UNION \n   ( SELECT   t0 . res0   AS   res0 , \n           t0 . res1   AS   res1 \n    FROM \n      ( SELECT   t0 . FirstName   AS   res0 , \n              t0 . LastName   AS   res1 \n       FROM   Employee   AS   t0 \n       LIMIT   10 )   AS   t0 )", 
            "title": "LIMIT/OFFSET and set operations"
        }, 
        {
            "location": "/user-guide/queries/window-functions/", 
            "text": "Window functions allow you to calculate aggregates over portions of your result\nset. They are defined in SQL2003. Some databases use the alternative\nnomenclature \nanalytic functions\n. They are expressed in SQL with the \nOVER\n\nclause. The\n\nPostgres documentation\n\noffers a good overview of window functions.\n\n\nThe \nwithWindow_\n function\n\n\nWhen you want to add windows to a query, use the \nwithWindow_\n function to\nintroduce your frames, and compute the projection. You may notice that this is a\ndeparture from SQL syntax, where you can define window expressions inline. Beam\nseeks to be type-safe. Queries with window functions follow slightly different\nrules. Wrapping such a query with a special function allows beam to enforce\nthese rules.\n\n\nFor example, to get each invoice along with the average invoice total by each\ncustomer, use \nwithWindow_\n as follows.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres9\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr to get each invoice along with the ranking of each invoice by total per\ncustomer \nand\n the overall ranking,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \n(\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n\n                   \n,\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n \n))\n\n            \n(\n\\\ni\n \n(\nallInvoices\n,\n \ncustomerInvoices\n)\n \n-\n \n(\ni\n,\n \nrank_\n \n`\nover_\n`\n \nallInvoices\n,\n \nrank_\n \n`\nover_\n`\n \ncustomerInvoices\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nRANK\n()\n \nOVER\n \n(\n\n                    \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres9\n,\n\n       \nRANK\n()\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n\n                    \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres10\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nrank_\n is only available in backends that implement the optional SQL2003\nT611 feature \"Elementary OLAP operations\". Beam syntaxes that implement this\nfunctionality implement the\n\nIsSql2003ExpressionElementaryOLAPOperationsSyntax\n type class.\n\n\n\n\nNotice that aggregates over the result of the window expression work as you'd\nexpect. Beam automatically generates a subquery once a query has been windowed.\nFor example, to get the sum of the totals of the invoices, by rank.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \norderBy_\n \n(\n\\\n(\nrank\n,\n \n_\n)\n \n-\n \nasc_\n \nrank\n)\n \n$\n\n\naggregate_\n \n(\n\\\n(\ni\n,\n \nrank\n)\n \n-\n \n(\ngroup_\n \nrank\n,\n \nsum_\n \n$\n \ninvoiceTotal\n \ni\n))\n \n$\n\n\nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \nrank_\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nres9\n \nAS\n \nres0\n,\n\n       \nSUM\n(\nt0\n.\nres8\n)\n \nAS\n \nres1\n\n\nFROM\n\n  \n(\nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n          \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n          \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n          \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n          \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n          \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n          \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n          \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n          \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n          \nRANK\n()\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n\n                       \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres9\n\n   \nFROM\n \nInvoice\n \nAS\n \nt0\n)\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nres9\n\n\nORDER\n \nBY\n \nt0\n.\nres9\n \nASC\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nFrame syntax\n\n\nThe \nframe_\n function takes a partition, ordering, and bounds parameter, all of\nwhich are optional. To specify no partition, use \nnoPartition_\n. For no\nordering, use \nnoOrder_\n. For no bounds, use \nnoBounds_\n.\n\n\nTo specify a partition, use \npartitionBy_\n with an expression or a tuple of\nexpressions. To specify an ordering use \norderPartitionBy_\n with an ordering\nexpression or a tuple of ordering expressions. Ordering expressions are scalar\nexpressions passed to either \nasc_\n or \ndesc_\n. Finally, to specify bounds, use\n\nbounds_\n or \nfromBound_\n. \nfromBound_\n starts the window at the specified\nposition, which can be \nunbounded_\n (the default) to include all rows seen thus\nfar. \nbounds_\n lets you specify an optional ending bound, which can be \nNothing\n\n(the default), \nJust unbounded_\n (the semantic default, but producing an\nexplicit bound syntactically), or \nJust (nrows_ x)\n, where \nx\n is an integer\nexpression, specifying the number of rows before or after to include in the\ncalculation.\n\n\nThe following query illustrates some of these features. Along with each invoice, it returns\n\n\n\n\nThe average total of all invoices, given by the frame with no partition, ordering, and bounds.\n\n\nThe average total of all invoices, by customer.\n\n\nThe rank of each invoice over all the rows, when ordered by total.\n\n\nThe average of the totals of the invoices starting at the two immediately\n  preceding and ending with the two immediately succeeding invoices, when\n  ordered by date.\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \n(\n \nframe_\n \nnoPartition_\n \nnoOrder_\n \nnoBounds_\n\n                   \n,\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n\n                   \n,\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceTotal\n \ni\n)))\n \nnoBounds_\n\n                   \n,\n \nframe_\n \nnoPartition_\n \n(\norderPartitionBy_\n \n(\nasc_\n \n(\ninvoiceDate\n \ni\n)))\n \n(\nbounds_\n \n(\nnrows_\n \n2\n)\n \n(\nJust\n \n(\nnrows_\n \n2\n)))))\n\n            \n(\n\\\ni\n \n(\nallRows_\n,\n \nsameCustomer_\n,\n \ntotals_\n,\n \nfourInvoicesAround_\n)\n \n-\n\n                 \n(\n \ni\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nallRows_\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nsameCustomer_\n\n                 \n,\n \nrank_\n \n`\nover_\n`\n \ntotals_\n\n                 \n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nover_\n`\n \nfourInvoicesAround_\n \n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n()\n \nAS\n \nres9\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres10\n,\n\n       \nRANK\n()\n \nOVER\n \n(\n\n                    \nORDER\n \nBY\n \nt0\n.\nTotal\n \nASC\n)\n \nAS\n \nres11\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nOVER\n \n(\n\n                               \nORDER\n \nBY\n \nt0\n.\nInvoiceDate\n \nASC\n \nROWS\n \nBETWEEN\n \n2\n \nPRECEDING\n \nAND\n \n2\n \nFOLLOWING\n)\n \nAS\n \nres12\n\n\nFROM\n \nInvoice\n \nAS\n \nt0", 
            "title": "Window functions"
        }, 
        {
            "location": "/user-guide/queries/window-functions/#the-withwindow_-function", 
            "text": "When you want to add windows to a query, use the  withWindow_  function to\nintroduce your frames, and compute the projection. You may notice that this is a\ndeparture from SQL syntax, where you can define window expressions inline. Beam\nseeks to be type-safe. Queries with window functions follow slightly different\nrules. Wrapping such a query with a special function allows beam to enforce\nthese rules.  For example, to get each invoice along with the average invoice total by each\ncustomer, use  withWindow_  as follows.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ ) \n             ( \\ i   w   -   ( i ,   avg_   ( invoiceTotal   i )   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res9  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                      Or to get each invoice along with the ranking of each invoice by total per\ncustomer  and  the overall ranking,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   (   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ \n                    ,   frame_   ( partitionBy_   ( invoiceCustomer   i ))   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_   )) \n             ( \\ i   ( allInvoices ,   customerInvoices )   -   ( i ,   rank_   ` over_ `   allInvoices ,   rank_   ` over_ `   customerInvoices )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        RANK ()   OVER   ( \n                     ORDER   BY   t0 . Total   ASC )   AS   res9 , \n        RANK ()   OVER   ( PARTITION   BY   t0 . CustomerId \n                     ORDER   BY   t0 . Total   ASC )   AS   res10  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Note  rank_  is only available in backends that implement the optional SQL2003\nT611 feature \"Elementary OLAP operations\". Beam syntaxes that implement this\nfunctionality implement the IsSql2003ExpressionElementaryOLAPOperationsSyntax  type class.   Notice that aggregates over the result of the window expression work as you'd\nexpect. Beam automatically generates a subquery once a query has been windowed.\nFor example, to get the sum of the totals of the invoices, by rank.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             orderBy_   ( \\ ( rank ,   _ )   -   asc_   rank )   $  aggregate_   ( \\ ( i ,   rank )   -   ( group_   rank ,   sum_   $   invoiceTotal   i ))   $  withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ ) \n             ( \\ i   w   -   ( i ,   rank_   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . res9   AS   res0 , \n        SUM ( t0 . res8 )   AS   res1  FROM \n   ( SELECT   t0 . InvoiceId   AS   res0 , \n           t0 . CustomerId   AS   res1 , \n           t0 . InvoiceDate   AS   res2 , \n           t0 . BillingAddress   AS   res3 , \n           t0 . BillingCity   AS   res4 , \n           t0 . BillingState   AS   res5 , \n           t0 . BillingCountry   AS   res6 , \n           t0 . BillingPostalCode   AS   res7 , \n           t0 . Total   AS   res8 , \n           RANK ()   OVER   ( PARTITION   BY   t0 . CustomerId \n                        ORDER   BY   t0 . Total   ASC )   AS   res9 \n    FROM   Invoice   AS   t0 )   AS   t0  GROUP   BY   t0 . res9  ORDER   BY   t0 . res9   ASC", 
            "title": "The withWindow_ function"
        }, 
        {
            "location": "/user-guide/queries/window-functions/#frame-syntax", 
            "text": "The  frame_  function takes a partition, ordering, and bounds parameter, all of\nwhich are optional. To specify no partition, use  noPartition_ . For no\nordering, use  noOrder_ . For no bounds, use  noBounds_ .  To specify a partition, use  partitionBy_  with an expression or a tuple of\nexpressions. To specify an ordering use  orderPartitionBy_  with an ordering\nexpression or a tuple of ordering expressions. Ordering expressions are scalar\nexpressions passed to either  asc_  or  desc_ . Finally, to specify bounds, use bounds_  or  fromBound_ .  fromBound_  starts the window at the specified\nposition, which can be  unbounded_  (the default) to include all rows seen thus\nfar.  bounds_  lets you specify an optional ending bound, which can be  Nothing \n(the default),  Just unbounded_  (the semantic default, but producing an\nexplicit bound syntactically), or  Just (nrows_ x) , where  x  is an integer\nexpression, specifying the number of rows before or after to include in the\ncalculation.  The following query illustrates some of these features. Along with each invoice, it returns   The average total of all invoices, given by the frame with no partition, ordering, and bounds.  The average total of all invoices, by customer.  The rank of each invoice over all the rows, when ordered by total.  The average of the totals of the invoices starting at the two immediately\n  preceding and ending with the two immediately succeeding invoices, when\n  ordered by date.   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   (   frame_   noPartition_   noOrder_   noBounds_ \n                    ,   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ \n                    ,   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceTotal   i )))   noBounds_ \n                    ,   frame_   noPartition_   ( orderPartitionBy_   ( asc_   ( invoiceDate   i )))   ( bounds_   ( nrows_   2 )   ( Just   ( nrows_   2 ))))) \n             ( \\ i   ( allRows_ ,   sameCustomer_ ,   totals_ ,   fourInvoicesAround_ )   - \n                  (   i \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   allRows_ \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   sameCustomer_ \n                  ,   rank_   ` over_ `   totals_ \n                  ,   avg_   ( invoiceTotal   i )   ` over_ `   fourInvoicesAround_   )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   OVER   ()   AS   res9 , \n        AVG ( t0 . Total )   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res10 , \n        RANK ()   OVER   ( \n                     ORDER   BY   t0 . Total   ASC )   AS   res11 , \n        AVG ( t0 . Total )   OVER   ( \n                                ORDER   BY   t0 . InvoiceDate   ASC   ROWS   BETWEEN   2   PRECEDING   AND   2   FOLLOWING )   AS   res12  FROM   Invoice   AS   t0", 
            "title": "Frame syntax"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/", 
            "text": "This page documents other advanced features that beam supports across backends\nthat support them.\n\n\nSQL2003 T611: Elementary OLAP operations\n\n\nThis optional SQL2003 feature allows attaching arbitrary \nFILTER (WHERE ..)\n\nclauses to aggregates. During querying only rows matching the given expression\nare included in computing the aggregate. This can often be simulated in other\ndatabases by an appropriate \nCASE\n expression, but beam will not do this\ntranslation.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\ni\n \n-\n \n(\ngroup_\n \n(\ninvoiceCustomer\n \ni\n),\n \nas_\n \n@\nInt\n \n$\n \ncountAll_\n \n`\nfilterWhere_\n`\n \n(\ninvoiceTotal\n \ni\n \n.\n \n500\n),\n \nas_\n \n@\nInt\n \n$\n \ncountAll_\n \n`\nfilterWhere_\n`\n \n(\ninvoiceTotal\n \ni\n \n.\n \n100\n)))\n \n$\n\n\nall_\n \n(\ninvoice\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nCustomerId\n \nAS\n \nres0\n,\n\n       \nCOUNT\n(\n*\n)\n \nFILTER\n \n(\n\n                        \nWHERE\n \n(\nt0\n.\nTotal\n)\n \n \n(\n500.0\n))\n \nAS\n \nres1\n,\n\n       \nCOUNT\n(\n*\n)\n \nFILTER\n \n(\n\n                        \nWHERE\n \n(\nt0\n.\nTotal\n)\n \n \n(\n100.0\n))\n \nAS\n \nres2\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\nGROUP\n \nBY\n \nt0\n.\nCustomerId\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThese combine as you'd expect with window functions. For example, to return each\ninvoice along with the average total of all invoices by the same customer where\nthe invoice was billed to an address in Los Angeles,\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nwithWindow_\n \n(\n\\\ni\n \n-\n \nframe_\n \n(\npartitionBy_\n \n(\ninvoiceCustomer\n \ni\n))\n \nnoOrder_\n \nnoBounds_\n)\n\n            \n(\n\\\ni\n \nw\n \n-\n \n(\ni\n,\n \navg_\n \n(\ninvoiceTotal\n \ni\n)\n \n`\nfilterWhere_\n`\n \n(\naddressCity\n \n(\ninvoiceBillingAddress\n \ni\n)\n \n==.\n \njust_\n \nLos Angeles\n)\n \n`\nover_\n`\n \nw\n))\n\n            \n(\nall_\n \n(\ninvoice\n \nchinookDb\n))\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nt0\n.\nInvoiceId\n \nAS\n \nres0\n,\n\n       \nt0\n.\nCustomerId\n \nAS\n \nres1\n,\n\n       \nt0\n.\nInvoiceDate\n \nAS\n \nres2\n,\n\n       \nt0\n.\nBillingAddress\n \nAS\n \nres3\n,\n\n       \nt0\n.\nBillingCity\n \nAS\n \nres4\n,\n\n       \nt0\n.\nBillingState\n \nAS\n \nres5\n,\n\n       \nt0\n.\nBillingCountry\n \nAS\n \nres6\n,\n\n       \nt0\n.\nBillingPostalCode\n \nAS\n \nres7\n,\n\n       \nt0\n.\nTotal\n \nAS\n \nres8\n,\n\n       \nAVG\n(\nt0\n.\nTotal\n)\n \nFILTER\n \n(\n\n                                 \nWHERE\n \n(\nt0\n.\nBillingCity\n)\n \n=\n \n(\nLos Angeles\n))\n \nOVER\n \n(\nPARTITION\n \nBY\n \nt0\n.\nCustomerId\n)\n \nAS\n \nres9\n\n\nFROM\n \nInvoice\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nDanger\n\n\nFILTER (WHERE ..)\n must be applied directly to a SQL aggregate function,\nbut this isn't enforced at compile time. This may be fixed in a later\nversion of beam.\n\n\n\n\nThis extension also provides various window functions for SQL. The only one beam\ncurrently implements is \nRANK()\n via the \nrank_\n function. Contributions are\nappreciated!\n\n\nSQL2003 T612: Advanced OLAP operations\n\n\nThis provides both the \nPERCENT_RANK()\n and \nCUME_DIST()\n functions as\n\npercentRank_\n and \ncumeDist_\n respectively.", 
            "title": "Advanced features"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/#sql2003-t611-elementary-olap-operations", 
            "text": "This optional SQL2003 feature allows attaching arbitrary  FILTER (WHERE ..) \nclauses to aggregates. During querying only rows matching the given expression\nare included in computing the aggregate. This can often be simulated in other\ndatabases by an appropriate  CASE  expression, but beam will not do this\ntranslation.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ i   -   ( group_   ( invoiceCustomer   i ),   as_   @ Int   $   countAll_   ` filterWhere_ `   ( invoiceTotal   i   .   500 ),   as_   @ Int   $   countAll_   ` filterWhere_ `   ( invoiceTotal   i   .   100 )))   $  all_   ( invoice   chinookDb )  \n\n         \n    \n         \n             SELECT   t0 . CustomerId   AS   res0 , \n        COUNT ( * )   FILTER   ( \n                         WHERE   ( t0 . Total )     ( 500.0 ))   AS   res1 , \n        COUNT ( * )   FILTER   ( \n                         WHERE   ( t0 . Total )     ( 100.0 ))   AS   res2  FROM   Invoice   AS   t0  GROUP   BY   t0 . CustomerId  \n\n         \n    \n         \n    \n                 \n                      These combine as you'd expect with window functions. For example, to return each\ninvoice along with the average total of all invoices by the same customer where\nthe invoice was billed to an address in Los Angeles,  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             withWindow_   ( \\ i   -   frame_   ( partitionBy_   ( invoiceCustomer   i ))   noOrder_   noBounds_ ) \n             ( \\ i   w   -   ( i ,   avg_   ( invoiceTotal   i )   ` filterWhere_ `   ( addressCity   ( invoiceBillingAddress   i )   ==.   just_   Los Angeles )   ` over_ `   w )) \n             ( all_   ( invoice   chinookDb ))  \n\n         \n    \n         \n             SELECT   t0 . InvoiceId   AS   res0 , \n        t0 . CustomerId   AS   res1 , \n        t0 . InvoiceDate   AS   res2 , \n        t0 . BillingAddress   AS   res3 , \n        t0 . BillingCity   AS   res4 , \n        t0 . BillingState   AS   res5 , \n        t0 . BillingCountry   AS   res6 , \n        t0 . BillingPostalCode   AS   res7 , \n        t0 . Total   AS   res8 , \n        AVG ( t0 . Total )   FILTER   ( \n                                  WHERE   ( t0 . BillingCity )   =   ( Los Angeles ))   OVER   ( PARTITION   BY   t0 . CustomerId )   AS   res9  FROM   Invoice   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Danger  FILTER (WHERE ..)  must be applied directly to a SQL aggregate function,\nbut this isn't enforced at compile time. This may be fixed in a later\nversion of beam.   This extension also provides various window functions for SQL. The only one beam\ncurrently implements is  RANK()  via the  rank_  function. Contributions are\nappreciated!", 
            "title": "SQL2003 T611: Elementary OLAP operations"
        }, 
        {
            "location": "/user-guide/queries/advanced-features/#sql2003-t612-advanced-olap-operations", 
            "text": "This provides both the  PERCENT_RANK()  and  CUME_DIST()  functions as percentRank_  and  cumeDist_  respectively.", 
            "title": "SQL2003 T612: Advanced OLAP operations"
        }, 
        {
            "location": "/user-guide/extensibility/", 
            "text": "The \nbeam-core\n library and respective backends strive to expose the full power\nof each underlying database. If a particular feature is missing, please feel\nfree to file a bug report on the GitHub issue tracker.\n\n\nHowever, in the meantime, beam offers a few options to inject raw SQL into your\nqueries. Of course, beam cannot predict types of expressions and queries that\nwere not created with its combinators, so \ncaveat emptor\n.\n\n\nCustom expressions\n\n\nIf you'd like to write an expression that beam currently does not support, you\ncan use the \ncustomExpr_\n function. Your backend's syntax must implement the\n\nIsSqlCustomExpressionSyntax\n type class. \ncustomExpr_\n takes a function of\narity \nn\n and \nn\n arguments, which must all be \nQGenExpr\ns with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same \ncustomExpr_\n).\n\n\nThe function supplied must return a string-like expression that it can build\nusing provided \nIsString\n and \nMonoid\n instances. The type of the expression is\nopaque to the user. The function's arguments will have the same type as the\nreturn type. Thus, they can be embedded into the returned expression using\n\nmappend\n. The arguments will be properly parenthesized and can be inserted\nwhole into the final expression. You will likely need to explicitly supply a\nresult type using the \nas_\n function.\n\n\nFor example, below, we use \ncustomExpr_\n to access the \nregr_intercept\n and\n\nregr_slope\n functions in postgres.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_\n \n(\n\\\nt\n \n-\n \n(\n \nas_\n \n@\nDouble\n \n@\nQAggregateContext\n \n$\n \ncustomExpr_\n \n(\n\\\nbytes\n \nms\n \n-\n \nregr_intercept(\n \n \nbytes\n \n \n, \n \n \nms\n \n \n)\n)\n \n(\ntrackBytes\n \nt\n)\n \n(\ntrackMilliseconds\n \nt\n)\n\n                  \n,\n \nas_\n \n@\nDouble\n \n@\nQAggregateContext\n \n$\n \ncustomExpr_\n \n(\n\\\nbytes\n \nms\n \n-\n \nregr_slope(\n \n \nbytes\n \n \n, \n \n \nms\n \n \n)\n)\n \n(\ntrackBytes\n \nt\n)\n \n(\ntrackMilliseconds\n \nt\n)\n \n))\n \n$\n\n\nall_\n \n(\ntrack\n \nchinookDb\n)\n\n\n\n\n        \n\n    \n        \n\n            \nSELECT\n \nregr_intercept\n((\nt0\n.\nBytes\n),\n \n(\nt0\n.\nMilliseconds\n))\n \nAS\n \nres0\n,\n\n       \nregr_slope\n((\nt0\n.\nBytes\n),\n \n(\nt0\n.\nMilliseconds\n))\n \nAS\n \nres1\n\n\nFROM\n \nTrack\n \nAS\n \nt0\n\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nCustom queries (i.e., embedding arbitrary expressions into \nQ\n) is currently\nbeing planned, but not implemented.", 
            "title": "Custom queries"
        }, 
        {
            "location": "/user-guide/extensibility/#custom-expressions", 
            "text": "If you'd like to write an expression that beam currently does not support, you\ncan use the  customExpr_  function. Your backend's syntax must implement the IsSqlCustomExpressionSyntax  type class.  customExpr_  takes a function of\narity  n  and  n  arguments, which must all be  QGenExpr s with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same  customExpr_ ).  The function supplied must return a string-like expression that it can build\nusing provided  IsString  and  Monoid  instances. The type of the expression is\nopaque to the user. The function's arguments will have the same type as the\nreturn type. Thus, they can be embedded into the returned expression using mappend . The arguments will be properly parenthesized and can be inserted\nwhole into the final expression. You will likely need to explicitly supply a\nresult type using the  as_  function.  For example, below, we use  customExpr_  to access the  regr_intercept  and regr_slope  functions in postgres.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_   ( \\ t   -   (   as_   @ Double   @ QAggregateContext   $   customExpr_   ( \\ bytes   ms   -   regr_intercept(     bytes     ,      ms     ) )   ( trackBytes   t )   ( trackMilliseconds   t ) \n                   ,   as_   @ Double   @ QAggregateContext   $   customExpr_   ( \\ bytes   ms   -   regr_slope(     bytes     ,      ms     ) )   ( trackBytes   t )   ( trackMilliseconds   t )   ))   $  all_   ( track   chinookDb )  \n\n         \n    \n         \n             SELECT   regr_intercept (( t0 . Bytes ),   ( t0 . Milliseconds ))   AS   res0 , \n        regr_slope (( t0 . Bytes ),   ( t0 . Milliseconds ))   AS   res1  FROM   Track   AS   t0  \n\n         \n    \n         \n    \n                 \n                       Note  Custom queries (i.e., embedding arbitrary expressions into  Q ) is currently\nbeing planned, but not implemented.", 
            "title": "Custom expressions"
        }, 
        {
            "location": "/user-guide/manipulation/insert/", 
            "text": "", 
            "title": "INSERT"
        }, 
        {
            "location": "/user-guide/manipulation/update/", 
            "text": "", 
            "title": "UPDATE"
        }, 
        {
            "location": "/user-guide/manipulation/delete/", 
            "text": "", 
            "title": "DELETE"
        }, 
        {
            "location": "/schema-guide/migrations/", 
            "text": "Warning\n\n\nThe \nbeam-migrations\n package is still a WIP. The following manual\nrepresents both planned and implemented features. If you'd like to help\nguide development, please join\nthe\n\nbeam-discussion\n mailing list\n.\n\n\n\n\nIn the User Guide we saw how to declare a schema for an already created database\nand use it to perform queries. Beam can also manage a database schema based on\nHaskell datatypes you feed it.\n\n\nThe Beam Migrations Framework is meant to be a robust, modular, and opinionated\nway of managing schema changes. It is an optional part of beam provided in the\n\nbeam-migrate\n package.\n\n\nInstall the migrations framework and tool by running\n\n\n$ cabal install beam-migrate\n\n# or\n\n$ stack install beam-migrate\n\n\n\n\n\nThis installs the \nbeam-migrate\n library as well as a CLI tool (named\n\nbeam-migrate\n as well) which automates common tasks.\n\n\nIf you use \nstack\n make sure you always use \nstack exec -- beam-migrate\n instead\nof the typical \nbeam-migrate\n command in order to have the package path\nautomatically and correctly set for you.\n\n\nBasic concepts\n\n\nIn the user guide, we saw how we can use \ndefaultDbSettings\n to generate default\nmetadata that can be used to access the database. This default metadata is\nenough to query, but not enough for \nbeam-migrate\n. Thus, \nbeam-migrate\n offers\nthe \ndefaultMigratableDbSettings\n function, which annotates the database schema\nwith additional information. Whereas \ndefaultDbSettings\n yields a value of type\n\nDatabaseSettings be db\n, \ndefaultMigratableDbSettings\n yields a value of type\n\nCheckedDatabaseSettings be db\n. You can recover a \nDatabaseSettings be db\n from\na \nCheckedDatabaseSettings be db\n value by applying the \nunCheckDatabase\n\nfunction.\n\n\nThe \nCheckedDatabaseSettings\n value contains the original \nDatabaseSettings\n\nalong with a series of \npredicates\n. Each \npredicate\n describes one aspect of\nthe database. As far as \nbeam-migrate\n is concerned, each database schema is\nfully specified by the set of predicates that apply to it. \nbeam-migrate\n calls\nthis the \nchecked type\n of the database.\n\n\nFor example, a database schema that consists of one table named \ntable\n with no\nfields is represented uniquely by the \nchecked type\n of \n[TableExistsPredicate\n\"table\"]\n. If you add a field \nfield1\n of type \nINT\n to the table, then the\nchecked type becomes \n[TableExistsPredicate \"table\", TableHasColumn \"table\"\n\"field1\" intType]\n.\n\n\n\n\nNote\n\n\nThe types are a bit more complicated than what they appear. In particular, a\npredicate can be of any type that satisfies the \nDatabasePredicate\n type\nclass. The predicates can be stored in a list because they are wrapped in\nthe \nSomeDatabasePredicate\n GADT that holds the type class instance as well.\n\n\n\n\nAutomatic migration generation\n\n\nGiven two \nCheckedDatabaseSettings\n values, \nbeam-migrate\n can generate a set of\nSQL steps that will transform one schema to another. The generation of such\nsteps is an exceedingly difficult problem in general. \nbeam-migrate\n can\nautomatically handle most common cases, but it will not always succeed. In this\ncase, it can present to you a list of steps it thinks are best as well as what\nremains to be solved.\n\n\nThe migration generation is implemented as a proof search in linear logic\n1\n. In\nparticular, \nbeam-migrate\n views a migration as a linear logic proof of the form\n\na \u22b8 b\n, where \na\n is the set of predicates of the original schema and \nb\n is\nthe set of predicates in the target schema. \nbeam-migrate\n ships with a set of\ndefault proof steps. Backends can add to these steps for backend-specific\npredicates.\n\n\n\n\nNote\n\n\nAt this time, Haskell does not allow the expression of linear programs (this\nwill change with the introduction of linear types). Thus, migrations written\nin Haskell are not checked by GHC for linear-ness, but \nbeam-migrate\n will\nvalidate such migrations at run-time to the best of its ability.\n\n\n\n\nThe migration prover may not be able to find a migration in a sufficiently short\nperiod of time. \nbeam-migrate\n's algorithm is designed to terminate, but this\nmay take a while. Additionally, the prover will not automatically generate steps\nfor some migrations. For example, \nbeam-migrate\n will never rename a table\nwithout explicit instructions.\n\n\nFor these cases, the \nbeam-migrate\n command line interface offers an\n\ninteractive\n mode. Here, it presents both database types for the user's\ninspection, as well as a list of steps \nbeam-migrate\n thinks it can take based\non these types. The user can choose to let \nbeam-migrate\n guess the next step,\nor the user can select a step that \nbeam-migrate\n offers as the next step, or\nthe user can enter his/her own step and select which predicates are consumed and\ngenerated.\n\n\nAdvantages of checked migrations\n\n\nUnlike other database migration frameworks, the checking process allows\n\nbeam-migrate\n to be sure that the migration you specify will result in the\ndatabase type you want. Also, checked migrations allow the programmer to verify\nthat the database they are accessing indeed matches what their schema expects.\n\n\nUsage modes\n\n\nbeam-migrate\n can be used as a library or a command-line tool in \nmanaged\n or\n\nunmanaged\n mode.\n\n\nThe \nbeam-migrate\n library\n\n\nThe \nbeam-migrate\n library provides syntax definitions for common SQL DDL tasks.\nIt also provides types for expressing migrations as transformations of one or\nmore schemas to another. The library exports types for database backends to hook\ninto automated migration tools (including the \nbeam-migrate\n tool). Finally, it\nalso implements the migration solver. Its use is described in the next section.\n\n\nThe \nbeam-migrate\n tool\n\n\nIn \nunmanaged\n mode, the \nbeam-migrate\n tool offers a set of convenience\nfunctionality for generating migrations, checking databases, etc based off of a\nschema. It is useful for performing one-off tasks (such as generating a\nmigration script) that you don't want to recompile your project for.\n\n\nManaged\n mode extends the functionality of \nunmanaged\n mode with tools for\nmanaging sets of schemas and migrations between them. In this mode,\n\nbeam-migrate\n can be used to update a production or development database\nschema. This mode supports schema branching and version-control integration but\nforces you to adopt \nbeam-migrate\n's conventions.\n\n\n\n\nTip\n\n\nIf you're worried about a \nbeam-migrate\n dependency in a production\napplication, \nbeam-migrate\n can be used to freeze a particular checked\ndatabase settings object. This means you get a \nDatabaseSettings\n value\nwhich can be used in an application with only a \nbeam-core\n dependency.\n\n\n\n\n\n\n\n\n\n\n\n\nLinear logic is a type of logic first described by Jean-Yves Gerard. In\nparticular, it constrains the weakening and strengthening rules of classical\nlogic. Intuitively, you can think of it as forcing the rule that each\nassumption is used exactly once to produce the result. Read\nmore \non Wikipedia\n.", 
            "title": "The Migrations Framework"
        }, 
        {
            "location": "/schema-guide/migrations/#basic-concepts", 
            "text": "In the user guide, we saw how we can use  defaultDbSettings  to generate default\nmetadata that can be used to access the database. This default metadata is\nenough to query, but not enough for  beam-migrate . Thus,  beam-migrate  offers\nthe  defaultMigratableDbSettings  function, which annotates the database schema\nwith additional information. Whereas  defaultDbSettings  yields a value of type DatabaseSettings be db ,  defaultMigratableDbSettings  yields a value of type CheckedDatabaseSettings be db . You can recover a  DatabaseSettings be db  from\na  CheckedDatabaseSettings be db  value by applying the  unCheckDatabase \nfunction.  The  CheckedDatabaseSettings  value contains the original  DatabaseSettings \nalong with a series of  predicates . Each  predicate  describes one aspect of\nthe database. As far as  beam-migrate  is concerned, each database schema is\nfully specified by the set of predicates that apply to it.  beam-migrate  calls\nthis the  checked type  of the database.  For example, a database schema that consists of one table named  table  with no\nfields is represented uniquely by the  checked type  of  [TableExistsPredicate\n\"table\"] . If you add a field  field1  of type  INT  to the table, then the\nchecked type becomes  [TableExistsPredicate \"table\", TableHasColumn \"table\"\n\"field1\" intType] .   Note  The types are a bit more complicated than what they appear. In particular, a\npredicate can be of any type that satisfies the  DatabasePredicate  type\nclass. The predicates can be stored in a list because they are wrapped in\nthe  SomeDatabasePredicate  GADT that holds the type class instance as well.", 
            "title": "Basic concepts"
        }, 
        {
            "location": "/schema-guide/migrations/#automatic-migration-generation", 
            "text": "Given two  CheckedDatabaseSettings  values,  beam-migrate  can generate a set of\nSQL steps that will transform one schema to another. The generation of such\nsteps is an exceedingly difficult problem in general.  beam-migrate  can\nautomatically handle most common cases, but it will not always succeed. In this\ncase, it can present to you a list of steps it thinks are best as well as what\nremains to be solved.  The migration generation is implemented as a proof search in linear logic 1 . In\nparticular,  beam-migrate  views a migration as a linear logic proof of the form a \u22b8 b , where  a  is the set of predicates of the original schema and  b  is\nthe set of predicates in the target schema.  beam-migrate  ships with a set of\ndefault proof steps. Backends can add to these steps for backend-specific\npredicates.   Note  At this time, Haskell does not allow the expression of linear programs (this\nwill change with the introduction of linear types). Thus, migrations written\nin Haskell are not checked by GHC for linear-ness, but  beam-migrate  will\nvalidate such migrations at run-time to the best of its ability.   The migration prover may not be able to find a migration in a sufficiently short\nperiod of time.  beam-migrate 's algorithm is designed to terminate, but this\nmay take a while. Additionally, the prover will not automatically generate steps\nfor some migrations. For example,  beam-migrate  will never rename a table\nwithout explicit instructions.  For these cases, the  beam-migrate  command line interface offers an interactive  mode. Here, it presents both database types for the user's\ninspection, as well as a list of steps  beam-migrate  thinks it can take based\non these types. The user can choose to let  beam-migrate  guess the next step,\nor the user can select a step that  beam-migrate  offers as the next step, or\nthe user can enter his/her own step and select which predicates are consumed and\ngenerated.", 
            "title": "Automatic migration generation"
        }, 
        {
            "location": "/schema-guide/migrations/#advantages-of-checked-migrations", 
            "text": "Unlike other database migration frameworks, the checking process allows beam-migrate  to be sure that the migration you specify will result in the\ndatabase type you want. Also, checked migrations allow the programmer to verify\nthat the database they are accessing indeed matches what their schema expects.", 
            "title": "Advantages of checked migrations"
        }, 
        {
            "location": "/schema-guide/migrations/#usage-modes", 
            "text": "beam-migrate  can be used as a library or a command-line tool in  managed  or unmanaged  mode.", 
            "title": "Usage modes"
        }, 
        {
            "location": "/schema-guide/migrations/#the-beam-migrate-library", 
            "text": "The  beam-migrate  library provides syntax definitions for common SQL DDL tasks.\nIt also provides types for expressing migrations as transformations of one or\nmore schemas to another. The library exports types for database backends to hook\ninto automated migration tools (including the  beam-migrate  tool). Finally, it\nalso implements the migration solver. Its use is described in the next section.", 
            "title": "The beam-migrate library"
        }, 
        {
            "location": "/schema-guide/migrations/#the-beam-migrate-tool", 
            "text": "In  unmanaged  mode, the  beam-migrate  tool offers a set of convenience\nfunctionality for generating migrations, checking databases, etc based off of a\nschema. It is useful for performing one-off tasks (such as generating a\nmigration script) that you don't want to recompile your project for.  Managed  mode extends the functionality of  unmanaged  mode with tools for\nmanaging sets of schemas and migrations between them. In this mode, beam-migrate  can be used to update a production or development database\nschema. This mode supports schema branching and version-control integration but\nforces you to adopt  beam-migrate 's conventions.   Tip  If you're worried about a  beam-migrate  dependency in a production\napplication,  beam-migrate  can be used to freeze a particular checked\ndatabase settings object. This means you get a  DatabaseSettings  value\nwhich can be used in an application with only a  beam-core  dependency.       Linear logic is a type of logic first described by Jean-Yves Gerard. In\nparticular, it constrains the weakening and strengthening rules of classical\nlogic. Intuitively, you can think of it as forcing the rule that each\nassumption is used exactly once to produce the result. Read\nmore  on Wikipedia .", 
            "title": "The beam-migrate tool"
        }, 
        {
            "location": "/schema-guide/tool/", 
            "text": "Tool", 
            "title": "The beam-migrate tool"
        }, 
        {
            "location": "/schema-guide/supported/", 
            "text": "supported", 
            "title": "Supported migrations"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/", 
            "text": "The \nbeam-postgres\n backend is the most feature complete SQL backend for beam.\nThe Postgres RDBMS supports most of the standards beam follows, so you can\nusually expect most queries to simply work. Additionally, \nbeam-postgres\n is\npart of the standard Beam distribution, and so upgrades are applied\nperiodically, and new functions are added to achieve feature-parity with the\nlatest Postgres stable\n\n\nPostgres-specific data types\n\n\nPostgres has several data types not available from \nbeam-core\n. The\n\nbeam-postgres\n library provides several types and functions to make working\nwith these easier.\n\n\nThe \ntsvector\n and \ntsquery\n types\n\n\nThe \ntsvector\n and \ntsquery\n types form the basis of full-text search in\nPostgres.", 
            "title": "beam-postgres"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#postgres-specific-data-types", 
            "text": "Postgres has several data types not available from  beam-core . The beam-postgres  library provides several types and functions to make working\nwith these easier.", 
            "title": "Postgres-specific data types"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#the-tsvector-and-tsquery-types", 
            "text": "The  tsvector  and  tsquery  types form the basis of full-text search in\nPostgres.", 
            "title": "The tsvector and tsquery types"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/", 
            "text": "SQLite is a lightweight RDBMS meant for embedding in larger applications.\nBecause it is not designed to be full-featured, not all Beam queries will work\nwith SQLite. The module \nDatabase.Beam.SQLite.Checked\n provides many symbols\nusually imported from the \nDatabase.Beam\n module that enforce extra checks on\nqueries to assure compliance with SQLite. Use this module in code that is SQLite\nspecific for maximal compile-time safety. Note that this module should be\nimported instead of \nDatabase.Beam\n to avoid name clashes.\n\n\nCompatibility\n\n\nSQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "beam-sqlite"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/#compatibility", 
            "text": "SQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "Compatibility"
        }, 
        {
            "location": "/user-guide/custom-backends/", 
            "text": "Writing a custom backend", 
            "title": "Writing a Custom Backend"
        }, 
        {
            "location": "/about/compatibility/", 
            "text": "Beam strives to cover the full breadth of the relevant SQL\nstandards. In general, if there is something in a SQL standard that is\nnot implemented in a generic manner in \nbeam-core\n, feel free to file\nan issue requesting support. There are some features that beam\npurposefully omits because no major RDBMS implements them. For\nexample, database-level assertions are not supported in any of the\ndefault beam backends, and thus are not supported by \nbeam-core\n. If\nyou have a need for these features, feel free to file an issue. Be\nsure to motivate your use case with examples and a testing strategy.\n\n\nThe relevant SQL standards are SQL-92, SQL:1999, SQL:2003, SQL:2008,\nand SQL:2011. Because not all the standards are not publicly\naccessible, I've done my best to piece together features from various\ndocuments available online. I believe I've covered most of the common\ncases, but there may be pieces of functionality that are missing. File\nan issue if this is the case.\n\n\nThe table below summarizes the features defined in each SQL standard and beam's\nsupport for them. FULL means beam supports everything in that feature. NONE\nmeans that there is no support for that feature, and none planned. N/A means\nthat the feature only applies to RDBMSs, not the SQL language. WONTFIX means\nthat the feature has been considered and willfully ignored. UNKNOWN means not\nenough investigation has gone into the feature to make a determination. TODO\nmeans the feature has not been implemented yet, but an implementation is\nplanned.\n\n\n\n\nTip\n\n\nThe 'TODO' items are a great way to contribute to beam!\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\nStatus\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nB011 Embedded Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB012 Embedded C\n\n\nNONE\n\n\n\n\n\n\n\n\nB013 Embedded COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB014 Embedded FORTRAN\n\n\nNONE\n\n\n\n\n\n\n\n\nB015 Embedded MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB016 Embedded Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB017 Embedded PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB021 Direct SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB031 Basic dynamic SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB032 Extended dynamic SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB033 Untyped SQL-invoked function arguments\n\n\nNONE\n\n\n\n\n\n\n\n\nB034 Dynamic specification of cursor attributes\n\n\nNONE\n\n\n\n\n\n\n\n\nB035 Non-extended descriptor names\n\n\nNONE\n\n\n\n\n\n\n\n\nB051 Enhanced execution rights\n\n\nNONE\n\n\n\n\n\n\n\n\nB111 Module language Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB112 Module language C\n\n\nNONE\n\n\n\n\n\n\n\n\nB113 Module language COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB114 Module language Fortran\n\n\nNONE\n\n\n\n\n\n\n\n\nB115 Module language MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB116 Module language Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB117 Module language PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB121 Routine language Ada\n\n\nNONE\n\n\n\n\n\n\n\n\nB122 Routine language C\n\n\nNONE\n\n\n\n\n\n\n\n\nB123 Routine language COBOL\n\n\nNONE\n\n\n\n\n\n\n\n\nB124 Routine language Fortran\n\n\nNONE\n\n\n\n\n\n\n\n\nB125 Routine language MUMPS\n\n\nNONE\n\n\n\n\n\n\n\n\nB126 Routine language Pascal\n\n\nNONE\n\n\n\n\n\n\n\n\nB127 Routine language PL/I\n\n\nNONE\n\n\n\n\n\n\n\n\nB128 Routine language SQL\n\n\nNONE\n\n\n\n\n\n\n\n\nB211 Module language Ada: VARCHAR and NUMERIC support\n\n\nNONE\n\n\n\n\n\n\n\n\nB221 Routine language Ada: VARCHAR and NUMERIC support\n\n\nNONE\n\n\n\n\n\n\n\n\nE011 - Numeric data types\n\n\n\n\n\n\n\n\n\n\nE011-01 INTEGER and SMALLINT data types\n\n\nFULL\n\n\nUse \nInt32\n for \nINTEGER\n, \nInt16\n for \nSMALLINT\n\n\n\n\n\n\nE011-02 REAL, DOUBLE PRECISION, FLOAT\n\n\nFULL\n\n\nUse \nDouble\n and \nFloat\n\n\n\n\n\n\nE011-03 DECIMAL and NUMERIC data types\n\n\nFULL\n\n\nUse \nScientific\n. You can provide the database precision using \nbeam-migrate\n\n\n\n\n\n\nE011-04 Arithmetic operators\n\n\nFULL\n\n\nUse the \nNum\n instance for \nQGenExpr\n\n\n\n\n\n\nE011-05 Numeric comparison\n\n\nFULL\n\n\nUse the \n.\n prefixed operators (i.e., \n==.\n, \n/=.\n, \n.\n, etc)\n\n\n\n\n\n\nE011-06 Implicit casting among numeric data types\n\n\nWONTFIX\n\n\nBeam never implicitly casts. Use \ncast_\n\n\n\n\n\n\nE021 Character string types\n\n\n\n\n\n\n\n\n\n\nE021-01 CHARACTER data type\n\n\nFULL\n\n\nUse \nText\n. Use \nbeam-migrate\n to specify width\n\n\n\n\n\n\nE021-02 CHARACTER VARYING data type\n\n\nFULL\n\n\nUse \nText\n. Use \nbeam-migrate\n to specify width.\n\n\n\n\n\n\nE021-03 Character literals\n\n\nFULL\n\n\nUse \nval_\n\n\n\n\n\n\nE021-04 CHARACTER_LENGTH function\n\n\nFULL\n\n\nUse \ncharLength_\n\n\n\n\n\n\nE021-05 OCTET_LENGTH function\n\n\nFULL\n\n\nUse \noctetLength_\n\n\n\n\n\n\nE021-06 SUBSTRING function\n\n\nTODO\n\n\n\n\n\n\n\n\nE021-07 Character concatenation\n\n\nTODO\n\n\nUse \n(\n#x007c;\n#0x007c).\n\n\n\n\n\n\nE021-08 UPPER and LOWER functions\n\n\nTODO\n\n\nUse \nupper_\n and \nlower_\n\n\n\n\n\n\nE021-09 TRIM function\n\n\nTODO\n\n\nUse \ntrim_\n\n\n\n\n\n\nE021-10 Implicit casting among string types\n\n\nWONTFIX\n\n\nBeam never implicitly casts. Use \ncast_\n\n\n\n\n\n\nE021-11 POSITION function\n\n\nFULL\n\n\nUse \nposition_\n\n\n\n\n\n\nE021-12 Character comparison\n\n\nFULL\n\n\nUse comparison operators (See E011-05)\n\n\n\n\n\n\nE031 Identifiers\n\n\n\n\n\n\n\n\n\n\nE031-01 Delimited identifiers\n\n\nTODO\n\n\nFind out more\n\n\n\n\n\n\nE021-02 Lower case identifiers\n\n\nTODO\n\n\n\n\n\n\n\n\nE021-03 Trailing underscore\n\n\nN/A\n\n\nBeam will use whatever column names you specify\n\n\n\n\n\n\nE051 Basic query specification\n\n\n\n\n\n\n\n\n\n\nE051-01 SELECT DISTINCT\n\n\nTODO\n\n\nUse \nselectDistinct_\n\n\n\n\n\n\nE051-02 GROUP BY clause\n\n\nFULL\n\n\nSee \naggregate_\n or read the \nsection on aggregates\n\n\n\n\n\n\nE051-04 GROUP BY can contain columns not in SELECT\n\n\nTODO\n\n\nUnsure how this applies to beam in particular\n\n\n\n\n\n\nE051-05 Select list items can be renamed\n\n\nN/A\n\n\nBeam uses this feature internally, the user never needs it\n\n\n\n\n\n\nE051-06 HAVING clause\n\n\nFULL\n\n\nguard_\n and \nfilter_\n are appropriately converted to \nHAVING\n when allowed\n\n\n\n\n\n\nE051-07 Qualified * in select list\n\n\nN/A\n\n\nBeam handles projections instead\n\n\n\n\n\n\nE051-08 Correlation names in FROM\n\n\nTODO\n\n\nUnsure how this applies to beam\n\n\n\n\n\n\nE051-09 Rename columns in the FROM clause\n\n\nNONE\n\n\nBeam doesn't need this\n\n\n\n\n\n\nE061 Basic predicates and search conditions\n\n\n\n\n\n\n\n\n\n\nE061-01 Comparison predicate\n\n\nFULL\n\n\nUse the comparison operators (see E011-05)\n\n\n\n\n\n\nE061-02 BETWEEN predicate\n\n\nFULL\n\n\nUse \nbetween_\n\n\n\n\n\n\nE061-03 IN predicate with list of values\n\n\nTODO\n\n\n\n\n\n\n\n\nE061-04 LIKE predicate\n\n\nFULL\n\n\nUse \nlike_\n\n\n\n\n\n\nE061-05 LIKE predicate ESCAPE clause\n\n\nTODO\n\n\nUnsure how this would apply\n\n\n\n\n\n\nE061-06 NULL predicate\n\n\nFULL\n\n\nUse \nisNull_\n and \nisNotNull_\n\n\n\n\n\n\nE061-07 Quantified comparison predicate\n\n\nPARTIAL\n\n\nSupported in syntaxes, not exposed in \nQGenExpr\n (TODO)\n\n\n\n\n\n\nE051-08 EXISTS predicate\n\n\nFULL\n\n\nUse \nexists_\n\n\n\n\n\n\nE061-09 Subqueries in comparison predicate\n\n\nFULL\n\n\nUse \nsubquery_\n as usual\n\n\n\n\n\n\nE061-11 Subqueries in IN predicate\n\n\nTODO\n\n\nWould be fixed by E061-03\n\n\n\n\n\n\nE061-12 Subqueries in quantified comparison predicate\n\n\nTODO\n\n\nWould be fixed by E061-07\n\n\n\n\n\n\nE061-13 Correlated subqueries\n\n\nFULL\n\n\nUse \nsubquery_\n\n\n\n\n\n\nE061-14 Search condition\n\n\nFULL\n\n\nConstruct \nQGenExprs\n with type \nBool\n\n\n\n\n\n\nE071 Basic query expressions\n\n\n\n\n\n\n\n\n\n\nE071-01 UNION DISTINCT table operator\n\n\nFULL\n\n\nUse \nunion_\n\n\n\n\n\n\nE071-02 UNION ALL table operator\n\n\nFULL\n\n\nUse \nunionAll_\n\n\n\n\n\n\nE071-03 EXCEPT DISTINCT table operator\n\n\nFULL\n\n\nUse \nexcept_\n\n\n\n\n\n\nE071-05 Columns combined via operators need not have same type\n\n\nWONTFIX\n\n\nBeam is strongly typed\n\n\n\n\n\n\nE071-06 Table operators in subqueries\n\n\nFULL\n\n\nSupported for backends that support it\n\n\n\n\n\n\nE081 Basic privileges\n\n\nNONE\n\n\nDatabase security is not beam's focus. \nbeam-migrate\n may expose this in the future\n\n\n\n\n\n\nE091 Set functions\n\n\n\n\n\n\n\n\n\n\nE091-01 AVG\n\n\nFULL\n\n\nUse \navg_\n or \navgOver_\n\n\n\n\n\n\nE091-02 COUNT\n\n\nFULL\n\n\nUse \ncountAll_\n, \ncountAllOver_\n, \ncount_\n, or \ncountOver_\n\n\n\n\n\n\nE091-03 MAX\n\n\nFULL\n\n\nUse \nmax_\n or \nmaxOver_\n\n\n\n\n\n\nE091-04 MIN\n\n\nFULL\n\n\nUse \nmin_\n or \nminOver_\n\n\n\n\n\n\nE091-05 SUM\n\n\nFULL\n\n\nUse \nsum_\n or \nsumOver_\n\n\n\n\n\n\nE091-06 ALL quantifier\n\n\nFULL\n\n\nUse the \n*Over_\n functions with the \nallInGroupExplicitly_\n quantifier\n\n\n\n\n\n\nE091-07 DISTINCT quantifier\n\n\nFULL\n\n\nUse the \n*Over_\n functions with the \ndistinctInGroup_\n quantifier\n\n\n\n\n\n\nE101 Basic data manipulation\n\n\n\n\n\n\n\n\n\n\nE101-01 INSERT statement\n\n\nFULL\n\n\nUse \ninsert\n and \nSqlInsert\n\n\n\n\n\n\nE101-03 Searched UPDATE\n\n\nFULL\n\n\nUse \nupdate\n and \nSqlUpdate\n\n\n\n\n\n\nE101-04 Searched DELETE\n\n\nFULL\n\n\nUse \ndelete\n and \nSqlDelete\n\n\n\n\n\n\nE111 Single row SELECT statement\n\n\nFULL\n\n\nUse \nselect\n as expected\n\n\n\n\n\n\nE121 Basic cursor support\n\n\nNONE\n\n\nUse the backends explicitly\n\n\n\n\n\n\nE131 Null value support\n\n\nPARTIAL\n\n\nUse \nMaybe\n column types, \nNullable\n, and the \njust_\n, \nnothing_\n, and \nmaybe_\n functions\n\n\n\n\n\n\nE141 Basic integrity constraints\n\n\n\n\nImplemented in \nbeam-migrate\n\n\n\n\n\n\nE141-01 NOT NULL constraints\n\n\nFULL\n\n\nUse \nnotNull_\n\n\n\n\n\n\nE141-02 UNIQUE constraints of NOT NULL columns\n\n\nTODO\n\n\n\n\n\n\n\n\nE141-03 PRIMARY KEY constraints\n\n\nFULL\n\n\nInstantiate \nTable\n with the correct \nPrimaryKey\n\n\n\n\n\n\nE141-04 Basic FOREIGN KEY constraints\n\n\nTODO\n\n\nYou can embed the \nPrimaryKey\n of the relation directly.\n\n\n\n\n\n\nE141-06 CHECK constraints\n\n\nTODO\n\n\n\n\n\n\n\n\nE141-07 Column defaults\n\n\nFULL\n\n\nUse \ndefault_\n from \nbeam-migrate\n\n\n\n\n\n\nE141-08 NOT NULL inferred on PRIMARY KEY\n\n\nN/A\n\n\n\n\n\n\n\n\nE141-10 Names in a foreign key can be specified in any order\n\n\nN/A\n\n\n\n\n\n\n\n\nE151 Transaction support\n\n\nNone\n\n\nUse the backend functions explicitly\n\n\n\n\n\n\nE152 SET TRANSACTION statement\n\n\nN/A\n\n\n\n\n\n\n\n\nE153 Updatable queries with subqueries\n\n\nTODO\n\n\n\n\n\n\n\n\nE161 SQL comments with double minus\n\n\nN/A\n\n\n\n\n\n\n\n\nE171 SQLSTATE support\n\n\nN/A\n\n\n\n\n\n\n\n\nE182 Host language binding\n\n\nN/A\n\n\n\n\n\n\n\n\nF031 Basic schema manipulation\n\n\n\n\n\n\n\n\n\n\nF031-01 CREATE TABLE for persistent base tables\n\n\nFULL\n\n\nUse \ncreateTable_\n in \nbeam-migrate\n\n\n\n\n\n\nF031-02 CREATE VIEW statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-03 GRANT statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-04 ALTER TABLE statement: ADD COLUMN clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-13 DROP TABLE statement: RESTRICT clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-16 DROP VIEW statement: RESTRICT clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF031-19 REVOKE statement: RESTRICT clause\n\n\nNONE\n\n\nSee note for E081\n\n\n\n\n\n\nF032 CASCADE drop behavior\n\n\nTODO\n\n\nWould be in \nbeam-migrate\n\n\n\n\n\n\nF033 ALTER TABLE statement: DROP COLUMN clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF034 Extended REVOKE statement\n\n\nNONE\n\n\n\n\n\n\n\n\nF041 Basic joined table\n\n\n\n\n\n\n\n\n\n\nF041-01 Inner join\n\n\nFULL\n\n\nUse the \nmonadic join interface\n\n\n\n\n\n\nF041-02 INNER keyword\n\n\nN/A\n\n\nNo semantic difference\n\n\n\n\n\n\nF041-03 LEFT OUTER JOIN\n\n\nFULL\n\n\nUse \nleftJoin_\n\n\n\n\n\n\nF041-04 RIGHT OUTER JOIN\n\n\nPARTIAL\n\n\nSupported in backend syntaxes, not exposed. Can always be written using LEFT OUTER JOIN\n\n\n\n\n\n\nF041-05 Outer joins can be nested\n\n\nTODO\n\n\nDepends on \nouterJoin_\n\n\n\n\n\n\nF041-07 The inner table in outer join can be used in inner join\n\n\nTODO\n\n\nHow does this apply to us?\n\n\n\n\n\n\nF041-08 All comparison operators in JOIN\n\n\nFULL\n\n\nArbitrary \nQGenExpr\ns are supported.\n\n\n\n\n\n\nF051 Basic date and time\n\n\n\n\n\n\n\n\n\n\nF051-01 DATE data type\n\n\nFULL\n\n\nUse \nDay\n from \nData.Time\n and \nval_\n\n\n\n\n\n\nF051-02 TIME data type\n\n\nFULL\n\n\nUse \nTimeOfDay\n from \nData.Time\n and \nval_\n\n\n\n\n\n\nF051-03 TIMESTAMP datatype\n\n\nFULL\n\n\nUse \nLocalTime\n from \nData.Time\n and \nval_\n. Precision can be specified in \nbeam-migrate\n\n\n\n\n\n\nF051-04 Comparison predicate on time types\n\n\nFULL\n\n\nUse comparison operatiors (See E011-05)\n\n\n\n\n\n\nF051-05 Explicit cast between date-time types and string\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-06 CURRENT_DATE\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-07 LOCALTIME\n\n\nTODO\n\n\n\n\n\n\n\n\nF051-08 LOCALTIMESTAMP\n\n\nTODO\n\n\n\n\n\n\n\n\nF081 UNION and EXCEPT in views\n\n\nTODO\n\n\nDepends on view support\n\n\n\n\n\n\nF111 Isolation levels other than SERIALIZABLE\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF121 Basic diagnostics mangement\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF122 Extended diagnostics management\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF123 All diagnostics\n\n\nNONE\n\n\nUse backends\n\n\n\n\n\n\nF131 Grouped operations\n\n\nTODO\n\n\nDepends on grouped views\n\n\n\n\n\n\nF171 Multiple schemas per user\n\n\nN/A\n\n\nDepends on backend\n\n\n\n\n\n\nF191 Referential delete actions\n\n\nTODO\n\n\n\n\n\n\n\n\nF181 Multiple module support\n\n\nN/A\n\n\n\n\n\n\n\n\nF200 TRUNCATE TABLE statement\n\n\nTODO\n\n\nMay be added in the future\n\n\n\n\n\n\nF201 CAST function\n\n\nTODO\n\n\n\n\n\n\n\n\nF202 TRUNCATE TABLE: identity column restart option\n\n\nTODO\n\n\nDepends on F200\n\n\n\n\n\n\nF221 Explicit defaults\n\n\nFULL\n\n\nUse \nAuto Nothing\n when inserting\n\n\n\n\n\n\nF222 INSERT statement: DEFAULT VALUES clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF251 Domain support\n\n\nTODO\n\n\nUse \nDomainType\n\n\n\n\n\n\nF261 CASE expression\n\n\n\n\n\n\n\n\n\n\nF261-01 Simple CASE\n\n\nTODO\n\n\nUse searched case (see F261-02)\n\n\n\n\n\n\nF261-02 Searched CASE\n\n\nFULL\n\n\nUse \nif_\n, \nthen_\n, and \nelse_\n\n\n\n\n\n\nF261-03 NULLIF\n\n\nFULL\n\n\nUse \nnullIf_\n\n\n\n\n\n\nF261-04 COALESCE\n\n\nFULL\n\n\nUse \ncoalesce_\n\n\n\n\n\n\nF262 Extended CASE expression\n\n\nPARTIAL\n\n\nBeam allows any value in a \nCASE\n expression\n\n\n\n\n\n\nF263 Comma-separater predicates in simple CASE expression\n\n\nTODO\n\n\n\n\n\n\n\n\nF271 Compound character literals\n\n\nPARTIAL\n\n\nBackends may do this automatically\n\n\n\n\n\n\nF281 LIKE enhancements\n\n\nPARTIAL\n\n\nSupported in backends that support this\n\n\n\n\n\n\nF291 UNIQUE predicate\n\n\nFULL\n\n\nUse \nunique_\n\n\n\n\n\n\nF301 CORRESPONDING in query expressions\n\n\nTODO\n\n\n\n\n\n\n\n\nF302 INTERSECT table operator\n\n\nFULL\n\n\nUse \nintersect_\n\n\n\n\n\n\nF302-01 INTERSECT DISTINCT table operator\n\n\nFULL\n\n\nUse \nintersect_\n\n\n\n\n\n\nF302-02 INTERSET ALL table operator\n\n\nFULL\n\n\nUse \nintersectAll_\n\n\n\n\n\n\nF304 EXCEPT ALL table operator\n\n\nFULL\n\n\nUse \nexceptAll_\n\n\n\n\n\n\nF311 Schema definition statement\n\n\nTODO\n\n\nWould be in \nbeam-migrate\n\n\n\n\n\n\nF312 MERGE statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF313 Enhanced MERGE statement\n\n\nTODO\n\n\n\n\n\n\n\n\nF314 MERGE statement with DELETE branch\n\n\nTODO\n\n\n\n\n\n\n\n\nF321 User authorization\n\n\nN/A\n\n\n\n\n\n\n\n\nF361 Subprogram support\n\n\nN/A\n\n\n\n\n\n\n\n\nF381 Extended schema manipulation\n\n\nTODO\n\n\n\n\n\n\n\n\nF382 Alter column data type\n\n\nTODO\n\n\n\n\n\n\n\n\nF384 Drop identity property clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF385 Drop column generation expression clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF386 Set identity column generation clause\n\n\nTODO\n\n\n\n\n\n\n\n\nF391 Long identifiers\n\n\nPARTIAL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF392 Unicode escapes in identifiers\n\n\nTODO\n\n\nUnsure how this applies\n\n\n\n\n\n\nF393 Unicode escapes in literals\n\n\nTODO\n\n\nUnsure how this applies\n\n\n\n\n\n\nF394 Optional normal form specification\n\n\nN/A\n\n\n\n\n\n\n\n\nF401 Extended joined table\n\n\nPARTIAL\n\n\nFULL OUTER JOIN\n support planned with \nouterJoin_\n. \nCROSS JOIN\n is the same as \nINNER JOIN\n, and \nNATURAL JOIN\n has no meaning in beam.\n\n\n\n\n\n\nF402 Named column joins for LOBs, arrays, and multisets\n\n\nPARTIAL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF403 Partitioned join tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF411 Time zone specification\n\n\nTODO\n\n\n\n\n\n\n\n\nF421 National character\n\n\nFULL\n\n\nSupported in \nbeam-migrate\n as a data type for \nText\n\n\n\n\n\n\nF431 Read-only scrollable cursors\n\n\nN/A\n\n\nUse the underlying backend\n\n\n\n\n\n\nF441 Extended set function support\n\n\nTODO\n\n\n\n\n\n\n\n\nF442 Mixed column references in set functions\n\n\nTODO\n\n\nUnsure how this would work with beam\n\n\n\n\n\n\nF451 Character set definition\n\n\nTODO\n\n\nLikely would go in \nbeam-migrate\n\n\n\n\n\n\nF461 Named character sets\n\n\nTODO\n\n\nSee F451\n\n\n\n\n\n\nF491 Constraint management\n\n\nTODO\n\n\n\n\n\n\n\n\nF492 Optional table constraint enforcement\n\n\nTODO\n\n\n\n\n\n\n\n\nF521 Assertions\n\n\nTODO\n\n\n\n\n\n\n\n\nF531 Temporary tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF481 Expanded NULL predicate\n\n\nFULL\n\n\nSupported in backends that support it\n\n\n\n\n\n\nF555 Enhanced seconds precision\n\n\nTODO\n\n\n\n\n\n\n\n\nF561 Full value expressions\n\n\nTODO\n\n\n\n\n\n\n\n\nF571 Truth value tests\n\n\nTODO\n\n\n\n\n\n\n\n\nF591 Derived tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF611 Indicator data types\n\n\nTODO\n\n\n\n\n\n\n\n\nF641 Row and table constructors\n\n\nPARTIAL\n\n\nUse \nrow_\n (TODO)\n\n\n\n\n\n\nF651 Catalog name qualifiers\n\n\nTODO\n\n\n\n\n\n\n\n\nF661 Simple tables\n\n\nTODO\n\n\n\n\n\n\n\n\nF671 Subqueries in CHECK constraints\n\n\nTODO\n\n\nPlanned with E141-06\n\n\n\n\n\n\nF672 Retrospective CHECK constraints\n\n\nTODO\n\n\nWould require temporal DB support\n\n\n\n\n\n\nF690 Collation support\n\n\nPARTIAL\n\n\nbeam-migrate\n supports some collation features\n\n\n\n\n\n\nF692 Enhanced collation support\n\n\nTODO\n\n\n\n\n\n\n\n\nF693 SQL-session and client module collations\n\n\nTODO\n\n\n\n\n\n\n\n\nF695 Translation support\n\n\nTODO\n\n\n\n\n\n\n\n\nF701 Referential update actions\n\n\nTODO\n\n\n\n\n\n\n\n\nF711 ALTER domain\n\n\nTODO\n\n\n\n\n\n\n\n\nF721 Deferrable constraints\n\n\nPARTIAL\n\n\nThe syntax exists in \nbeam-migrate\n\n\n\n\n\n\nF731 INSERT column privileges\n\n\nN/A\n\n\n\n\n\n\n\n\nF741 Referential MATCH type\n\n\nPARTIAL\n\n\nExists in the syntax in \nbeam-migrate\n, not exposed yet (TODO)\n\n\n\n\n\n\nF751 View CHECK enhancements\n\n\nTODO\n\n\n\n\n\n\n\n\nF761 Session management\n\n\nTODO\n\n\n\n\n\n\n\n\nF762 CURRENT_CATALOG\n\n\nTODO\n\n\n\n\n\n\n\n\nF763 CURRENT_SCHEMA\n\n\nTODO\n\n\n\n\n\n\n\n\nF812 Basic flagging\n\n\nN/A\n\n\n\n\n\n\n\n\nF841 LIKE_REGEX predicate\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF842 OCCURENCES_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF843 POSITION_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF844 SUBSTRING_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF845 TRANSLATE_REGEX function\n\n\nTODO\n\n\nEasy\n\n\n\n\n\n\nF846 Octet support in regular expression operators\n\n\nTODO\n\n\n\n\n\n\n\n\nF847 Nonconstant regular expression\n\n\nTODO\n\n\nEasy once regex support is added\n\n\n\n\n\n\nF850 Top-level \n in \n\n\nFULL\n\n\nUse \norderBy_\n as usual. Beam will do the right thing behind the scenes.\n\n\n\n\n\n\nF851 \n in subqueries\n\n\nFULL\n\n\nWorks in backends that support it\n\n\n\n\n\n\nF852 Top-level \n in views\n\n\nTODO\n\n\n\n\n\n\n\n\nF855 Nested \n in \n\n\nUNKNOWN\n\n\n\n\n\n\n\n\nF856 Nested \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF857 Top-level \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF858 \n in subqueries\n\n\nTODO\n\n\n\n\n\n\n\n\nF859 Top-level \n in subqueries\n\n\nTODO\n\n\n\n\n\n\n\n\n*\nF860 dynamic \n in \n\n\nTODO\n\n\n\n\n\n\n\n\n*\nF861 Top-level \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF862 \n in subqueries\n\n\nTODO\n\n\n\n\n\n\n\n\nF863 Nested \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF864 TOp-level \n in views\n\n\nTODO\n\n\n\n\n\n\n\n\nF865 dynamic \n in \n\n\nTODO\n\n\n\n\n\n\n\n\nF866 FETCH FIRST clause: PERCENT option\n\n\nTODO\n\n\n\n\n\n\n\n\nF867 FETCH FIRST clause: WITH TIES option\n\n\nTODO\n\n\n\n\n\n\n\n\nR010 Row pattern recognition: FROM clause\n\n\nTODO\n\n\n\n\n\n\n\n\nR020 Row pattern recognition: WINDOW clause\n\n\nTODO\n\n\n\n\n\n\n\n\nR030 Row pattern recognition: full aggregate support\n\n\nTODO\n\n\n\n\n\n\n\n\nS011 Distinct data types\n\n\nTODO\n\n\n\n\n\n\n\n\nS023 Basic structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS024 Enhanced structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS025 Final structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS026 Self-referencing structured types\n\n\nTODO\n\n\n\n\n\n\n\n\nS027 Create method by specific method name\n\n\nTODO\n\n\n\n\n\n\n\n\nS028 Permutable UDT options list\n\n\nTODO\n\n\n\n\n\n\n\n\nS041 Basic reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS043 Enhanced reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS051 Create table of type\n\n\nTODO\n\n\n\n\n\n\n\n\nS071 SQL paths in function and type name resolution\n\n\nN/A\n\n\nBeam qualifies everything anyway\n\n\n\n\n\n\nS081 Subtables\n\n\nPARTIAL\n\n\nYou can use them right now, but there's no support for their creation or management in \nbeam-migrate\n\n\n\n\n\n\nS091 Basic array support\n\n\nPARTIAL\n\n\nSupported via custom syntax in some backends (\nbeam-postgres\n for example)\n\n\n\n\n\n\nS092 Arrays of user-defined types\n\n\nTODO\n\n\nDepends on user-defined types\n\n\n\n\n\n\nS094 Arrays of reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS095 Array constructors by query\n\n\nTODO\n\n\n\n\n\n\n\n\nS096 Optional array bounds\n\n\nPARTIAL\n\n\nSupported in \nbeam-postgres\n\n\n\n\n\n\nS097 Array element assignment\n\n\nTODO\n\n\nNot yet, but should be easy enough in \nbeam-postgres\n\n\n\n\n\n\nS098 ARRAY_AGG\n\n\nTODO\n\n\nEasily added to \nbeam-postgres\n (Easy)\n\n\n\n\n\n\nS111 ONLY in query expressions\n\n\nTODO\n\n\n\n\n\n\n\n\nS151 Type predicate\n\n\nTODO\n\n\n\n\n\n\n\n\nS161 Subtype treatment\n\n\nTODO\n\n\n\n\n\n\n\n\nS162 Subtype treatment for references\n\n\nTODO\n\n\n\n\n\n\n\n\nS201 SQL-invoked routines on arrays\n\n\nTODO\n\n\nWould be subsumed by sql-routines (T-321)\n\n\n\n\n\n\nS202 SQL-invoked routines on multisets\n\n\nTODO\n\n\nWould be subsumed by sql-routines (T-321)\n\n\n\n\n\n\nS211 User-defined cast functions\n\n\nTODO\n\n\n\n\n\n\n\n\nS231 Structured type locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS232 Array locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS233 Multiset locators\n\n\nTODO\n\n\n\n\n\n\n\n\nS241 Transform functions\n\n\nTODO\n\n\n\n\n\n\n\n\nS242 Alter transform statement\n\n\nTODO\n\n\n\n\n\n\n\n\nS251 User-defined orderings\n\n\nTODO\n\n\n\n\n\n\n\n\nS261 Specific type method\n\n\nTODO\n\n\n\n\n\n\n\n\nS271 Basic multiset support\n\n\nTODO\n\n\n\n\n\n\n\n\nS272 Multisets of user-defined types\n\n\nTODO\n\n\n\n\n\n\n\n\nS274 Multisets reference types\n\n\nTODO\n\n\n\n\n\n\n\n\nS275 Advanced multiset support\n\n\nTODO\n\n\n\n\n\n\n\n\nS281 Nested collection types\n\n\nTODO\n\n\n\n\n\n\n\n\nS291 Unique constraint on entire row\n\n\nTODO\n\n\n\n\n\n\n\n\nS301 Enhanced UNNEST\n\n\nTODO\n\n\n\n\n\n\n\n\nS401 Distinct types based on array types\n\n\nTODO\n\n\n\n\n\n\n\n\nS402 Distinct types based on distinct types\n\n\nTODO\n\n\n\n\n\n\n\n\nS403 ARRAY_MAX_CARDINALITY\n\n\nTODO\n\n\n\n\n\n\n\n\nS404 TRIM_ARRAY\n\n\nTODO\n\n\n\n\n\n\n\n\nT021 BINARY and VARBINARY data types\n\n\nTODO\n\n\n\n\n\n\n\n\nT022 Advanced support for BINARY and VARBINARY data types\n\n\nTODO\n\n\n\n\n\n\n\n\nT023 Compound binary literals\n\n\nTODO\n\n\n\n\n\n\n\n\nT024 Spaces in binary literals\n\n\nTODO\n\n\n\n\n\n\n\n\nT031 Boolean data type\n\n\nTODO\n\n\n\n\n\n\n\n\nT041 Basic LOB data type support\n\n\nTODO\n\n\n\n\n\n\n\n\nT042 Extended LOB data type support\n\n\nTODO\n\n\n\n\n\n\n\n\nT043 Multiplier T\n\n\nTODO\n\n\n\n\n\n\n\n\nT044 Multiplier P\n\n\nTODO\n\n\n\n\n\n\n\n\nT051 Row types\n\n\nPARTIAL\n\n\n\n\n\n\n\n\nT061 UCS support\n\n\nTODO\n\n\n\n\n\n\n\n\nT071 BIGINT data type\n\n\nTODO\n\n\n\n\n\n\n\n\nT101 Enhanced nullability detection\n\n\nTODO\n\n\n\n\n\n\n\n\nT111 Updatable joins, unions,  and columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT121 WITH (excluding recursive) in query expression\n\n\nTODO\n\n\n\n\n\n\n\n\nT122 WITH (excluding recursive) in subquery\n\n\nTODO\n\n\n\n\n\n\n\n\nT131 Recursive query\n\n\nTODO\n\n\n\n\n\n\n\n\nT132 Recursive query in subquery\n\n\nTODO\n\n\n\n\n\n\n\n\nT141 SIMILAR predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nT151 DISTINCT predicate\n\n\nFULL\n\n\n\n\n\n\n\n\nT152 DISTINCT predicate with negation\n\n\nTODO\n\n\n\n\n\n\n\n\nT171 LIKE clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT172 AS subquery clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT173 Extended LIKE clause in table definition\n\n\nTODO\n\n\n\n\n\n\n\n\nT174 Identity columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT175 Generated columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT176 Sequence generator support\n\n\nTODO\n\n\n\n\n\n\n\n\nT177 Sequence generator support: simple restart option\n\n\nTODO\n\n\n\n\n\n\n\n\nT178 Identity columns: simple restart option\n\n\nTODO\n\n\n\n\n\n\n\n\nT180 System-versioned tables\n\n\nTODO\n\n\n\n\n\n\n\n\nT181 Application-time period tables\n\n\nTODO\n\n\n\n\n\n\n\n\nT191 Referential action RESTART\n\n\nTODO\n\n\n\n\n\n\n\n\nT201 Comparable data types for referential constraints\n\n\nTODO\n\n\n\n\n\n\n\n\nT211 Basic trigger capability\n\n\nTODO\n\n\n\n\n\n\n\n\nT212 Enhanced trigger capability\n\n\nTODO\n\n\n\n\n\n\n\n\nT213 INSTEAD OF triggers\n\n\nTODO\n\n\n\n\n\n\n\n\nT231 Sensitive cursors\n\n\nTODO\n\n\n\n\n\n\n\n\nT241 START TRANSACTION statement\n\n\nWONTFIX\n\n\nUse the backend library\n\n\n\n\n\n\nT251 SET TRANSACTION option: LOCAL option\n\n\nWONTFIX\n\n\nUse the backend library\n\n\n\n\n\n\nT261 Chained transactions\n\n\nN/A\n\n\n\n\n\n\n\n\nT271 Savepoints\n\n\nN/A\n\n\n\n\n\n\n\n\nT272 Enhanced savepoint management\n\n\nN/A\n\n\n\n\n\n\n\n\nT281 SELECT privilege with column granularity\n\n\nN/A\n\n\n\n\n\n\n\n\nT285 Enhanced derived column names\n\n\nN/A\n\n\n\n\n\n\n\n\nT301 Functional dependencies\n\n\nTODO\n\n\n\n\n\n\n\n\nT312 OVERLAY function\n\n\nTODO\n\n\n\n\n\n\n\n\nT321 Basic SQL-invoked routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT323 Explicit security for external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT324 Explicit security for SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT325 Qualified SQL parameter references\n\n\nN/A\n\n\nBeam will likely use the qualified ones by default. Likely not exposed to user\n\n\n\n\n\n\nT326 Table functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT331 Basic roles\n\n\nN/A\n\n\n\n\n\n\n\n\nT332 Extended roles\n\n\nN/A\n\n\n\n\n\n\n\n\nT341 Overleading of SQL-invoked functions and procodures\n\n\nWONTFIX\n\n\nHaskell doesn't allow overloading, and this seems complicated and unnecessary\n\n\n\n\n\n\nT351 Bracketed comments\n\n\nN/A\n\n\n\n\n\n\n\n\nT431 Extended grouping capabalities\n\n\nTODO\n\n\n\n\n\n\n\n\nT432 Nested and concatenated GROUPING SETs\n\n\nTODO\n\n\n\n\n\n\n\n\nT433 Multiargument GROUPING function\n\n\nTODO\n\n\n\n\n\n\n\n\nT434 GROUP BY DISTINCT\n\n\nTODO\n\n\n\n\n\n\n\n\nT441 ABS and MOD functions\n\n\nFULL\n\n\n\n\n\n\n\n\nT461 Symmetric BETWEEN predicate\n\n\nFULL\n\n\nBeam doesn't check this\n\n\n\n\n\n\nT471 Result sets return value\n\n\nTODO\n\n\n\n\n\n\n\n\nT472 DESCRIBE CURSOR\n\n\nN/A\n\n\nUse the backend library\n\n\n\n\n\n\nT491 LATERAL derived table\n\n\nTODO\n\n\n\n\n\n\n\n\nT495 Combined data change and retrieval\n\n\nTODO\n\n\n\n\n\n\n\n\nT501 Enhanced EXISTS predicate\n\n\nTODO\n\n\n\n\n\n\n\n\nT502 Period predicates\n\n\nTODO\n\n\n\n\n\n\n\n\nT511 Transaction counts\n\n\nTODO\n\n\n\n\n\n\n\n\nT521 Nested arguments in CALL statement\n\n\nTODO\n\n\n\n\n\n\n\n\nT522 Default values for IN parameters of SQL-invoked procs\n\n\nTODO\n\n\n\n\n\n\n\n\nT551 Optional key words for DEFAULT syntax\n\n\nTODO\n\n\n\n\n\n\n\n\nT561 Holdable locators\n\n\nTODO\n\n\n\n\n\n\n\n\nT571 Array-returning SQL-invoked functions\n\n\nTODO\n\n\nWill be supported once SQL-invoked functions are\n\n\n\n\n\n\nT572 Multiset-returning SQL-invoked functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT581 Regular expression substring function\n\n\nTODO\n\n\n\n\n\n\n\n\nT591 UNIQUE constraints of possible NULL columns\n\n\nTODO\n\n\n\n\n\n\n\n\nT601 Local cursor references\n\n\nN/A\n\n\n\n\n\n\n\n\nT611 Elementary OLAP operations\n\n\nPARTIAL\n\n\nSee \nwithWindow_\n, \nwindow functions\n. Need \nnullsFirst_\n and \nnullsLast_\n\n\n\n\n\n\nT612 Advanced OLAP operations\n\n\nPARTIAL\n\n\nNeed \npercentRank_\n, \ncumeDist_\n, no exclusions yet\n\n\n\n\n\n\nT613 Sampling\n\n\nTODO\n\n\n\n\n\n\n\n\nT614 NTILE function\n\n\nTODO\n\n\n\n\n\n\n\n\nT615 LEAD and LAG function\n\n\nTODO\n\n\n\n\n\n\n\n\nT616 Null treatment for LEAD and LAG functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT617 FIRST_VALUE and LAST_VALUE function\n\n\nTODO\n\n\n\n\n\n\n\n\nT618 NTH_VALUE function\n\n\nTODO\n\n\n\n\n\n\n\n\nT619 Nested window function\n\n\nTODO\n\n\n\n\n\n\n\n\nT620 WINDOW clause: GROUPS option\n\n\nTODO\n\n\n\n\n\n\n\n\nT621 Enhanced numeric functions\n\n\nTODO\n\n\n\n\n\n\n\n\nT641 Multiple column assignment\n\n\nTODO\n\n\n\n\n\n\n\n\nT651 SQL-schema statements in SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT652 SQL-dynamic statements in SQL routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT653 SQL-schema statements in external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT654 SQL-dynamic statements in external routines\n\n\nTODO\n\n\n\n\n\n\n\n\nT655 Cyclically dependent routines\n\n\nTODO", 
            "title": "Compatibility Matrix"
        }, 
        {
            "location": "/about/license/", 
            "text": "The MIT License (MIT)\n\n\nCopyright \u00a9 2017 Travis Athougies\nand\n\nthe Beam authors\n\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "License"
        }, 
        {
            "location": "/about/license/#the-mit-license-mit", 
            "text": "Copyright \u00a9 2017 Travis Athougies\nand the Beam authors  Permission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:  The above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "The MIT License (MIT)"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "Beam Release Notes\n\n\n0.5.0.0\n\n\n\n\nMove to using finally tagless style for SQL generation\n\n\nSplit out backends from \nbeam-core\n\n\nAllow non-table entities to be stored in databases\n\n\nBasic migrations support", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#beam-release-notes", 
            "text": "", 
            "title": "Beam Release Notes"
        }, 
        {
            "location": "/about/release-notes/#0500", 
            "text": "Move to using finally tagless style for SQL generation  Split out backends from  beam-core  Allow non-table entities to be stored in databases  Basic migrations support", 
            "title": "0.5.0.0"
        }
    ]
}