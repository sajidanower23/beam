{
    "docs": [
        {
            "location": "/", 
            "text": "Beam is a highly-general library for accessing any kind of database with\nHaskell. Currently, it supports two SQL backends, Postgres and SQLite. Work is\nunderway for a MySQL backend. For information on creating additional SQL\nbackends, see the \nmanual section\n for more.\n\n\nBeam features\n\n\n\n\nEasy schema generation\n from existing databases\n\n\nA basic migration infrastructure\n for working with multiple versions of your\n  database schema.\n\n\nSupport for most SQL92, SQL99, and SQL2003 features\n across backends that\n  support them, including aggregations, subqueries, and window functions.\n\n\nA straightforward Haskell-friendly query syntax\n. You can use Beam's \nQ\n\n  monad much like you would interact with the \n[]\n monad.\n\n\nNo Template Haskell\n Beam uses the GHC Haskell type system and nothing else.\n  The types have been designed to be easily-inferrable by the compiler, and\n  appropriate functions to refine types have been provided for the where the\n  compiler may need more help.\n\n\n\n\nHow to install\n\n\nBeam is available via both \nHackage\n\nand \nStack\n. For most Haskell\ninstallations, one of the two commands should work.\n\n\ncabal install beam-core beam-migrate \nbackend\n\n\n\n\n\nor\n\n\nstack install beam-core beam-migrate \nbackend\n\n\n\n\n\nYou will also need to install an appropriate backend. Available backends are\n\n\n\n\n\n\nbeam-postgres\n -- A feature-complete backend for the Postgres RDBMS.\n  See \nthe beam-postgres documentation\n\n  for more information.\n\n\n\n\n\n\nbeam-sqlite\n -- An almost feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to \nthe beam-sqlite documentation\n for\n  more information on compatibility.\n\n\n\n\n\n\nQuick Start Guide\n\n\nIf you already have a database schema, you can use the \nbeam-migrate\n command to\nautomatically generate appropriate Beam data definitions.\n\n\nbeam-migrate --backend \nbackend-module\n \nbackend-options\n new \noutput-module-name\n\n\n\n\n\nFor example, to generate a schema for the Postgres database \nemployees\n at\n\nlocalhost:5000\n with the user \nbeam\n, run the following command.\n\n\nbeam-migrate --backend Database.Beam.Postgres.Migrate --pgconnect postgres://beam@localhost:5000/employees new BeamTutorial.Schema\n\n\n\n\nThis will generate a\n\n\nHow to Contribute\n\n\nWe always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the \nbeam-users\n Google\nGroup. The following is a quick step-by-step guide of contributing a new feature:\n\n\n\n\nFork the github repository at \nhttps://github.com/tathougies/beam\n\n   and clone the fork to a local directory.\n\n\nWork on your feature on your own branch, or pick\n   an \nissue\n.\n\n\nWhen you feel ready to contribute the feature back to \nbeam-core\n, send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.\n\n\nRespond to community comments and rework your patch.\n\n\nWhen the maintainer feels comfortable with your patch, he will commit it to\n   the \nmaster\n branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.\n\n\n\n\nQuestions, Feedback, Discussion\n\n\n\n\nFor frequently asked questions, see the \nFAQ\n.\n\n\nFor general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list\n\n\nFor bugs or feature requests,\n  please \nopen an issue\n\n\n\n\nWhy Beam?\n\n\nBeam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the entire breadth of the SQL92, SQL99, SQL2003, SQL2006, SQL2008,\nSQL2011, and SQL2016 specifications, as well as the entire breadth of features\nof each of its backends. See\nthe \ncompatibility matrix\n. You will rarely be forced to\nwrite a SQL query 'by hand' when using Beam.\n\n\nAdditionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of the underlying\n\ndb\n-simple\n packages. Beam provides only minimum support for querying data\nacross multiple databases. It is assumed that you have chosen you RDBMS with\nmuch care, and we want to support you in that. Beam's main purpose is to marshal\ndata back and forth, to serve as the source of truth for the DB schema, and to\ngenerate properly formed SQL from Haskell expressions.", 
            "title": "Home"
        }, 
        {
            "location": "/#how-to-install", 
            "text": "Beam is available via both  Hackage \nand  Stack . For most Haskell\ninstallations, one of the two commands should work.  cabal install beam-core beam-migrate  backend   or  stack install beam-core beam-migrate  backend   You will also need to install an appropriate backend. Available backends are    beam-postgres  -- A feature-complete backend for the Postgres RDBMS.\n  See  the beam-postgres documentation \n  for more information.    beam-sqlite  -- An almost feature-complete backend for the Sqlite library.\n  Note that SQLite does not support all SQL92 features, so some of the examples\n  may not work. Refer\n  to  the beam-sqlite documentation  for\n  more information on compatibility.", 
            "title": "How to install"
        }, 
        {
            "location": "/#quick-start-guide", 
            "text": "If you already have a database schema, you can use the  beam-migrate  command to\nautomatically generate appropriate Beam data definitions.  beam-migrate --backend  backend-module   backend-options  new  output-module-name   For example, to generate a schema for the Postgres database  employees  at localhost:5000  with the user  beam , run the following command.  beam-migrate --backend Database.Beam.Postgres.Migrate --pgconnect postgres://beam@localhost:5000/employees new BeamTutorial.Schema  This will generate a", 
            "title": "Quick Start Guide"
        }, 
        {
            "location": "/#how-to-contribute", 
            "text": "We always welcome contributions, especially to cover more database features or\nto add support for a new backend. Help is available on the  beam-users  Google\nGroup. The following is a quick step-by-step guide of contributing a new feature:   Fork the github repository at  https://github.com/tathougies/beam \n   and clone the fork to a local directory.  Work on your feature on your own branch, or pick\n   an  issue .  When you feel ready to contribute the feature back to  beam-core , send a\n   Pull Request on Github, with an explanation of what your patch does and\n   whether it breaks the API.  Respond to community comments and rework your patch.  When the maintainer feels comfortable with your patch, he will commit it to\n   the  master  branch and it will be included in the next minor version.\n   API-breaking changes will not be included until the next major version.", 
            "title": "How to Contribute"
        }, 
        {
            "location": "/#questions-feedback-discussion", 
            "text": "For frequently asked questions, see the  FAQ .  For general questions, feedback on patches, support, or other concerns, please\n  write to the mailing list  For bugs or feature requests,\n  please  open an issue", 
            "title": "Questions, Feedback, Discussion"
        }, 
        {
            "location": "/#why-beam", 
            "text": "Beam is the most feature-complete, turnkey Haskell database solution out there.\nIt supports the entire breadth of the SQL92, SQL99, SQL2003, SQL2006, SQL2008,\nSQL2011, and SQL2016 specifications, as well as the entire breadth of features\nof each of its backends. See\nthe  compatibility matrix . You will rarely be forced to\nwrite a SQL query 'by hand' when using Beam.  Additionally, Beam plays nice with the rest of the Haskell ecosystem, the\nstandard Beam backends are all implemented in terms of the underlying db -simple  packages. Beam provides only minimum support for querying data\nacross multiple databases. It is assumed that you have chosen you RDBMS with\nmuch care, and we want to support you in that. Beam's main purpose is to marshal\ndata back and forth, to serve as the source of truth for the DB schema, and to\ngenerate properly formed SQL from Haskell expressions.", 
            "title": "Why Beam?"
        }, 
        {
            "location": "/about/faq/", 
            "text": "How does \nbeam\n compare with \nx\n?\n\n\nHelp! The type checker keeps complaining about \nSyntax\n types\n\n\nSuppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.\n\n\nlistEmployees :: (IsSql92Syntax cmd, MonadBeam cmd be hdl m) =\n m [Employee]\nlistEmployees = runSelectReturningList $ select (all_ (employees employeeDb))\n\n\n\n\nYou may get an error message like the following\n\n\nMyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of 'select'\n\n\n\n\nBeam uses a \nfinally-tagless\n\nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in \nWHERE\n and \nHAVING\n\nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking\n\nUndecidableSuperclasses\n extension in GHC).\n\n\nNevertheless, we can avoid all this hullabaloo by using the \nSql92SanityCheck\n\nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.\n\n\nlistEmployees :: ( IsSql92Syntax cmd, Sql92SanityCheck cmd\n                 , MonadBeam cmd be hdl m)\n              =\n m [Employee]\nlistEmployees = runSelectReturningList $ select (all_ (employees employeeDb))", 
            "title": "Frequently Asked Questions"
        }, 
        {
            "location": "/about/faq/#how-does-beam-compare-with-x", 
            "text": "", 
            "title": "How does beam compare with &lt;x&gt;?"
        }, 
        {
            "location": "/about/faq/#help-the-type-checker-keeps-complaining-about-syntax-types", 
            "text": "Suppose you had the following code to run a query over an arbitrary backend that\nsupported the SQL92 syntax.  listEmployees :: (IsSql92Syntax cmd, MonadBeam cmd be hdl m) =  m [Employee]\nlistEmployees = runSelectReturningList $ select (all_ (employees employeeDb))  You may get an error message like the following  MyQueries.hs:1:1: error:\n    * Could not deduce: Sql92ProjectionExpressionSyntax\n                          (Sql92SelectTableProjectionSyntax\n                             (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd)))\n                        ~\n                        Sql92SelectTableExpressionSyntax\n                          (Sql92SelectSelectTableSyntax (Sql92SelectSyntax cmd))\n        arising from a use of 'select'  Beam uses a  finally-tagless \nencoding for syntaxes. This means we never deal with concrete syntax types\ninternally, just types that fulfill certain constraints (in this case, being a\nvalid description of a SQL92 syntax). This works really nicely for\nextensibility, but makes the types slightly confusing. Here, the type checker is\ncomplaining that it cannot prove that the type of expressions used in\nprojections is the same as the type of expressions used in  WHERE  and  HAVING \nclauses. Of course, any sane SQL92 syntax would indeed meet this criteria, but\nthis criteria is difficult to enforce at the type class level (it leads to\ncycles in superclasses, which requires the scary-looking UndecidableSuperclasses  extension in GHC).  Nevertheless, we can avoid all this hullabaloo by using the  Sql92SanityCheck \nconstraint synonym. This takes a command syntax and asserts all the type\nequalities that a sane SQL92 syntax would support. Thus the code above becomes.  listEmployees :: ( IsSql92Syntax cmd, Sql92SanityCheck cmd\n                 , MonadBeam cmd be hdl m)\n              =  m [Employee]\nlistEmployees = runSelectReturningList $ select (all_ (employees employeeDb))", 
            "title": "Help! The type checker keeps complaining about Syntax types"
        }, 
        {
            "location": "/user-guide/getting-started/", 
            "text": "Beam is made up of several Haskell packages. The main package is \nbeam-core\n,\nwhich provides core type definitions and common combinators for SQL. It also\nprovides a basic interface for using backends in a generic way. Beam also comes\nwith some default backends. Backends for other RDBMSs are available on Hackage\nand GitHub.\n\n\nGetting Started", 
            "title": "Getting Started"
        }, 
        {
            "location": "/user-guide/getting-started/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/user-guide/models/", 
            "text": "Beam allows you to define models for your data that can be used across multiple\nbackends. Beam models are standard Haskell data structures, but with some extra\nfeatures that allow Beam to introspect them at run-time.\n\n\nA Simple Model\n\n\nLet's define a simple model to represent a person. Open up a file named\n\nSchema.hs\n and add the following.\n\n\n{-# LANGUAGE GADTs #-}\n{-# LANGUAGE DeriveGeneric #-}\nmodule Schema where\n\nimport Database.Beam\nimport Database.Beam.SQLite\nimport Database.SQLite.Simple\n\nimport Data.Text (Text)\n\ndata PersonT f\n    = Person\n    { personFirstName :: Columnar f Text\n    , personLastName  :: Columnar f Text\n    , personAge       :: Columnar f Int\n    } deriving Generic\ninstance Beamable PersonT\n\n\n\n\nBeam also requires that your tables have a primary key that can be used to\nuniquely identify each tuple in your relation. We tell beam about the primary\nkey by implementing the \nTable\n type class for your table.\n\n\ninstance Table PersonT where\n  data PrimaryKey PersonT f\n      = PersonKey\n      { personKeyFirstName :: Columnar f Text\n      , personKeyLastName  :: Columnar f Text\n      } deriving Generic\n  primaryKey person = PersonKey (personFirstName person) (personLastName person)\n\n\n\n\n\n\nNote\n\n\nUsing the first and last name as a primary key is a bad idea, we use it here\nto illustrate using multiple fields as the primary key.\n\n\n\n\n\n\nTip\n\n\nMany people find it useful to use the \nApplicative\n instance for \n(-\n) a\n to\nwrite \nprimaryKey\n. For example, we could have written the above \nprimaryKey\nperson = PersonKey (personFirstName person) (personLastName person)\n as\n\nprimaryKey = PersonKey \n$\n personFirstName \n*\n personLastName\n.\n\n\n\n\nFor ease-of-use purposes we define some type synonyms for \nPersonT\n and\n\nPrimaryKey PersonT\n and some convenient instances. These are not strictly\nrequired but make working with these tables much easier.\n\n\ntype Person = PersonT Identity\ntype PersonKey = PrimaryKey PersonT Identity\nderiving instance Show Person; deriving instance Eq Person\nderiving instance Show PersonKey; deriving instance Eq PersonKey\n\n\n\n\nDue to the magic of the \nColumnar\n type family, the \nPerson\n type can\nbe thought of as having the following definition.\n\n\ndata Person\n    = Person\n    { personFirstName :: Text\n    , personLastName  :: Text\n    , personAge       :: Int\n    } deriving (Show, Eq)\n\n\n\n\nThis allows us to use your type definitions for Beam as regular\nHaskell data structures without wrapping/unwrapping.\n\n\n\n\nTip\n\n\nTyping \nColumnar\n may become tiresome. \nDatabase.Beam\n also exports \nC\n as a\ntype alias for \nColumnar\n, which may make writing models easier. Since \nC\n\nmay cause name clashes, all examples are given using \nColumnar\n.\n\n\n\n\nForeign references\n\n\nForeign references are also easily supported in models by simply\nembedding the \nPrimaryKey\n of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.\n\n\ndata PostT f\n    = Post\n    { postId       :: Columnar f (Auto Int)\n    , postPostedAt :: Columnar f LocalTime\n    , postContent  :: Columnar f Text\n    , postPoster   :: PrimaryKey PersonT f\n    } deriving Generic\ninstance Beamable PostT\n\ninstance Table PostT where\n  data PrimaryKey PostT f\n      = PostId (Columnar f (Auto Int)) deriving Generic\n  primaryKey = PostId . postId\n\ntype Post = PostT Identity\ntype PostId = PrimaryKey PostT Identity\nderiving instance Show Post; deriving instance Eq Post\nderiving instance Show PostId; deriving instance Eq PostId\n\n\n\n\nThe \nAuto\n type constructor is provided by \nbeam-core\n for fields that\nare automatically assigned by the database. Internally, \nAuto x\n is\nsimply a newtype over \nMaybe x\n. The guarantee is that all values of\ntype \nAuto x\n returned by beam in the result set will have a value,\nalthough this guarantee is not enforced at the type level (yet).\n\n\nEmbedding\n\n\nSometimes, we want to declare multiple models with fields in\ncommon. Beam allows you to simple embed such fields in common types\nand embed those directly into models. For example,\n\n\n\n\n\nDefaults\n\n\nBased on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the\n\npersonFirstName\n field is accessible in SQL as \nfirst_name\n. This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.\n\n\nFor the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.\n\n\nWhen defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.\n\n\n\n\n\n\n\n\nHaskell field name\n\n\nBeam defaulted column name\n\n\n\n\n\n\n\n\n\n\npersonFirstName\n\n\nfirst_name\n\n\n\n\n\n\n_personLastName\n\n\nlast_name\n\n\n\n\n\n\nname\n\n\nname\n\n\n\n\n\n\nfirst_name\n\n\nfirst_name\n\n\n\n\n\n\n_first_name\n\n\nfirst_name\n\n\n\n\n\n\n___\n (three underscores)\n\n\n___\n (no changes)\n\n\n\n\n\n\n\n\nNote that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.\n\n\nAll of these defaults can be overriden using the modifications system,\ndescribed in the next section.\n\n\nWhat about tables without primary keys?\n\n\nTables without primary keys are considered bad style. However,\nsometimes you need to use beam with a schema that you have no control\nover. To declare a table without a primary key, simply instantiate the\n\nTable\n class without overriding the defaults.\n\n\nMore complicated relationships\n\n\nThis is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.\n\n\nPutting a Database Together\n\n\nBeam also requires you to give a type for your database. The database type\ncontains all the entities (tables or otherwise) that would be present in your\ndatabase. Our database only has one table right now, so it only contains one\nfield.\n\n\ndata ExampleDb f\n    = ExampleDb\n    { persons :: f (TableEntity PersonT)\n    } deriving Generic\ninstance Database ExampleDb\n\nexampleDb :: DatabaseSettings be ExampleDb\nexampleDb = autoDbSettings\n\n\n\n\nUsing your database\n\n\nLet's open up a SQLite database. Open up \nghci\n and import your module.\n\n\nPrelude\n :load Schema.hs\nPrelude Schema\n conn \n- open \nbeam-manual.db\n\n\n\n\n\nA quick note on backends\n\n\nBeam is backend-agnostic and doesn't provide any means to connect to a\ndatabase. Beam backend libraries usually use well-used Haskell\nlibraries to provide database connectivity. For example, the\n\nbeam-sqlite\n backend uses the \nsqlite-simple\n backend.\n\n\nBeam distinguishes each backend via type indexes. Each backend defines\na type that is used to enable backend-specific behavior. For example,\nthe \nbeam-sqlite\n backend ships with the \nSqlite\n type that is used to\ndistinguish sqlite specific constructs with generic or other\nbackend-specific ones.\n\n\nEach backend can have one or more 'syntaxes', which are particular\nways to query the database. While the \nbeam-core\n library ships with a\nstandard ANSI SQL builder, few real-world database implementations\nfully follow the standard. Most backends use their own custom syntax\ntype. Internally, beam uses a finally-tagless representation for\nsyntax trees that allow straightforward construction against any\nbackend.\n\n\nBeam offers backend-generic functions for the most common operations\nagainst databases. These functions are meant to fit the lowest common\ndenominator. For example, no control is offered over streaming results\nfrom SELECT statements. While these backend-generic functions are\nuseful for ad-hoc querying and development, it is wisest to use\nbackend-specific functions in production for maximum control. Refer to\nbackend-specific documentation for more information.\n\n\nFor our examples, we will use the \nbeam-sqlite\n backend and demonstrate\nusage of the beam standard query functions.\n\n\nInserting data\n\n\nFirst, let's connect to a sqlite database, and create our schema. The\n\nbeam-core\n does not offer any support for the SQL DDL language. There\nis a separate core library \nbeam-migrate\n that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.\n\n\nFor our example, we will simply issue a \nCREATE TABLE\n command\ndirectly against the database using \nsqlite-simple\n functionality:\n\n\nPrelude Schema\n execute_ conn \nCREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )\n\n\n\n\n\nNow we can insert some data into our database. Beam ships with a\nfunction \nwithDatabase\n, with the following signature:\n\n\nwithDatabase :: MonadBeam syntax be m =\n DbHandle be -\n m a -\n IO a\n\n\n\n\nDbHandle be\n is a type family that refers to a backend-specific type\nfor referring to a particular database connection. For the\n\nbeam-sqlite\n backend \nDbHandle Sqlite ~\nDatabase.Sqlite.Simple.Connection\n. \n\n\nMonadBeam\n is a type class relating a particular syntax and backend\nto a monad we can use to execute data query and manipulation commands.\n\n\nLet's insert some data into our database. We are going to use the\n\nrunInsert\n function from \nMonadBeam\n.\n\n\nPrelude Schema\n :{\nPrelude Schema| withDatabase conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person \nBob\n \nSmith\n 50\nPrelude Schema|                            , Person \nAlice\n \nWong\n 55\nPrelude Schema|                            , Person \nJohn\n \nQuincy\n 30 ]\nPrelude Schema| :}\n\n\n\n\nThe \nrunInsert\n function has the type signature\n\n\nrunInsert :: MonadBeam syntax be m =\n SqlInsert syntax -\n m ()\n\n\n\n\nSqlInsert syntax\n represents a SQL \nINSERT\n command in the given\n\nsyntax\n. We construct this value using the \ninsert\n function from\n\nDatabase.Beam.Query\n.\n\n\ninsert :: IsSql92InsertSyntax syntax =\n\n          DatabaseEntity be db (TableEntity table)\n       -\n Sql92InsertValuesSyntax syntax\n       -\n SqlInsert syntax\n\n\n\n\nIntuitively, \ninsert\n takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values. \nSql92InsertValuesSyntax syntax\n always\nimplements the \nIsSql92InsertValuesSyntax\n typeclass, which is where\nwe get the \ninsertValues\n function from. \nIsSql92InsertValuesSyntax\n\nalso defines the \ninsertSelect\n function for inserting values from the\nresult of a \nSELECT\n statement. Other backends may provide other ways\nof specifying the source of values. This brings us to another point\n\n\nPrelude Schema\n runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName = \nBob\n, personLastName=\nSmith\n, personAge=50 }, ... ]", 
            "title": "Models"
        }, 
        {
            "location": "/user-guide/models/#a-simple-model", 
            "text": "Let's define a simple model to represent a person. Open up a file named Schema.hs  and add the following.  {-# LANGUAGE GADTs #-}\n{-# LANGUAGE DeriveGeneric #-}\nmodule Schema where\n\nimport Database.Beam\nimport Database.Beam.SQLite\nimport Database.SQLite.Simple\n\nimport Data.Text (Text)\n\ndata PersonT f\n    = Person\n    { personFirstName :: Columnar f Text\n    , personLastName  :: Columnar f Text\n    , personAge       :: Columnar f Int\n    } deriving Generic\ninstance Beamable PersonT  Beam also requires that your tables have a primary key that can be used to\nuniquely identify each tuple in your relation. We tell beam about the primary\nkey by implementing the  Table  type class for your table.  instance Table PersonT where\n  data PrimaryKey PersonT f\n      = PersonKey\n      { personKeyFirstName :: Columnar f Text\n      , personKeyLastName  :: Columnar f Text\n      } deriving Generic\n  primaryKey person = PersonKey (personFirstName person) (personLastName person)   Note  Using the first and last name as a primary key is a bad idea, we use it here\nto illustrate using multiple fields as the primary key.    Tip  Many people find it useful to use the  Applicative  instance for  (- ) a  to\nwrite  primaryKey . For example, we could have written the above  primaryKey\nperson = PersonKey (personFirstName person) (personLastName person)  as primaryKey = PersonKey  $  personFirstName  *  personLastName .   For ease-of-use purposes we define some type synonyms for  PersonT  and PrimaryKey PersonT  and some convenient instances. These are not strictly\nrequired but make working with these tables much easier.  type Person = PersonT Identity\ntype PersonKey = PrimaryKey PersonT Identity\nderiving instance Show Person; deriving instance Eq Person\nderiving instance Show PersonKey; deriving instance Eq PersonKey  Due to the magic of the  Columnar  type family, the  Person  type can\nbe thought of as having the following definition.  data Person\n    = Person\n    { personFirstName :: Text\n    , personLastName  :: Text\n    , personAge       :: Int\n    } deriving (Show, Eq)  This allows us to use your type definitions for Beam as regular\nHaskell data structures without wrapping/unwrapping.   Tip  Typing  Columnar  may become tiresome.  Database.Beam  also exports  C  as a\ntype alias for  Columnar , which may make writing models easier. Since  C \nmay cause name clashes, all examples are given using  Columnar .", 
            "title": "A Simple Model"
        }, 
        {
            "location": "/user-guide/models/#foreign-references", 
            "text": "Foreign references are also easily supported in models by simply\nembedding the  PrimaryKey  of the referred to table directly in the\nparent. For example, suppose we want to create a new model\nrepresenting a post by a user.  data PostT f\n    = Post\n    { postId       :: Columnar f (Auto Int)\n    , postPostedAt :: Columnar f LocalTime\n    , postContent  :: Columnar f Text\n    , postPoster   :: PrimaryKey PersonT f\n    } deriving Generic\ninstance Beamable PostT\n\ninstance Table PostT where\n  data PrimaryKey PostT f\n      = PostId (Columnar f (Auto Int)) deriving Generic\n  primaryKey = PostId . postId\n\ntype Post = PostT Identity\ntype PostId = PrimaryKey PostT Identity\nderiving instance Show Post; deriving instance Eq Post\nderiving instance Show PostId; deriving instance Eq PostId  The  Auto  type constructor is provided by  beam-core  for fields that\nare automatically assigned by the database. Internally,  Auto x  is\nsimply a newtype over  Maybe x . The guarantee is that all values of\ntype  Auto x  returned by beam in the result set will have a value,\nalthough this guarantee is not enforced at the type level (yet).", 
            "title": "Foreign references"
        }, 
        {
            "location": "/user-guide/models/#embedding", 
            "text": "Sometimes, we want to declare multiple models with fields in\ncommon. Beam allows you to simple embed such fields in common types\nand embed those directly into models. For example,", 
            "title": "Embedding"
        }, 
        {
            "location": "/user-guide/models/#defaults", 
            "text": "Based on your data type declarations, beam can already guess a lot\nabout your tables. For example, it already assumes that the personFirstName  field is accessible in SQL as  first_name . This\ndefaulting behavior makes it very easy to interact with typical\ndatabases.  For the easiest user experience, it's best to follow beam's\nconventions for declaring models. In particular, the defaulting\nmechanisms rely on each table type declaring only one constructor\nwhich has fields named in the camelCase style.  When defaulting the name of a table field or column, beam\nun-camelCases the field name (after dropping leading underscores) and\ndrops the first word. The remaining words are joined with\nunderscores. If there is only one component, it is not\ndropped. Trailing and internal underscores are preserved in the name\nand if the name consists solely of underscores, beam makes no\nchanges. A summary of these rules is given in the table below.     Haskell field name  Beam defaulted column name      personFirstName  first_name    _personLastName  last_name    name  name    first_name  first_name    _first_name  first_name    ___  (three underscores)  ___  (no changes)     Note that beam only uses lower case in field names. While typically\ncase does not matter for SQL queries, beam always quotes\nidentifiers. Many DBMS's are case-sensitive for quoted\nidentifiers. Thus, queries can sometimes fail if your tables use\nmixtures of lower- and upper-case to distinguish between fields.  All of these defaults can be overriden using the modifications system,\ndescribed in the next section.", 
            "title": "Defaults"
        }, 
        {
            "location": "/user-guide/models/#what-about-tables-without-primary-keys", 
            "text": "Tables without primary keys are considered bad style. However,\nsometimes you need to use beam with a schema that you have no control\nover. To declare a table without a primary key, simply instantiate the Table  class without overriding the defaults.", 
            "title": "What about tables without primary keys?"
        }, 
        {
            "location": "/user-guide/models/#more-complicated-relationships", 
            "text": "This is the extent of beam's support for defining models. Although\nsimilar packages in other languages provide support for declaring\none-to-many, many-to-one, and many-to-many relationships, beam's\nfocused is providing a direct mapping of relational database concepts\nto Haskell, not on abstracting away the complexities of database\nquerying. Thus, beam does not use 'lazy-loading' or other tricks that\nobfuscate performance. Because of this, the bulk of the functionality\ndealing with different types of relations is found in the querying\nsupport, rather than in the model declarations.", 
            "title": "More complicated relationships"
        }, 
        {
            "location": "/user-guide/models/#putting-a-database-together", 
            "text": "Beam also requires you to give a type for your database. The database type\ncontains all the entities (tables or otherwise) that would be present in your\ndatabase. Our database only has one table right now, so it only contains one\nfield.  data ExampleDb f\n    = ExampleDb\n    { persons :: f (TableEntity PersonT)\n    } deriving Generic\ninstance Database ExampleDb\n\nexampleDb :: DatabaseSettings be ExampleDb\nexampleDb = autoDbSettings", 
            "title": "Putting a Database Together"
        }, 
        {
            "location": "/user-guide/models/#using-your-database", 
            "text": "Let's open up a SQLite database. Open up  ghci  and import your module.  Prelude  :load Schema.hs\nPrelude Schema  conn  - open  beam-manual.db", 
            "title": "Using your database"
        }, 
        {
            "location": "/user-guide/models/#a-quick-note-on-backends", 
            "text": "Beam is backend-agnostic and doesn't provide any means to connect to a\ndatabase. Beam backend libraries usually use well-used Haskell\nlibraries to provide database connectivity. For example, the beam-sqlite  backend uses the  sqlite-simple  backend.  Beam distinguishes each backend via type indexes. Each backend defines\na type that is used to enable backend-specific behavior. For example,\nthe  beam-sqlite  backend ships with the  Sqlite  type that is used to\ndistinguish sqlite specific constructs with generic or other\nbackend-specific ones.  Each backend can have one or more 'syntaxes', which are particular\nways to query the database. While the  beam-core  library ships with a\nstandard ANSI SQL builder, few real-world database implementations\nfully follow the standard. Most backends use their own custom syntax\ntype. Internally, beam uses a finally-tagless representation for\nsyntax trees that allow straightforward construction against any\nbackend.  Beam offers backend-generic functions for the most common operations\nagainst databases. These functions are meant to fit the lowest common\ndenominator. For example, no control is offered over streaming results\nfrom SELECT statements. While these backend-generic functions are\nuseful for ad-hoc querying and development, it is wisest to use\nbackend-specific functions in production for maximum control. Refer to\nbackend-specific documentation for more information.  For our examples, we will use the  beam-sqlite  backend and demonstrate\nusage of the beam standard query functions.", 
            "title": "A quick note on backends"
        }, 
        {
            "location": "/user-guide/models/#inserting-data", 
            "text": "First, let's connect to a sqlite database, and create our schema. The beam-core  does not offer any support for the SQL DDL language. There\nis a separate core library  beam-migrate  that offers complete support\nfor ANSI-standard SQL DDL operations, as well as tools to manipulate\ndatabase schemas. See the section on migrations for more information.  For our example, we will simply issue a  CREATE TABLE  command\ndirectly against the database using  sqlite-simple  functionality:  Prelude Schema  execute_ conn  CREATE TABLE persons ( first_name TEXT NOT NULL, last_name TEXT NOT NULL, age INT NOT NULL, PRIMARY KEY(first_name, last_name) )   Now we can insert some data into our database. Beam ships with a\nfunction  withDatabase , with the following signature:  withDatabase :: MonadBeam syntax be m =  DbHandle be -  m a -  IO a  DbHandle be  is a type family that refers to a backend-specific type\nfor referring to a particular database connection. For the beam-sqlite  backend  DbHandle Sqlite ~\nDatabase.Sqlite.Simple.Connection .   MonadBeam  is a type class relating a particular syntax and backend\nto a monad we can use to execute data query and manipulation commands.  Let's insert some data into our database. We are going to use the runInsert  function from  MonadBeam .  Prelude Schema  :{\nPrelude Schema| withDatabase conn $ do\nPrelude Schema|   runInsert $ insert (persons exampleDb) $\nPrelude Schema|               insertValues [ Person  Bob   Smith  50\nPrelude Schema|                            , Person  Alice   Wong  55\nPrelude Schema|                            , Person  John   Quincy  30 ]\nPrelude Schema| :}  The  runInsert  function has the type signature  runInsert :: MonadBeam syntax be m =  SqlInsert syntax -  m ()  SqlInsert syntax  represents a SQL  INSERT  command in the given syntax . We construct this value using the  insert  function from Database.Beam.Query .  insert :: IsSql92InsertSyntax syntax = \n          DatabaseEntity be db (TableEntity table)\n       -  Sql92InsertValuesSyntax syntax\n       -  SqlInsert syntax  Intuitively,  insert  takes a database table descriptor and some\nvalues (particular to the given syntax) and returns a statement to\ninsert these values.  Sql92InsertValuesSyntax syntax  always\nimplements the  IsSql92InsertValuesSyntax  typeclass, which is where\nwe get the  insertValues  function from.  IsSql92InsertValuesSyntax \nalso defines the  insertSelect  function for inserting values from the\nresult of a  SELECT  statement. Other backends may provide other ways\nof specifying the source of values. This brings us to another point  Prelude Schema  runSelect (select (all_ (persons exampleDb)))\n[ Person { personFirstName =  Bob , personLastName= Smith , personAge=50 }, ... ]", 
            "title": "Inserting data"
        }, 
        {
            "location": "/user-guide/databases/", 
            "text": "In addition to defining types for each of your tables, beam also\nrequires you to declare your database as a type with fields for\nholding all entities in your database. This includes more than just\ntables. For example, user-defined types that you would like to work\nwith must also be included in your database type.\n\n\nA simple database type\n\n\nLike tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.\n\n\ndata ExampleDb f\n    = ExampleDb\n    { persons :: f (TableEntity PersonT)\n    , posts   :: f (TableEntity PersonT)\n    } deriving Generic\ninstance Database ExampleDb\n\nexampleDb :: DatabaseSettings be ExampleDb\nexampleDb = defaultDbSettings\n\n\n\n\nOther database entities\n\n\nViews\n\n\n\n\nNote\n\n\nViews have not yet been implemented, but this is the expected syntax\n\n\n\n\nSome databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.\n\n\ndata PostAndPosterView f\n    = PostAndPosterView\n    { post   :: PostT f\n    , poster :: PersonT f\n    } deriving Generic\ninstance Beamable PostAndPosterView\n\n\n\n\nWe can include this in our database:\n\n\ndata ExampleDb f\n    = ExampleDb\n    { persons        :: f (TableEntity PersonT)\n    , posts          :: f (TableEntity PersonT)\n    , postAndPosters :: f (ViewEntity PostAndPosterView)\n    } deriving Generic\n\n\n\n\nNow we can use \npostAndPosters\n wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations packgae.\n\n\nUnique constraints\n\n\n\n\nNote\n\n\nThis is the current implementation plan. Uniques are not currently implemented.\n\n\n\n\nThe \nTableEntityWithUnique\n database entity allows you to declare\ntables with additional uniqueness constraints (the primary key is\nconsidered to be unique by default).\n\n\nFor example, suppose you wanted to re-define the \nPersonT\n table with\nan additional unique e-mail and another unique phone column.\n\n\ndata PersonT f\n    = Person\n    { personFirstName :: Columnar f Text\n    , personLastName  :: Columnar f Text\n    , personAge       :: Columnar f Int\n    , personEmail     :: Columnar f Text\n    , personPhone     :: Columnar f Text\n    } deriving Generic\n\ndata PersonByEmail f = PersonByEmail (Columnar f Text)\ndata PersonByPhone f = PersonByPhone (Columnar f Text)\n\n\n\n\nNow, use \nTableEntityWithUnique\n to declare the table.\n\n\ndata ExampleDb f\n    = ExampleDb\n    { persons        :: f (TableEntityWithUnique PersonT '[PersonByEmail, PersonByPhone])\n    , posts          :: f (TableEntity PersonT)\n    , postAndPosters :: f (ViewEntity PostAndPosterView)\n    } deriving Generic\n\n\n\n\nBeam will not complain about this definition, but you will need to\ndeclare additional instances in order to actually use the unique\nconstraints.\n\n\ninstance Unique PersonT PersonByEmail where\n  mkUnique = PersonByEmail . personEmail\n\ninstance Unique PersonT PersonByPhone where\n  mkUnique = PersonByPhone . personPhone\n\n\n\n\nTODO\n: Should the unique constraints be declared at the database or table level?\n\n\nDomain types\n\n\nDomain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.\n\n\nTriggers\n\n\nTODO\n\n\nCharacter sets\n\n\nTODO\n\n\nCollations\n\n\nTODO\n\n\nTranslations\n\n\nTODO\n\n\nDatabase descriptors\n\n\nIn order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the\n\ndefaultDbSettings\n function.\n\n\nFor example, to create a backend-agnostic database descriptor for the\n\nExampleDb\n type:\n\n\nexampleDb :: DatabaseSettings be ExampleDb\nexampleDb = defaultDbSettings\n\n\n\n\nNow, we can use the entities in \nexampleDb\n to write queries. The\nrules for name defaulting for database entities are the same as those\nfor \ntable fields", 
            "title": "Databases"
        }, 
        {
            "location": "/user-guide/databases/#a-simple-database-type", 
            "text": "Like tables, a database type takes a functor and applies it to each\nentity in the database. For example, a database type for the two\ntables defined above has the form.  data ExampleDb f\n    = ExampleDb\n    { persons :: f (TableEntity PersonT)\n    , posts   :: f (TableEntity PersonT)\n    } deriving Generic\ninstance Database ExampleDb\n\nexampleDb :: DatabaseSettings be ExampleDb\nexampleDb = defaultDbSettings", 
            "title": "A simple database type"
        }, 
        {
            "location": "/user-guide/databases/#other-database-entities", 
            "text": "", 
            "title": "Other database entities"
        }, 
        {
            "location": "/user-guide/databases/#views", 
            "text": "Note  Views have not yet been implemented, but this is the expected syntax   Some databases also offer the concept of 'views' -- pseudo-tables that\nare built from a pre-defined query. Suppose we wanted to create a view\nthat returned the latest comments and their respective posters.  data PostAndPosterView f\n    = PostAndPosterView\n    { post   :: PostT f\n    , poster :: PersonT f\n    } deriving Generic\ninstance Beamable PostAndPosterView  We can include this in our database:  data ExampleDb f\n    = ExampleDb\n    { persons        :: f (TableEntity PersonT)\n    , posts          :: f (TableEntity PersonT)\n    , postAndPosters :: f (ViewEntity PostAndPosterView)\n    } deriving Generic  Now we can use  postAndPosters  wherever we'd use a table. Note that you do not\nneed to specify the definition of the view. The definition is not important to\naccess the view, so beam does not need to know about it at the type-level. If\nyou want to manipulate view definitions, use the migrations packgae.", 
            "title": "Views"
        }, 
        {
            "location": "/user-guide/databases/#unique-constraints", 
            "text": "Note  This is the current implementation plan. Uniques are not currently implemented.   The  TableEntityWithUnique  database entity allows you to declare\ntables with additional uniqueness constraints (the primary key is\nconsidered to be unique by default).  For example, suppose you wanted to re-define the  PersonT  table with\nan additional unique e-mail and another unique phone column.  data PersonT f\n    = Person\n    { personFirstName :: Columnar f Text\n    , personLastName  :: Columnar f Text\n    , personAge       :: Columnar f Int\n    , personEmail     :: Columnar f Text\n    , personPhone     :: Columnar f Text\n    } deriving Generic\n\ndata PersonByEmail f = PersonByEmail (Columnar f Text)\ndata PersonByPhone f = PersonByPhone (Columnar f Text)  Now, use  TableEntityWithUnique  to declare the table.  data ExampleDb f\n    = ExampleDb\n    { persons        :: f (TableEntityWithUnique PersonT '[PersonByEmail, PersonByPhone])\n    , posts          :: f (TableEntity PersonT)\n    , postAndPosters :: f (ViewEntity PostAndPosterView)\n    } deriving Generic  Beam will not complain about this definition, but you will need to\ndeclare additional instances in order to actually use the unique\nconstraints.  instance Unique PersonT PersonByEmail where\n  mkUnique = PersonByEmail . personEmail\n\ninstance Unique PersonT PersonByPhone where\n  mkUnique = PersonByPhone . personPhone  TODO : Should the unique constraints be declared at the database or table level?", 
            "title": "Unique constraints"
        }, 
        {
            "location": "/user-guide/databases/#domain-types", 
            "text": "Domain types are a way of creating new database types with additional\nconstraints. Beam supports declaring these types as part of your\ndatabase, so they can be used anywhere a data type can. In order to\nuse your domain type, you need to supply beam a Haskell newtype that\nis used to represent values of this type in Haskell.", 
            "title": "Domain types"
        }, 
        {
            "location": "/user-guide/databases/#triggers", 
            "text": "TODO", 
            "title": "Triggers"
        }, 
        {
            "location": "/user-guide/databases/#character-sets", 
            "text": "TODO", 
            "title": "Character sets"
        }, 
        {
            "location": "/user-guide/databases/#collations", 
            "text": "TODO", 
            "title": "Collations"
        }, 
        {
            "location": "/user-guide/databases/#translations", 
            "text": "TODO", 
            "title": "Translations"
        }, 
        {
            "location": "/user-guide/databases/#database-descriptors", 
            "text": "In order to interact with the database, beam needs to know more about\nthe data structure, it also needs to know how to refer to each entity\nin your database. For the most part, beam can figure out the names for\nyou using its Generics-based defaulting mechanims. Once you have a\ndatabase type defined, you can create a database descriptor using the defaultDbSettings  function.  For example, to create a backend-agnostic database descriptor for the ExampleDb  type:  exampleDb :: DatabaseSettings be ExampleDb\nexampleDb = defaultDbSettings  Now, we can use the entities in  exampleDb  to write queries. The\nrules for name defaulting for database entities are the same as those\nfor  table fields", 
            "title": "Database descriptors"
        }, 
        {
            "location": "/user-guide/queries/basic/", 
            "text": "Given our database definition and database descriptor, we can query database\nentities and retrieve data. Before we discuss writing queries, we will take a\nlook at some of the important query types.\n\n\nData types\n\n\nThe \nQ\n data type\n\n\nBeam queries are built using the \nQ\n data type. \nQ\n's signature is as follows\n\n\ndata Q syntax db s a\n\n\n\n\nIn this definition\n\n\n\n\n\n\nsyntax\n is the particular dialect of SQL this \nQ\n monad will evaluate to.\n  Often times, this is any instance of \nIsSql92SelectSyntax\n, but sometimes you\n  use syntax-specific features. For example, if you want to use named windows in\n  postgres, you'll likely have to specialize this to \nPgSelectSyntax\n from\n  \nDatabase.Beam.Postgres.Syntax\n.\n\n\n\n\n\n\ndb\n is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.\n\n\n\n\n\n\ns\n is the scope parameter. For the most part, you'll write your queries so\n  that they work over all \ns\n. Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.\n\n\n\n\n\n\na\n is the type of the result of the query.\n\n\n\n\n\n\nThe \nQGenExpr\n type\n\n\nWhile \nQ\n represents the result of whole queries (entire \nSELECT\ns for example),\n\nQGenExpr\n represents the type of SQL expressions. \nQGenExpr\n also takes some\ntype parameters:\n\n\ndata QGenExpr context syntax s a\n\n\n\n\n\n\n\n\ncontext\n is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have \ncontext ~ QAggregateContext\n.\n  Expressions returning scalar values have \ncontext ~ QValueContext\n.\n\n\n\n\n\n\nsyntax\n is the particular SQL dialect this expression is written in. Note\n  that this is usually different than the \nsyntax\n for \nQ\n, because \nQ\n's syntax\n  refers to a particular syntax for \nSELECT\n expressions (a type implementing\n  \nIsSql92SelectSyntax\n), while \nQGenExpr\n's syntax usually refers to an\n  expression syntax (a type implementing \nIsSql92ExpressionSyntax\n). Of course,\n  since syntaxes are related, you can get from a \nQ\n \nSELECT\n syntax to a\n  \nQGenExpr\n \nsyntax\n with the \nSql92SelectExpressionSyntax\n type family.\n\n\n\n\n\n\nThus, a \nQGenExpr\n with syntax \nSql92SelectExpressionSyntax select\n can be\n  used in the \nFILTER\n clause of a query with type \nQ select db s a\n.\n\n\n\n\n\n\ns\n is a scoping parameter, which will match the \ns\n in \nQ\n.\n\n\n\n\n\n\na\n is the type of this expression. For example, expressions returning SQL\n  \nint\n values, will have Haskell type \nInt\n. This ensures that your SQL query\n  won't fail at run-time with a type error.\n\n\n\n\n\n\nBeam defines some specializations of \nQGenExpr\n for common uses.\n\n\ntype QExpr = QGenExpr QValueContext\ntype QAgg = QGenExpr QAggregateContext\ntype QOrd = QGenExpr QOrderingContext\ntype QWindowExpr = QGenExpr QWindowingContext\ntype QWindowFrame = QGenExpr QWindowFrameContext\ntype QGroupExpr = QGenExpr QGroupingContext\n\n\n\n\nThus, value expressions can be given the simpler type of \nQExpr syntax s a\n.\nExpressions containing aggregates are typed as \nQAgg syntax s a\n.\n\n\nA note on type inference\n\n\nThese types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.\n\n\nBut alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example, \nSELECT\ning just the literal \n1\n may cause an ambiguity, because\nthe compiler won't know which \nIntegral\n type to use. Beam provides an easy\nutility function \nas_\n for this. With \n-XTypeApplications\n enabled,\n\n\nas_ @Int (ambiguous expression)\n\n\n\n\nensures that \nambiguous expression\n has the type \nQGenExpr ctxt syntax s Int\n\nwith the \nctxt\n, \nsyntax\n, and \ns\n types appropriately inferred.\n\n\nSimple queries\n\n\nThe easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type \nDatabaseSettings be db\n) with some\ntable or view entities, you can use the \nall_\n function to retrieve all rows in\na specific table or view.\n\n\nFor example, to retrieve all \nPersonT\n entries in the \nexampleDb\n we defined in\nthe last section, we can say \n\n\nall_ (persons exampleDb) :: Q syntax ExampleDb s (PersonT (QExpr s))\n\n\n\n\n\n\nNote\n\n\nWe give the full type of the query here for illustrative purposes only. There \nis no need to do so in your own code\n\n\n\n\nTwo things to note. Firstly, here \nPersonT\n is parameterized over the \nQExpr s\n\nhigher-kinded type. This means that each field in \nPersonT\n now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.\n\n\nThus,\n\n\npersonFirstName (all_ (persons exampleDb)) :: QExpr s Text\n\n\n\n\nand\n\n\npersonFirstName (Person \nJohn\n \nSmith\n 23 \njohn.smith@example.com\n \n8888888888\n :: Person) :: Text\n\n\n\n\nSecondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of \ns\n from outside \nQ\n.\n\n\nOnce we have a query in terms of \nQ\n, we can use the \nselect\n function from\n\nDatabase.Beam.Query\n to turn it into a select statement that can be run against\nthe backend.\n\n\nselect (all_ (persons exampleDb)) :: (...) =\n SqlSelect syntax Person\n\n\n\n\nThe \n...\n in the context represents a bunch of requirements for \nsyntax\n that\nGHC will generate.\n\n\nNormally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.\n\n\ndumpSqlSelect (all_ (persons exampleDb))\nSELECT \nt0\n.\nfirst_name\n AS \nres0\n, \nt0\n.\nlast_name\n AS \nres1\n, \nt0\n.\nage\n AS \nres2\n, \nt0\n.\nemail\n AS \nres3\n, \nt0\n.\nphone\n AS \nres4\n FROM \nperson\n AS \nt0\n\n\n\n\n\nInternally, \ndumpSqlSelect\n uses a \nbeam-core\n provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.\n\n\nA note on composability\n\n\nAll beam queries are \ncomposable\n. This means that you can freely mix values of\ntype \nQ\n in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.\n\n\nFor example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, and then limit the amount of rows returned. In beam, \n\n\nConnecting to a database\n\n\nOkay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient \nMonadBeam\n type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However, \nMonadBeam\n\ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the \nbeam-sqlite\n backend.\n\n\nFirst, install \nbeam-sqlite\n with \ncabal\n or \nstack\n:\n\n\n$ cabal install beam-sqlite\n# or\n$ stack install beam-sqlite\n\n\n\n\nNow, load \nbeam-sqlite\n in GHCi. \n\n\nPrelude\n import Database.Beam.Sqlite\nPrelude Database.Beam.Sqlite\n \n\n\n\n\nNow, in another terminal, load the example database provided. \n\n\n$ sqlite3 basics.db \n beam-sqlite/examples/basics.sql\n\n\n\n\nNow, back in GHCi, we can create a connection to this database.\n\n\nPrelude Database.Beam.Sqlite\n basics \n- open \nbasics.db\n\nPrelude Database.Beam.Sqlite\n withDatabase basics $ runSelectReturningList (select (all_ (persons exampleDb)))\n[ .. ]\n\n\n\n\nThe \nrunSelectReturningList\n function takes a \nSqlSelect\n for the given syntax\nand returns the results via a list.\n\n\nVoil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.", 
            "title": "Basic Queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#data-types", 
            "text": "", 
            "title": "Data types"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-q-data-type", 
            "text": "Beam queries are built using the  Q  data type.  Q 's signature is as follows  data Q syntax db s a  In this definition    syntax  is the particular dialect of SQL this  Q  monad will evaluate to.\n  Often times, this is any instance of  IsSql92SelectSyntax , but sometimes you\n  use syntax-specific features. For example, if you want to use named windows in\n  postgres, you'll likely have to specialize this to  PgSelectSyntax  from\n   Database.Beam.Postgres.Syntax .    db  is the type of the database (as we defined above). This is used to ensure\n  you only query database entities that are in scope in this database.    s  is the scope parameter. For the most part, you'll write your queries so\n  that they work over all  s . Beam manipulates this parameter internally to\n  ensure that the fields in your expressions are always in scope at run-time.    a  is the type of the result of the query.", 
            "title": "The Q data type"
        }, 
        {
            "location": "/user-guide/queries/basic/#the-qgenexpr-type", 
            "text": "While  Q  represents the result of whole queries (entire  SELECT s for example), QGenExpr  represents the type of SQL expressions.  QGenExpr  also takes some\ntype parameters:  data QGenExpr context syntax s a    context  is the particular way in which this expression is being used. For\n  example, expressions containing aggregates have  context ~ QAggregateContext .\n  Expressions returning scalar values have  context ~ QValueContext .    syntax  is the particular SQL dialect this expression is written in. Note\n  that this is usually different than the  syntax  for  Q , because  Q 's syntax\n  refers to a particular syntax for  SELECT  expressions (a type implementing\n   IsSql92SelectSyntax ), while  QGenExpr 's syntax usually refers to an\n  expression syntax (a type implementing  IsSql92ExpressionSyntax ). Of course,\n  since syntaxes are related, you can get from a  Q   SELECT  syntax to a\n   QGenExpr   syntax  with the  Sql92SelectExpressionSyntax  type family.    Thus, a  QGenExpr  with syntax  Sql92SelectExpressionSyntax select  can be\n  used in the  FILTER  clause of a query with type  Q select db s a .    s  is a scoping parameter, which will match the  s  in  Q .    a  is the type of this expression. For example, expressions returning SQL\n   int  values, will have Haskell type  Int . This ensures that your SQL query\n  won't fail at run-time with a type error.    Beam defines some specializations of  QGenExpr  for common uses.  type QExpr = QGenExpr QValueContext\ntype QAgg = QGenExpr QAggregateContext\ntype QOrd = QGenExpr QOrderingContext\ntype QWindowExpr = QGenExpr QWindowingContext\ntype QWindowFrame = QGenExpr QWindowFrameContext\ntype QGroupExpr = QGenExpr QGroupingContext  Thus, value expressions can be given the simpler type of  QExpr syntax s a .\nExpressions containing aggregates are typed as  QAgg syntax s a .", 
            "title": "The QGenExpr type"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-type-inference", 
            "text": "These types may seem incredibly complicated. Indeed, the safety that beam tries\nto provide requires these scary-looking types.  But alas, do not fear! Beam is also designed to assist type inference. For the\nmost part, you will rarely need to annotate these types in your code.\nOccassionally you will need to provide a type for the result of an expression.\nFor example,  SELECT ing just the literal  1  may cause an ambiguity, because\nthe compiler won't know which  Integral  type to use. Beam provides an easy\nutility function  as_  for this. With  -XTypeApplications  enabled,  as_ @Int (ambiguous expression)  ensures that  ambiguous expression  has the type  QGenExpr ctxt syntax s Int \nwith the  ctxt ,  syntax , and  s  types appropriately inferred.", 
            "title": "A note on type inference"
        }, 
        {
            "location": "/user-guide/queries/basic/#simple-queries", 
            "text": "The easiest query is simply getting all the rows in a specific table. If you\nhave a database object (something with type  DatabaseSettings be db ) with some\ntable or view entities, you can use the  all_  function to retrieve all rows in\na specific table or view.  For example, to retrieve all  PersonT  entries in the  exampleDb  we defined in\nthe last section, we can say   all_ (persons exampleDb) :: Q syntax ExampleDb s (PersonT (QExpr s))   Note  We give the full type of the query here for illustrative purposes only. There \nis no need to do so in your own code   Two things to note. Firstly, here  PersonT  is parameterized over the  QExpr s \nhigher-kinded type. This means that each field in  PersonT  now contains a SQL\nexpression instead of a Haskell value. This is the magic that our parameterized\ntypes allow.  Thus,  personFirstName (all_ (persons exampleDb)) :: QExpr s Text  and  personFirstName (Person  John   Smith  23  john.smith@example.com   8888888888  :: Person) :: Text  Secondly, the field type has the same scope variable as the entire query. This\nmeans, it can only be used in the scope of this query. You will never be able to\ninspect the type of  s  from outside  Q .  Once we have a query in terms of  Q , we can use the  select  function from Database.Beam.Query  to turn it into a select statement that can be run against\nthe backend.  select (all_ (persons exampleDb)) :: (...) =  SqlSelect syntax Person  The  ...  in the context represents a bunch of requirements for  syntax  that\nGHC will generate.  Normally, you'd ship this select statement off to a backend to run, but for the\npurposes of this tutorial, we can also ask beam to dump what the standard SQL\nexpression this query encodes.  dumpSqlSelect (all_ (persons exampleDb))\nSELECT  t0 . first_name  AS  res0 ,  t0 . last_name  AS  res1 ,  t0 . age  AS  res2 ,  t0 . email  AS  res3 ,  t0 . phone  AS  res4  FROM  person  AS  t0   Internally,  dumpSqlSelect  uses a  beam-core  provided syntax to generate\nstandard ANSI SQL expressions. Note that these expressions should not be shipped\nto a backend directly, as they may not be escaped properly. Still, it is useful\nto see what would run.", 
            "title": "Simple queries"
        }, 
        {
            "location": "/user-guide/queries/basic/#a-note-on-composability", 
            "text": "All beam queries are  composable . This means that you can freely mix values of\ntype  Q  in whichever way typechecks and expect a reasonable SQL query. This\ndiffers from the behavior of SQL, where the syntax for composing queries depends\non the structure of that query.  For example, suppose you wanted to fetch all rows of a table, filter them by a\ncondition, and then limit the amount of rows returned. In beam,", 
            "title": "A note on composability"
        }, 
        {
            "location": "/user-guide/queries/basic/#connecting-to-a-database", 
            "text": "Okay, so we can print out a SQL statement, but how do we execute it against a\ndatabase? Beam provides a convenient  MonadBeam  type class that allows us to\nwrite queries in a backend agnostic manner. This is good-enough for most\napplications and preserves portability across databases. However,  MonadBeam \ndoes not support features specific to each backend, nor does it guarantee the\nhighest-performance. Most backends provide additional methods to query a\ndatabase, and you should prefer these if you've committed to a particular\nbackend. For tutorial purposes, we will use the  beam-sqlite  backend.  First, install  beam-sqlite  with  cabal  or  stack :  $ cabal install beam-sqlite\n# or\n$ stack install beam-sqlite  Now, load  beam-sqlite  in GHCi.   Prelude  import Database.Beam.Sqlite\nPrelude Database.Beam.Sqlite    Now, in another terminal, load the example database provided.   $ sqlite3 basics.db   beam-sqlite/examples/basics.sql  Now, back in GHCi, we can create a connection to this database.  Prelude Database.Beam.Sqlite  basics  - open  basics.db \nPrelude Database.Beam.Sqlite  withDatabase basics $ runSelectReturningList (select (all_ (persons exampleDb)))\n[ .. ]  The  runSelectReturningList  function takes a  SqlSelect  for the given syntax\nand returns the results via a list.  Voil\u00e0! We've successfully created our first query and run it against an example\ndatabase. We have now seen the major functionalities of the beam library. In the\nnext section we'll explore more advanced querying and using relationships\nbetween tables.", 
            "title": "Connecting to a database"
        }, 
        {
            "location": "/user-guide/queries/select/", 
            "text": "We've seen how to create simple queries from our schema. Beam supports other\nclauses in the SQL SELECT statement.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database. The Chinook database schema is modeled after a\nfictional record store. It provides several tables containing information on the\nmusic as well as the billing operations. Thus, it provides a good 'real-world'\ndemonstration of beam's capabalities.\n\n\nFirst, create a SQLite database from the included example.\n\n\n$ sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude Database.Beam.Sqlite\n :load beam-sqlite/examples/Chinook/Schema.hs\nPrelude Chinook.Schema\n chinook \n- open \nchinook.db\n\n\n\n\n\nOne more thing, before we see more complex examples, let's define a quick\nutility function.\n\n\nPrelude Chinook.Schema\n let withConnectionTutorial = withDatabaseDebug putStrLn chinook\n\n\n\n\nLet's test it!\n\n\nWe can run all our queries like:\n\n\nwithConnectionTutorial $ runSelectReturningList $ select $ \nquery\n\n\n\n\n\nLet's select all the tracks.\n\n\nwithConnectionTutorial $ runSelectReturningList $ select $ all_ (track chinookDb)\n\n\n\n\nFor the rest of the guide, we will also show the generated SQL code for both\nsqlite and postgres.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nall_ (track chinookDb)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nTrackId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       \nt0\n.\nAlbumId\n AS \nres2\n,\n       \nt0\n.\nMediaTypeId\n AS \nres3\n,\n       \nt0\n.\nGenreId\n AS \nres4\n,\n       \nt0\n.\nComposer\n AS \nres5\n,\n       \nt0\n.\nMilliseconds\n AS \nres6\n,\n       \nt0\n.\nBytes\n AS \nres7\n,\n       \nt0\n.\nUnitPrice\n AS \nres8\n\nFROM \nTrack\n AS \nt0\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nTrackId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       \nt0\n.\nAlbumId\n AS \nres2\n,\n       \nt0\n.\nMediaTypeId\n AS \nres3\n,\n       \nt0\n.\nGenreId\n AS \nres4\n,\n       \nt0\n.\nComposer\n AS \nres5\n,\n       \nt0\n.\nMilliseconds\n AS \nres6\n,\n       \nt0\n.\nBytes\n AS \nres7\n,\n       \nt0\n.\nUnitPrice\n AS \nres8\n\nFROM \nTrack\n AS \nt0\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nWHERE\n clause\n\n\nWe've seen how to use \nall_\n to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the \nfilter_\n function.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_ (\\customer -\n customerFirstName customer `like_` \nJo%\n) $\nall_ (customer chinookDb)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (\nt0\n.\nFirstName\n) LIKE (?)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (\nt0\n.\nFirstName\n) LIKE ('Jo%')\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can use \n(\n.)\n and \n(||.)\n to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nfilter_ (\\customer -\n ((customerFirstName customer `like_` \nJo%\n) \n. (customerLastName customer `like_` \nS%\n)) \n.\n                      (addressState (customerAddress customer) ==. just_ \nCA\n ||. addressState (customerAddress customer) ==. just_ \nWA\n)) $\n        all_ (customer chinookDb)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n  AND (((\nt0\n.\nState\n)=(?))\n       OR ((\nt0\n.\nState\n)=(?)))\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE ('Jo%'))\n       AND ((\nt0\n.\nLastName\n) LIKE ('S%')))\n  AND (((\nt0\n.\nState\n) = ('CA'))\n       OR ((\nt0\n.\nState\n) = ('WA')))\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nWe had to use the \njust_\n function above to compare\n\naddressState (customerAddress customer)\n. This is because \naddressState\n(customerAddress customer)\n represents a nullable column which beam types as\n\nMaybe Text\n. Just as in Haskell, we need to explicitly unwrap the \nMaybe\n\ntype. This is an example of beam offering stronger typing than SQL itself.\n\n\n\n\nLIMIT\n/\nOFFSET\n support\n\n\nThe \nlimit_\n and \noffset_\n functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe \nLIMIT\n and \nOFFSET\n SQL constructs.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlimit_ 10 $ offset_ 100 $\nfilter_ (\\customer -\n ((customerFirstName customer `like_` \nJo%\n) \n. (customerLastName customer `like_` \nS%\n)) \n.\n                      (addressState (customerAddress customer) ==. just_ \nCA\n ||. addressState (customerAddress customer) ==. just_ \nWA\n)) $\n        all_ (customer chinookDb)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n  AND (((\nt0\n.\nState\n)=(?))\n       OR ((\nt0\n.\nState\n)=(?)))\nLIMIT 10\nOFFSET 100\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE ('Jo%'))\n       AND ((\nt0\n.\nLastName\n) LIKE ('S%')))\n  AND (((\nt0\n.\nState\n) = ('CA'))\n       OR ((\nt0\n.\nState\n) = ('WA')))\nLIMIT 10\nOFFSET 100\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nNote\n\n\nNested \nlimit_\ns and \noffset_\ns compose in the way you'd expect without\ngenerating extraneous subqueries.\n\n\n\n\n\n\nWarning\n\n\nNote that the order of the \nlimit_\n and \noffset_\n functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \noffset_ 100 $ limit_ 10 $\nfilter_ (\\customer -\n ((customerFirstName customer `like_` \nJo%\n) \n. (customerLastName customer `like_` \nS%\n)) \n.\n                      (addressState (customerAddress customer) ==. just_ \nCA\n ||. addressState (customerAddress customer) ==. just_ \nWA\n)) $\n        all_ (customer chinookDb)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE (?))\n       AND ((\nt0\n.\nLastName\n) LIKE (?)))\n  AND (((\nt0\n.\nState\n)=(?))\n       OR ((\nt0\n.\nState\n)=(?)))\nLIMIT 0\nOFFSET 100\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nCustomerId\n AS \nres0\n,\n       \nt0\n.\nFirstName\n AS \nres1\n,\n       \nt0\n.\nLastName\n AS \nres2\n,\n       \nt0\n.\nCompany\n AS \nres3\n,\n       \nt0\n.\nAddress\n AS \nres4\n,\n       \nt0\n.\nCity\n AS \nres5\n,\n       \nt0\n.\nState\n AS \nres6\n,\n       \nt0\n.\nCountry\n AS \nres7\n,\n       \nt0\n.\nPostalCode\n AS \nres8\n,\n       \nt0\n.\nPhone\n AS \nres9\n,\n       \nt0\n.\nFax\n AS \nres10\n,\n       \nt0\n.\nEmail\n AS \nres11\n,\n       \nt0\n.\nSupportRepId\n AS \nres12\n\nFROM \nCustomer\n AS \nt0\n\nWHERE (((\nt0\n.\nFirstName\n) LIKE ('Jo%'))\n       AND ((\nt0\n.\nLastName\n) LIKE ('S%')))\n  AND (((\nt0\n.\nState\n) = ('CA'))\n       OR ((\nt0\n.\nState\n) = ('WA')))\nLIMIT 0\nOFFSET 100", 
            "title": "More complex SELECTs"
        }, 
        {
            "location": "/user-guide/queries/select/#where-clause", 
            "text": "We've seen how to use  all_  to select all rows of a table. Sometimes, you would\nlike to filter results based on the result of some condition. For example,\nperhaps you would like to fetch all customers whose names start with \"Jo\". We\ncan filter over results using the  filter_  function.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             filter_ (\\customer -  customerFirstName customer `like_`  Jo% ) $\nall_ (customer chinookDb) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ( t0 . FirstName ) LIKE (?) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ( t0 . FirstName ) LIKE ('Jo%') \n         \n    \n         \n    \n                 \n                      You can use  ( .)  and  (||.)  to combine boolean expressions, as you'd expect.\nFor example, to select all customers whose first name begins with \"Jo\", last\nname begins with \"S\", and who live in either California or Washington:  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             filter_ (\\customer -  ((customerFirstName customer `like_`  Jo% )  . (customerLastName customer `like_`  S% ))  .\n                      (addressState (customerAddress customer) ==. just_  CA  ||. addressState (customerAddress customer) ==. just_  WA )) $\n        all_ (customer chinookDb) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE (?))\n       AND (( t0 . LastName ) LIKE (?)))\n  AND ((( t0 . State )=(?))\n       OR (( t0 . State )=(?))) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE ('Jo%'))\n       AND (( t0 . LastName ) LIKE ('S%')))\n  AND ((( t0 . State ) = ('CA'))\n       OR (( t0 . State ) = ('WA'))) \n         \n    \n         \n    \n                 \n                       Note  We had to use the  just_  function above to compare addressState (customerAddress customer) . This is because  addressState\n(customerAddress customer)  represents a nullable column which beam types as Maybe Text . Just as in Haskell, we need to explicitly unwrap the  Maybe \ntype. This is an example of beam offering stronger typing than SQL itself.", 
            "title": "WHERE clause"
        }, 
        {
            "location": "/user-guide/queries/select/#limitoffset-support", 
            "text": "The  limit_  and  offset_  functions can be used to truncate the result set at a\ncertain length and fetch different portions of the result. They correspond to\nthe  LIMIT  and  OFFSET  SQL constructs.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             limit_ 10 $ offset_ 100 $\nfilter_ (\\customer -  ((customerFirstName customer `like_`  Jo% )  . (customerLastName customer `like_`  S% ))  .\n                      (addressState (customerAddress customer) ==. just_  CA  ||. addressState (customerAddress customer) ==. just_  WA )) $\n        all_ (customer chinookDb) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE (?))\n       AND (( t0 . LastName ) LIKE (?)))\n  AND ((( t0 . State )=(?))\n       OR (( t0 . State )=(?)))\nLIMIT 10\nOFFSET 100 \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE ('Jo%'))\n       AND (( t0 . LastName ) LIKE ('S%')))\n  AND ((( t0 . State ) = ('CA'))\n       OR (( t0 . State ) = ('WA')))\nLIMIT 10\nOFFSET 100 \n         \n    \n         \n    \n                 \n                       Note  Nested  limit_ s and  offset_ s compose in the way you'd expect without\ngenerating extraneous subqueries.    Warning  Note that the order of the  limit_  and  offset_  functions matter.\nOffseting an already limited result is not the same as limiting an offseted\nresult. For example, if you offset three rows into a limited set of five\nresults, you will get at most two rows. On the other hand, if you offset\nthree rows and then limit the result to the next five, you may get up to\nfive. Beam will generate exactly the query you specify. Notice the\ndifference below, where the order of the clauses made beam generate a query\nthat returns no results.   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             offset_ 100 $ limit_ 10 $\nfilter_ (\\customer -  ((customerFirstName customer `like_`  Jo% )  . (customerLastName customer `like_`  S% ))  .\n                      (addressState (customerAddress customer) ==. just_  CA  ||. addressState (customerAddress customer) ==. just_  WA )) $\n        all_ (customer chinookDb) \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE (?))\n       AND (( t0 . LastName ) LIKE (?)))\n  AND ((( t0 . State )=(?))\n       OR (( t0 . State )=(?)))\nLIMIT 0\nOFFSET 100 \n         \n    \n         \n             SELECT  t0 . CustomerId  AS  res0 ,\n        t0 . FirstName  AS  res1 ,\n        t0 . LastName  AS  res2 ,\n        t0 . Company  AS  res3 ,\n        t0 . Address  AS  res4 ,\n        t0 . City  AS  res5 ,\n        t0 . State  AS  res6 ,\n        t0 . Country  AS  res7 ,\n        t0 . PostalCode  AS  res8 ,\n        t0 . Phone  AS  res9 ,\n        t0 . Fax  AS  res10 ,\n        t0 . Email  AS  res11 ,\n        t0 . SupportRepId  AS  res12 \nFROM  Customer  AS  t0 \nWHERE ((( t0 . FirstName ) LIKE ('Jo%'))\n       AND (( t0 . LastName ) LIKE ('S%')))\n  AND ((( t0 . State ) = ('CA'))\n       OR (( t0 . State ) = ('WA')))\nLIMIT 0\nOFFSET 100", 
            "title": "LIMIT/OFFSET support"
        }, 
        {
            "location": "/user-guide/queries/ordering/", 
            "text": "Usually, queries are ordered before \nLIMIT\n and \nOFFSET\n are applied. Beam\nsupports the standard SQL \nORDER BY\n construct through the \norderBy_\n function.", 
            "title": "Ordering"
        }, 
        {
            "location": "/user-guide/queries/relationships/", 
            "text": "Relational databases are so-named because they're good at expressing relations\namong data and providing related data in queries. Beam exposes these features in\nits DSL.\n\n\nFor these examples, we're going to use the \nbeam-sqlite\n backend with the\nprovided sample Chinook database.\n\n\nFirst, create a SQLite database from the included example.\n\n\n sqlite3 chinook.db \n beam-sqlite/examples/chinook.sql\n\n\n\n\nNow, load the chinook database schema in GHCi.\n\n\nPrelude Database.Beam.Sqlite\n :load beam-sqlite/examples/Chinook/Schema.hs\nPrelude Chinook.Schema\n chinook \n- open \nchinook.db\n\n\n\n\n\nOne more thing, before we explore how beam handles relationships. Before we do, let's define a quick utility function.\n\n\nPrelude Chinook.Schema\n let withConnectionTutorial = withDatabaseDebug putStrLn chinook\n\n\n\n\nThis function prints each of our queries to standard output before running them.\nUsing this function will let us see what SQL is executing.\n\n\nOne-to-many\n\n\nBeam supports querying for one-to-many joins. For example, to get every\n\nInvoiceLine\n for each \nInvoice\n, use the \noneToMany_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo i \n- all_ (invoice chinookDb)\n   ln \n- oneToMany_ (invoiceLine chinookDb) invoiceLineInvoice i\n   pure (i, ln)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n       \nt0\n.\nCustomerId\n AS \nres1\n,\n       \nt0\n.\nInvoiceDate\n AS \nres2\n,\n       \nt0\n.\nBillingAddress\n AS \nres3\n,\n       \nt0\n.\nBillingCity\n AS \nres4\n,\n       \nt0\n.\nBillingState\n AS \nres5\n,\n       \nt0\n.\nBillingCountry\n AS \nres6\n,\n       \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n       \nt0\n.\nTotal\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM \nInvoice\n AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nInvoiceId\n)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n       \nt0\n.\nCustomerId\n AS \nres1\n,\n       \nt0\n.\nInvoiceDate\n AS \nres2\n,\n       \nt0\n.\nBillingAddress\n AS \nres3\n,\n       \nt0\n.\nBillingCity\n AS \nres4\n,\n       \nt0\n.\nBillingState\n AS \nres5\n,\n       \nt0\n.\nBillingCountry\n AS \nres6\n,\n       \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n       \nt0\n.\nTotal\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM \nInvoice\n AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n) = (\nt0\n.\nInvoiceId\n)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nOr, if you have an actual \nInvoice\n (called \noneInvoice\n) and you want all the\nassociated \nInvoiceLine\ns, you can use \nval_\n to convert \noneInvoice\n to the SQL\nexpression level.\n\n\noneToMany_ (invoiceLine chinookDb) invoiceLineInvoice (val_ i)\n\n\n\n\nIf you find yourself repeating yourself constantly, you can define a helper.\n\n\ninvoiceLines_ :: OneToMany InvoiceT InvoiceLineT\ninvoiceLines_ = oneToMany_ (invoiceLine chinookDb) invoiceLineInvoice\n\n\n\n\nThen the above queries become\n\n\ndo i \n- all_ (invoice chinookDb)\n   ln \n- invoiceLines_ i\n\n\n\n\nand\n\n\ninvoiceLines (val_ i)\n\n\n\n\nNullable columns\n\n\nIf you have a nullable foreign key in your many table, you can use\n\noneToManyOptional_\n and \nOneToManyOptional\n, respectively. For example, \n\n\nOne-to-one\n\n\nOne to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.\n\n\nFor convenience, \noneToOne_\n and \nOneToOne\n are equivalent to \noneToMany_\n and\n\nOneToMany\n. Additionally, \noneToMaybe_\n and \nOneToMaybe\n correspond to\n\noneToManyOptional_\n and \nOneToManyOptional\n.\n\n\nMany-to-many\n\n\nMany to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.\n\n\nThe \nmanyToMany_\n construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.\n\n\nmanyToMany_ :: ( Database db, Table joinThrough\n               , Table left, Table right\n               , Sql92SelectSanityCheck syntax\n               , IsSql92SelectSyntax syntax\n\n               , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey left g)\n               , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey right h) )\n            =\n DatabaseEntity be db (TableEntity joinThrough)\n            -\n (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -\n PrimaryKey left g)\n            -\n (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -\n PrimaryKey right h)\n            -\n Q syntax db s (left g) -\n Q syntax db s (right h)\n            -\n Q syntax db s (left g, right h)\n\n\n\n\nThis reads: for any database \ndb\n; tables \njoinThrough\n, \nleft\n, and \nright\n;\nand sane select syntax \nsyntax\n, where the primary keys of \nleft\n and \nright\n\nare comparable as value expressions and we have some way of extracting a primary\nkey of \nleft\n and \nright\n from \njoinThrough\n, associate all entries of \nleft\n\nwith those of \nright\n through \njoinThrough\n and return the results of \nleft\n and\n\nright\n.\n\n\nFor example, \n\n\nMany-to-many with arbitrary data\n\n\nSometimes you want to have additional data for each relationship. For this, use\n\nmanyToManyPassthrough_\n.\n\n\nmanyToManyPassthrough_ \n    :: ( Database db, Table joinThrough\n       , Table left, Table right\n       , Sql92SelectSanityCheck syntax\n       , IsSql92SelectSyntax syntax\n\n       , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey left g)\n       , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey right h) )\n    =\n DatabaseEntity be db (TableEntity joinThrough)\n    -\n (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -\n PrimaryKey left g)\n    -\n (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -\n PrimaryKey right h)\n    -\n Q syntax db s (left g) -\n Q syntax db s (right h)\n    -\n Q syntax db s (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s), left g, right h)\n\n\n\n\nUnder the hood \nmanyToMany_\n is defined simply as \n\n\nmanyToMany_ = fmap (\\(_, left, right) -\n (left, right)) manyToManyPassthrough_\n\n\n\n\n\n\nTODO\n\n\nIt would be nice to have a \nManyToMany\n type or some equivalent.\n\n\n\n\nArbitrary Joins\n\n\nJoins with arbitrary conditions can be specified using the \njoin_\n construct.\n\n\nOuter joins\n\n\nLeft and right joins\n\n\nLeft joins with arbitrary conditions can be specified with the \nleftJoin_\n\nconstruct. \nleftJoin_\n takes a table and a join condition. It associates each\nresult record with a record of the table given or an fully NULL row of that\ntable in case no row matches. For this reason, the result of \nleftJoin_\n has an\nextra \nNullable\n column tag, which converts each field into the corresponding\n\nMaybe\n type.\n\n\n\n\nNote\n\n\nThe table parameter passed in as the join condition does not have a \n\nNullable\n column tag. The join condition should be written as if a \nconcrete row from that table exists.\n\n\n\n\n\n\nTODO\n\n\nGive an example of \nleftJoin_\n\n\n\n\n\n\nTODO\n\n\nrightJoin_\n is not yet implemented\n\n\n\n\nRight joins are supported (albeit awkwardly) with the \nrightJoin_\n construct.\n\n\nFull Outer joins\n\n\n\n\nTODO\n\n\nouterJoin_\n not yet supported\n\n\n\n\nFull outer joins are supported via the \nouterJoin_\n construct.\n\n\nSubqueries\n\n\nSometimes you want to join against a \nsubquery\n rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.\n\n\nFor example, the following query generates the code you'd expect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \ndo i \n- limit_ 10 $ all_ (invoice chinookDb)\n   line \n- invoiceLines i\n   pure (i, line)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nres2\n AS \nres2\n,\n       \nt0\n.\nres3\n AS \nres3\n,\n       \nt0\n.\nres4\n AS \nres4\n,\n       \nt0\n.\nres5\n AS \nres5\n,\n       \nt0\n.\nres6\n AS \nres6\n,\n       \nt0\n.\nres7\n AS \nres7\n,\n       \nt0\n.\nres8\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n          \nt0\n.\nBillingState\n AS \nres5\n,\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n          \nt0\n.\nTotal\n AS \nres8\n\n   FROM \nInvoice\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nres0\n)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nres2\n AS \nres2\n,\n       \nt0\n.\nres3\n AS \nres3\n,\n       \nt0\n.\nres4\n AS \nres4\n,\n       \nt0\n.\nres5\n AS \nres5\n,\n       \nt0\n.\nres6\n AS \nres6\n,\n       \nt0\n.\nres7\n AS \nres7\n,\n       \nt0\n.\nres8\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n          \nt0\n.\nBillingState\n AS \nres5\n,\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n          \nt0\n.\nTotal\n AS \nres8\n\n   FROM \nInvoice\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n) = (\nt0\n.\nres0\n)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using \nsubselect_\n. The \nsubselect_\n will force a new query to be\noutput in most cases. For simple queries, such as \nall_\n, \nsubselect_\n will have\nno effect.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Same as above, but with explicit sub select\ndo i \n- subselect_ $ limit_ 10 $ all_ (invoice chinookDb)\n   line \n- invoiceLines i\n   pure (i, line)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nres2\n AS \nres2\n,\n       \nt0\n.\nres3\n AS \nres3\n,\n       \nt0\n.\nres4\n AS \nres4\n,\n       \nt0\n.\nres5\n AS \nres5\n,\n       \nt0\n.\nres6\n AS \nres6\n,\n       \nt0\n.\nres7\n AS \nres7\n,\n       \nt0\n.\nres8\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n          \nt0\n.\nBillingState\n AS \nres5\n,\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n          \nt0\n.\nTotal\n AS \nres8\n\n   FROM \nInvoice\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n)=(\nt0\n.\nres0\n)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nres2\n AS \nres2\n,\n       \nt0\n.\nres3\n AS \nres3\n,\n       \nt0\n.\nres4\n AS \nres4\n,\n       \nt0\n.\nres5\n AS \nres5\n,\n       \nt0\n.\nres6\n AS \nres6\n,\n       \nt0\n.\nres7\n AS \nres7\n,\n       \nt0\n.\nres8\n AS \nres8\n,\n       \nt1\n.\nInvoiceLineId\n AS \nres9\n,\n       \nt1\n.\nInvoiceId\n AS \nres10\n,\n       \nt1\n.\nTrackId\n AS \nres11\n,\n       \nt1\n.\nUnitPrice\n AS \nres12\n,\n       \nt1\n.\nQuantity\n AS \nres13\n\nFROM\n  (SELECT \nt0\n.\nInvoiceId\n AS \nres0\n,\n          \nt0\n.\nCustomerId\n AS \nres1\n,\n          \nt0\n.\nInvoiceDate\n AS \nres2\n,\n          \nt0\n.\nBillingAddress\n AS \nres3\n,\n          \nt0\n.\nBillingCity\n AS \nres4\n,\n          \nt0\n.\nBillingState\n AS \nres5\n,\n          \nt0\n.\nBillingCountry\n AS \nres6\n,\n          \nt0\n.\nBillingPostalCode\n AS \nres7\n,\n          \nt0\n.\nTotal\n AS \nres8\n\n   FROM \nInvoice\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\nINNER JOIN \nInvoiceLine\n AS \nt1\n ON (\nt1\n.\nInvoiceId\n) = (\nt0\n.\nres0\n)", 
            "title": "Relationships"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-many", 
            "text": "Beam supports querying for one-to-many joins. For example, to get every InvoiceLine  for each  Invoice , use the  oneToMany_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do i  - all_ (invoice chinookDb)\n   ln  - oneToMany_ (invoiceLine chinookDb) invoiceLineInvoice i\n   pure (i, ln) \n         \n    \n         \n             SELECT  t0 . InvoiceId  AS  res0 ,\n        t0 . CustomerId  AS  res1 ,\n        t0 . InvoiceDate  AS  res2 ,\n        t0 . BillingAddress  AS  res3 ,\n        t0 . BillingCity  AS  res4 ,\n        t0 . BillingState  AS  res5 ,\n        t0 . BillingCountry  AS  res6 ,\n        t0 . BillingPostalCode  AS  res7 ,\n        t0 . Total  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM  Invoice  AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . InvoiceId ) \n         \n    \n         \n             SELECT  t0 . InvoiceId  AS  res0 ,\n        t0 . CustomerId  AS  res1 ,\n        t0 . InvoiceDate  AS  res2 ,\n        t0 . BillingAddress  AS  res3 ,\n        t0 . BillingCity  AS  res4 ,\n        t0 . BillingState  AS  res5 ,\n        t0 . BillingCountry  AS  res6 ,\n        t0 . BillingPostalCode  AS  res7 ,\n        t0 . Total  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM  Invoice  AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId ) = ( t0 . InvoiceId ) \n         \n    \n         \n    \n                 \n                      Or, if you have an actual  Invoice  (called  oneInvoice ) and you want all the\nassociated  InvoiceLine s, you can use  val_  to convert  oneInvoice  to the SQL\nexpression level.  oneToMany_ (invoiceLine chinookDb) invoiceLineInvoice (val_ i)  If you find yourself repeating yourself constantly, you can define a helper.  invoiceLines_ :: OneToMany InvoiceT InvoiceLineT\ninvoiceLines_ = oneToMany_ (invoiceLine chinookDb) invoiceLineInvoice  Then the above queries become  do i  - all_ (invoice chinookDb)\n   ln  - invoiceLines_ i  and  invoiceLines (val_ i)", 
            "title": "One-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#nullable-columns", 
            "text": "If you have a nullable foreign key in your many table, you can use oneToManyOptional_  and  OneToManyOptional , respectively. For example,", 
            "title": "Nullable columns"
        }, 
        {
            "location": "/user-guide/queries/relationships/#one-to-one", 
            "text": "One to one relationships are a special case of one to many relationships, save\nfor a unique constraint on one column. Thus, there are no special constructs for\none-to-one relationships.  For convenience,  oneToOne_  and  OneToOne  are equivalent to  oneToMany_  and OneToMany . Additionally,  oneToMaybe_  and  OneToMaybe  correspond to oneToManyOptional_  and  OneToManyOptional .", 
            "title": "One-to-one"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many", 
            "text": "Many to many relationships require a linking table, with foreign keys to each\ntable part of the relationship.  The  manyToMany_  construct can be used to fetch both, one, or no sides of a\nmany-to-many relationship.  manyToMany_ :: ( Database db, Table joinThrough\n               , Table left, Table right\n               , Sql92SelectSanityCheck syntax\n               , IsSql92SelectSyntax syntax\n\n               , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey left g)\n               , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey right h) )\n            =  DatabaseEntity be db (TableEntity joinThrough)\n            -  (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -  PrimaryKey left g)\n            -  (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -  PrimaryKey right h)\n            -  Q syntax db s (left g) -  Q syntax db s (right h)\n            -  Q syntax db s (left g, right h)  This reads: for any database  db ; tables  joinThrough ,  left , and  right ;\nand sane select syntax  syntax , where the primary keys of  left  and  right \nare comparable as value expressions and we have some way of extracting a primary\nkey of  left  and  right  from  joinThrough , associate all entries of  left \nwith those of  right  through  joinThrough  and return the results of  left  and right .  For example,", 
            "title": "Many-to-many"
        }, 
        {
            "location": "/user-guide/queries/relationships/#many-to-many-with-arbitrary-data", 
            "text": "Sometimes you want to have additional data for each relationship. For this, use manyToManyPassthrough_ .  manyToManyPassthrough_ \n    :: ( Database db, Table joinThrough\n       , Table left, Table right\n       , Sql92SelectSanityCheck syntax\n       , IsSql92SelectSyntax syntax\n\n       , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey left g)\n       , SqlOrd (QExpr (Sql92SelectExpressionSyntax syntax) s) (PrimaryKey right h) )\n    =  DatabaseEntity be db (TableEntity joinThrough)\n    -  (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -  PrimaryKey left g)\n    -  (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s) -  PrimaryKey right h)\n    -  Q syntax db s (left g) -  Q syntax db s (right h)\n    -  Q syntax db s (joinThrough (QExpr (Sql92SelectExpressionSyntax syntax) s), left g, right h)  Under the hood  manyToMany_  is defined simply as   manyToMany_ = fmap (\\(_, left, right) -  (left, right)) manyToManyPassthrough_   TODO  It would be nice to have a  ManyToMany  type or some equivalent.", 
            "title": "Many-to-many with arbitrary data"
        }, 
        {
            "location": "/user-guide/queries/relationships/#arbitrary-joins", 
            "text": "Joins with arbitrary conditions can be specified using the  join_  construct.", 
            "title": "Arbitrary Joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#outer-joins", 
            "text": "", 
            "title": "Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#left-and-right-joins", 
            "text": "Left joins with arbitrary conditions can be specified with the  leftJoin_ \nconstruct.  leftJoin_  takes a table and a join condition. It associates each\nresult record with a record of the table given or an fully NULL row of that\ntable in case no row matches. For this reason, the result of  leftJoin_  has an\nextra  Nullable  column tag, which converts each field into the corresponding Maybe  type.   Note  The table parameter passed in as the join condition does not have a  Nullable  column tag. The join condition should be written as if a \nconcrete row from that table exists.    TODO  Give an example of  leftJoin_    TODO  rightJoin_  is not yet implemented   Right joins are supported (albeit awkwardly) with the  rightJoin_  construct.", 
            "title": "Left and right joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#full-outer-joins", 
            "text": "TODO  outerJoin_  not yet supported   Full outer joins are supported via the  outerJoin_  construct.", 
            "title": "Full Outer joins"
        }, 
        {
            "location": "/user-guide/queries/relationships/#subqueries", 
            "text": "Sometimes you want to join against a  subquery  rather than a table. For the\nmost part, beam will automatically figure out when certain queries need to be\nwritten using subqueries. For example, to join two result sets cointaining a SQL\nLIMIT, you would normally have to write both queries as subqueries. In beam, you\ncan write such queries as you'd expect. The library takes care of creating\nsubqueries as expected.  For example, the following query generates the code you'd expect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             do i  - limit_ 10 $ all_ (invoice chinookDb)\n   line  - invoiceLines i\n   pure (i, line) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t0 . res2  AS  res2 ,\n        t0 . res3  AS  res3 ,\n        t0 . res4  AS  res4 ,\n        t0 . res5  AS  res5 ,\n        t0 . res6  AS  res6 ,\n        t0 . res7  AS  res7 ,\n        t0 . res8  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM\n  (SELECT  t0 . InvoiceId  AS  res0 ,\n           t0 . CustomerId  AS  res1 ,\n           t0 . InvoiceDate  AS  res2 ,\n           t0 . BillingAddress  AS  res3 ,\n           t0 . BillingCity  AS  res4 ,\n           t0 . BillingState  AS  res5 ,\n           t0 . BillingCountry  AS  res6 ,\n           t0 . BillingPostalCode  AS  res7 ,\n           t0 . Total  AS  res8 \n   FROM  Invoice  AS  t0 \n   LIMIT 10) AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . res0 ) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t0 . res2  AS  res2 ,\n        t0 . res3  AS  res3 ,\n        t0 . res4  AS  res4 ,\n        t0 . res5  AS  res5 ,\n        t0 . res6  AS  res6 ,\n        t0 . res7  AS  res7 ,\n        t0 . res8  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM\n  (SELECT  t0 . InvoiceId  AS  res0 ,\n           t0 . CustomerId  AS  res1 ,\n           t0 . InvoiceDate  AS  res2 ,\n           t0 . BillingAddress  AS  res3 ,\n           t0 . BillingCity  AS  res4 ,\n           t0 . BillingState  AS  res5 ,\n           t0 . BillingCountry  AS  res6 ,\n           t0 . BillingPostalCode  AS  res7 ,\n           t0 . Total  AS  res8 \n   FROM  Invoice  AS  t0 \n   LIMIT 10) AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId ) = ( t0 . res0 ) \n         \n    \n         \n    \n                 \n                      If you need to (for efficiency for example), you can also generate subqueries\nexplicitly, using  subselect_ . The  subselect_  will force a new query to be\noutput in most cases. For simple queries, such as  all_ ,  subselect_  will have\nno effect.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Same as above, but with explicit sub select\ndo i  - subselect_ $ limit_ 10 $ all_ (invoice chinookDb)\n   line  - invoiceLines i\n   pure (i, line) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t0 . res2  AS  res2 ,\n        t0 . res3  AS  res3 ,\n        t0 . res4  AS  res4 ,\n        t0 . res5  AS  res5 ,\n        t0 . res6  AS  res6 ,\n        t0 . res7  AS  res7 ,\n        t0 . res8  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM\n  (SELECT  t0 . InvoiceId  AS  res0 ,\n           t0 . CustomerId  AS  res1 ,\n           t0 . InvoiceDate  AS  res2 ,\n           t0 . BillingAddress  AS  res3 ,\n           t0 . BillingCity  AS  res4 ,\n           t0 . BillingState  AS  res5 ,\n           t0 . BillingCountry  AS  res6 ,\n           t0 . BillingPostalCode  AS  res7 ,\n           t0 . Total  AS  res8 \n   FROM  Invoice  AS  t0 \n   LIMIT 10) AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId )=( t0 . res0 ) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t0 . res2  AS  res2 ,\n        t0 . res3  AS  res3 ,\n        t0 . res4  AS  res4 ,\n        t0 . res5  AS  res5 ,\n        t0 . res6  AS  res6 ,\n        t0 . res7  AS  res7 ,\n        t0 . res8  AS  res8 ,\n        t1 . InvoiceLineId  AS  res9 ,\n        t1 . InvoiceId  AS  res10 ,\n        t1 . TrackId  AS  res11 ,\n        t1 . UnitPrice  AS  res12 ,\n        t1 . Quantity  AS  res13 \nFROM\n  (SELECT  t0 . InvoiceId  AS  res0 ,\n           t0 . CustomerId  AS  res1 ,\n           t0 . InvoiceDate  AS  res2 ,\n           t0 . BillingAddress  AS  res3 ,\n           t0 . BillingCity  AS  res4 ,\n           t0 . BillingState  AS  res5 ,\n           t0 . BillingCountry  AS  res6 ,\n           t0 . BillingPostalCode  AS  res7 ,\n           t0 . Total  AS  res8 \n   FROM  Invoice  AS  t0 \n   LIMIT 10) AS  t0 \nINNER JOIN  InvoiceLine  AS  t1  ON ( t1 . InvoiceId ) = ( t0 . res0 )", 
            "title": "Subqueries"
        }, 
        {
            "location": "/user-guide/queries/aggregates/", 
            "text": "You can use the \naggregate_\n function to group your result set and compute\naggregates within the group. You can think of \naggregate_\n as a souped up\nversion of Haskell's \ngroupBy\n.\n\n\nYou use \naggregate_\n by specifying an underlying query to run and a function\nthat produces an aggregation projection. An aggregation projection is either a\nvalue of type \nQAgg syntax s a\n, a value of type \nQGroupExpr syntax s a\n, or a\ntuple of such values. Any \nQGenExpr\n that uses an aggregate function is\nautomatically assigned the \nQAgg syntax s a\n type. Any \nQGenExpr\n that contains\nthe \ngroup_\n combinator is given the type \nQGroupExpr\n.\n\n\nDuring query generation, the expressions of type \nQGroupExpr\n are added to the\n\nGROUP BY\n clause, and expressions of type \nQAgg\n are treated as aggregation to\nbe computed.\n\n\nThe result of the \naggregate_\n lifts all the \nQAgg\ns and \nQGroupExpr\ns to\n'regular' value-level \nQExpr\ns, so the result of \naggregate_\n can be used in\nexpressions as usual.\n\n\nSimple aggregate usage\n\n\nSuppose we wanted to count the number of genres in our database.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_ (\\_ -\n countAll_) (all_ (genre chinookDb))\n\n\n        \n\n    \n        \n\n            \nSELECT COUNT(*) AS \nres0\n\nFROM \nGenre\n AS \nt0\n\n\n\n        \n\n    \n        \n\n            \nSELECT COUNT(*) AS \nres0\n\nFROM \nGenre\n AS \nt0\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nAdding a GROUP BY clause\n\n\nAbove, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the \ngroup_\n function to\ngroup by the genre.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_ (\\(genre, track) -\n (group_ genre, as_ @Int $ count_ (trackId track)))\n           ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb))\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(\nt1\n.\nTrackId\n) AS \nres2\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(\nt1\n.\nTrackId\n) AS \nres2\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\n\n\nTip\n\n\ncount_\n can return any \nIntegral\n type. Adding the explicit \nas_ @Int\n above \nprevents an ambiguous type error.\n\n\n\n\nSQL compatibility\n\n\nAbove, we demonstrated the use of \ncount_\n and \ncountAll_\n which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.\n\n\nIn general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example, \nsum_\n\ncorresponds to the SQL aggregate \nSUM\n.\n\n\nSQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by \nOver\n. For example \nSUM(DISTINCT x)\n can be\nwritten \nsumOver_ distinctInGroup_ x\n. The universally quantified version of\neach aggregate is obtained by using the \nallInGroup_\n quantifier. Thus, \nsum_ ==\nsumOver_ allInGroup_\n. Because \nALL\n is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the \nallInGroupExplicitly_\n quantifier.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \naggregate_ (\\(genre, track) -\n\n              ( group_ genre\n              , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n              , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n           ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb))\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe \nbeam-core\n library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).\n\n\n\n\n\n\n\n\nSQL Aggregate\n\n\nRelevant standard\n\n\nUnquantified beam function\n\n\nQuantified beam function\n\n\n\n\n\n\n\n\n\n\nSUM\n\n\nSQL92\n\n\nsum_\n\n\nsumOver_\n\n\n\n\n\n\nMIN\n\n\nSQL92\n\n\nmin_\n\n\nminOver_\n\n\n\n\n\n\nMAX\n\n\nSQL92\n\n\nmax_\n\n\nmaxOver_\n\n\n\n\n\n\nAVG\n\n\nSQL92\n\n\navg_\n\n\navgOver_\n\n\n\n\n\n\nCOUNT(x)\n\n\nSQL92\n\n\ncount_\n\n\ncountOver_\n\n\n\n\n\n\nCOUNT(*)\n\n\nSQL92\n\n\ncountAll_\n\n\nN/A\n\n\n\n\n\n\nEVERY(x)\n\n\nSQL99\n\n\nevery_\n\n\neveryOver_\n\n\n\n\n\n\nANY(x)/SOME(x)\n\n\nSQL99\n\n\nany_\n, \nsome_\n\n\nanyOver_\n, \nsomeOver_\n\n\n\n\n\n\n\n\nThe \nHAVING\n clause\n\n\nSQL allows users to specify a \nHAVING\n condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports \nHAVIVG\n clauses, but does\nnot use any special syntax. Simply use \nfilter_\n or \nguard_\n as usual, and beam\nwill add a \nHAVING\n clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a \nWHERE\n clause. Either way, this is transparent to the user.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\nfilter_ (\\(genre, distinctPriceCount, totalTrackLength) -\n totalTrackLength \n=. 300000) $\naggregate_ (\\(genre, track) -\n\n              ( group_ genre\n              , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n              , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n           ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb))\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\nHAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nGenreId\n AS \nres0\n,\n       \nt0\n.\nName\n AS \nres1\n,\n       COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n       (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\nFROM \nGenre\n AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n\nGROUP BY \nt0\n.\nGenreId\n,\n         \nt0\n.\nName\n\nHAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000)) \n= (300000)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nBeam will also handle the \nfilter_\n correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\nfilter_ (\\(genre, track, distinctPriceCount, totalTrackLength) -\n totalTrackLength \n=. 300000) $\ndo (genre, priceCnt, trackLength) \n-\n            aggregate_ (\\(genre, track) -\n\n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb))\n   track \n- join_ (track chinookDb) (\\track -\n trackGenreId track ==. just_ (pk genre))\n   pure (genre, track, priceCnt, trackLength)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt1\n.\nTrackId\n AS \nres2\n,\n       \nt1\n.\nName\n AS \nres3\n,\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n       \nt1\n.\nGenreId\n AS \nres6\n,\n       \nt1\n.\nComposer\n AS \nres7\n,\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n       \nt1\n.\nBytes\n AS \nres9\n,\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n       \nt0\n.\nres2\n AS \nres11\n,\n       \nt0\n.\nres3\n AS \nres12\n\nFROM\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n) AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n)=(\nt0\n.\nres0\n)\nWHERE (\nt0\n.\nres3\n)\n=(?)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt1\n.\nTrackId\n AS \nres2\n,\n       \nt1\n.\nName\n AS \nres3\n,\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n       \nt1\n.\nGenreId\n AS \nres6\n,\n       \nt1\n.\nComposer\n AS \nres7\n,\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n       \nt1\n.\nBytes\n AS \nres9\n,\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n       \nt0\n.\nres2\n AS \nres11\n,\n       \nt0\n.\nres3\n AS \nres12\n\nFROM\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n) AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n) = (\nt0\n.\nres0\n)\nWHERE (\nt0\n.\nres3\n) \n= (300000)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nThe position of \nfilter_\n changes the code generated. Above, the \nfilter_\n\nproduced a \nWHERE\n clause on the outermost \nSELECT\n. If instead, we put the\n\nfilter_\n clause right outside the \naggregate_\n, beam will produce a \nHAVING\n clause instead.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\ndo (genre, priceCnt, trackLength) \n-\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -\n totalTrackLength \n=. 300000) $\n            aggregate_ (\\(genre, track) -\n\n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb))\n   track \n- join_ (track chinookDb) (\\track -\n trackGenreId track ==. just_ (pk genre))\n   pure (genre, track, priceCnt, trackLength)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt1\n.\nTrackId\n AS \nres2\n,\n       \nt1\n.\nName\n AS \nres3\n,\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n       \nt1\n.\nGenreId\n AS \nres6\n,\n       \nt1\n.\nComposer\n AS \nres7\n,\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n       \nt1\n.\nBytes\n AS \nres9\n,\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n       \nt0\n.\nres2\n AS \nres11\n,\n       \nt0\n.\nres3\n AS \nres12\n\nFROM\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n\n   HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?)) AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n)=(\nt0\n.\nres0\n)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n,\n       \nt1\n.\nTrackId\n AS \nres2\n,\n       \nt1\n.\nName\n AS \nres3\n,\n       \nt1\n.\nAlbumId\n AS \nres4\n,\n       \nt1\n.\nMediaTypeId\n AS \nres5\n,\n       \nt1\n.\nGenreId\n AS \nres6\n,\n       \nt1\n.\nComposer\n AS \nres7\n,\n       \nt1\n.\nMilliseconds\n AS \nres8\n,\n       \nt1\n.\nBytes\n AS \nres9\n,\n       \nt1\n.\nUnitPrice\n AS \nres10\n,\n       \nt0\n.\nres2\n AS \nres11\n,\n       \nt0\n.\nres3\n AS \nres12\n\nFROM\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n\n   HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000)) \n= (300000)) AS \nt0\n\nINNER JOIN \nTrack\n AS \nt1\n ON (\nt1\n.\nGenreId\n) = (\nt0\n.\nres0\n)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nDue to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\ndo track_ \n- all_ (track chinookDb)\n   (genre, priceCnt, trackLength) \n-\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -\n totalTrackLength \n=. 300000) $\n            aggregate_ (\\(genre, track) -\n\n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb)) \n   guard_ (trackGenreId track_ ==. just_ (pk genre))\n   pure (genre, track_, priceCnt, trackLength)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n       \nt1\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nTrackId\n AS \nres2\n,\n       \nt0\n.\nName\n AS \nres3\n,\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n       \nt0\n.\nGenreId\n AS \nres6\n,\n       \nt0\n.\nComposer\n AS \nres7\n,\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n       \nt0\n.\nBytes\n AS \nres9\n,\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n       \nt1\n.\nres2\n AS \nres11\n,\n       \nt1\n.\nres3\n AS \nres12\n\nFROM \nTrack\n AS \nt0\n\nINNER JOIN\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n) AS \nt1\n\nWHERE ((\nt1\n.\nres3\n)\n=(?))\n  AND ((\nt0\n.\nGenreId\n)=(\nt1\n.\nres0\n))\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n       \nt1\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nTrackId\n AS \nres2\n,\n       \nt0\n.\nName\n AS \nres3\n,\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n       \nt0\n.\nGenreId\n AS \nres6\n,\n       \nt0\n.\nComposer\n AS \nres7\n,\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n       \nt0\n.\nBytes\n AS \nres9\n,\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n       \nt1\n.\nres2\n AS \nres11\n,\n       \nt1\n.\nres3\n AS \nres12\n\nFROM \nTrack\n AS \nt0\n\nINNER JOIN\n  (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n          \nt0\n.\nName\n AS \nres1\n,\n          COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n          (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\n   FROM \nGenre\n AS \nt0\n\n   INNER JOIN \nTrack\n AS \nt1\n\n   GROUP BY \nt0\n.\nGenreId\n,\n            \nt0\n.\nName\n) AS \nt1\n\nWHERE ((\nt1\n.\nres3\n) \n= (300000))\n  AND ((\nt0\n.\nGenreId\n) = (\nt1\n.\nres0\n))\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nYou can prove to the compiler that the \nfilter_\n should generate a having by\nusing the \nsubselect_\n combinator.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \n-- Only return results for genres whose total track length is over 5 minutes\ndo track_ \n- all_ (track chinookDb)\n   (genre, priceCnt, trackLength) \n-\n            subselect_ $\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -\n totalTrackLength \n=. 300000) $\n            aggregate_ (\\(genre, track) -\n\n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,) \n$\n all_ (genre chinookDb) \n*\n all_ (track chinookDb)) \n   guard_ (trackGenreId track_ ==. just_ (pk genre))\n   pure (genre, track_, priceCnt, trackLength)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n       \nt1\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nTrackId\n AS \nres2\n,\n       \nt0\n.\nName\n AS \nres3\n,\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n       \nt0\n.\nGenreId\n AS \nres6\n,\n       \nt0\n.\nComposer\n AS \nres7\n,\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n       \nt0\n.\nBytes\n AS \nres9\n,\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n       \nt1\n.\nres2\n AS \nres11\n,\n       \nt1\n.\nres3\n AS \nres12\n\nFROM \nTrack\n AS \nt0\n\nINNER JOIN\n  (SELECT \nt0\n.\nres0\n AS \nres0\n,\n          \nt0\n.\nres1\n AS \nres1\n,\n          \nt0\n.\nres2\n AS \nres2\n,\n          \nt0\n.\nres3\n AS \nres3\n\n   FROM\n     (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n             \nt0\n.\nName\n AS \nres1\n,\n             COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n             (SUM(ALL \nt1\n.\nMilliseconds\n)) / (?) AS \nres3\n\n      FROM \nGenre\n AS \nt0\n\n      INNER JOIN \nTrack\n AS \nt1\n\n      GROUP BY \nt0\n.\nGenreId\n,\n               \nt0\n.\nName\n\n      HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (?))\n=(?)) AS \nt0\n) AS \nt1\n\nWHERE (\nt0\n.\nGenreId\n)=(\nt1\n.\nres0\n)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt1\n.\nres0\n AS \nres0\n,\n       \nt1\n.\nres1\n AS \nres1\n,\n       \nt0\n.\nTrackId\n AS \nres2\n,\n       \nt0\n.\nName\n AS \nres3\n,\n       \nt0\n.\nAlbumId\n AS \nres4\n,\n       \nt0\n.\nMediaTypeId\n AS \nres5\n,\n       \nt0\n.\nGenreId\n AS \nres6\n,\n       \nt0\n.\nComposer\n AS \nres7\n,\n       \nt0\n.\nMilliseconds\n AS \nres8\n,\n       \nt0\n.\nBytes\n AS \nres9\n,\n       \nt0\n.\nUnitPrice\n AS \nres10\n,\n       \nt1\n.\nres2\n AS \nres11\n,\n       \nt1\n.\nres3\n AS \nres12\n\nFROM \nTrack\n AS \nt0\n\nINNER JOIN\n  (SELECT \nt0\n.\nres0\n AS \nres0\n,\n          \nt0\n.\nres1\n AS \nres1\n,\n          \nt0\n.\nres2\n AS \nres2\n,\n          \nt0\n.\nres3\n AS \nres3\n\n   FROM\n     (SELECT \nt0\n.\nGenreId\n AS \nres0\n,\n             \nt0\n.\nName\n AS \nres1\n,\n             COUNT(DISTINCT \nt1\n.\nUnitPrice\n) AS \nres2\n,\n             (SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000) AS \nres3\n\n      FROM \nGenre\n AS \nt0\n\n      INNER JOIN \nTrack\n AS \nt1\n\n      GROUP BY \nt0\n.\nGenreId\n,\n               \nt0\n.\nName\n\n      HAVING ((SUM(ALL \nt1\n.\nMilliseconds\n)) / (1000)) \n= (300000)) AS \nt0\n) AS \nt1\n\nWHERE (\nt0\n.\nGenreId\n) = (\nt1\n.\nres0\n)", 
            "title": "Aggregates"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#simple-aggregate-usage", 
            "text": "Suppose we wanted to count the number of genres in our database.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_ (\\_ -  countAll_) (all_ (genre chinookDb)) \n         \n    \n         \n             SELECT COUNT(*) AS  res0 \nFROM  Genre  AS  t0  \n         \n    \n         \n             SELECT COUNT(*) AS  res0 \nFROM  Genre  AS  t0", 
            "title": "Simple aggregate usage"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#adding-a-group-by-clause", 
            "text": "Above, SQL used the default grouping, which puts all rows in one group. We can\nalso specify columns and expressions to group by. For example, if we wanted to\ncount the number of tracks for each genre, we can use the  group_  function to\ngroup by the genre.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_ (\\(genre, track) -  (group_ genre, as_ @Int $ count_ (trackId track)))\n           ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb)) \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT( t1 . TrackId ) AS  res2 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name  \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT( t1 . TrackId ) AS  res2 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name  \n         \n    \n         \n    \n                 \n                       Tip  count_  can return any  Integral  type. Adding the explicit  as_ @Int  above \nprevents an ambiguous type error.", 
            "title": "Adding a GROUP BY clause"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#sql-compatibility", 
            "text": "Above, we demonstrated the use of  count_  and  countAll_  which map to the\nappropriate SQL aggregates. Beam supports all of the other standard SQL92\naggregates.  In general, SQL aggregates are named similarly in beam and SQL. As usual, the\naggregate function in beam is suffixed by an underscore. For example,  sum_ \ncorresponds to the SQL aggregate  SUM .  SQL also allows you to specify set quantifiers for each aggregate. Beam supports\nthese as well. By convention, versions of aggregates that take in an optional\nset quantifier are suffixed by  Over . For example  SUM(DISTINCT x)  can be\nwritten  sumOver_ distinctInGroup_ x . The universally quantified version of\neach aggregate is obtained by using the  allInGroup_  quantifier. Thus,  sum_ ==\nsumOver_ allInGroup_ . Because  ALL  is the default set quantifier, beam does\nnot typically generate it in queries. If, for some reason, you would like beam\nto be explicit about it, you can use the  allInGroupExplicitly_  quantifier.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             aggregate_ (\\(genre, track) - \n              ( group_ genre\n              , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n              , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n           ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb)) \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n       (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name  \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n       (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name  \n         \n    \n         \n    \n                 \n                      The  beam-core  library supports the standard SQL aggregation functions.\nIndividual backends are likely to support the full range of aggregates available\non that backend (if not, please send a bug report).     SQL Aggregate  Relevant standard  Unquantified beam function  Quantified beam function      SUM  SQL92  sum_  sumOver_    MIN  SQL92  min_  minOver_    MAX  SQL92  max_  maxOver_    AVG  SQL92  avg_  avgOver_    COUNT(x)  SQL92  count_  countOver_    COUNT(*)  SQL92  countAll_  N/A    EVERY(x)  SQL99  every_  everyOver_    ANY(x)/SOME(x)  SQL99  any_ ,  some_  anyOver_ ,  someOver_", 
            "title": "SQL compatibility"
        }, 
        {
            "location": "/user-guide/queries/aggregates/#the-having-clause", 
            "text": "SQL allows users to specify a  HAVING  condition to filter results based on the\ncomputed result of an aggregate. Beam fully supports  HAVIVG  clauses, but does\nnot use any special syntax. Simply use  filter_  or  guard_  as usual, and beam\nwill add a  HAVING  clause if it forms legal SQL. Otherwise, beam will create a\nsubselect and add a  WHERE  clause. Either way, this is transparent to the user.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes\nfilter_ (\\(genre, distinctPriceCount, totalTrackLength) -  totalTrackLength  =. 300000) $\naggregate_ (\\(genre, track) - \n              ( group_ genre\n              , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n              , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n           ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb)) \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n       (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name \nHAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?) \n         \n    \n         \n             SELECT  t0 . GenreId  AS  res0 ,\n        t0 . Name  AS  res1 ,\n       COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n       (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \nFROM  Genre  AS  t0 \nINNER JOIN  Track  AS  t1 \nGROUP BY  t0 . GenreId ,\n          t0 . Name \nHAVING ((SUM(ALL  t1 . Milliseconds )) / (1000))  = (300000) \n         \n    \n         \n    \n                 \n                      Beam will also handle the  filter_  correctly in the presence of more\ncomplicated queries. For example, we can now join our aggregate on genres back\nover tracks.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes\nfilter_ (\\(genre, track, distinctPriceCount, totalTrackLength) -  totalTrackLength  =. 300000) $\ndo (genre, priceCnt, trackLength)  -\n            aggregate_ (\\(genre, track) - \n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb))\n   track  - join_ (track chinookDb) (\\track -  trackGenreId track ==. just_ (pk genre))\n   pure (genre, track, priceCnt, trackLength) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t1 . TrackId  AS  res2 ,\n        t1 . Name  AS  res3 ,\n        t1 . AlbumId  AS  res4 ,\n        t1 . MediaTypeId  AS  res5 ,\n        t1 . GenreId  AS  res6 ,\n        t1 . Composer  AS  res7 ,\n        t1 . Milliseconds  AS  res8 ,\n        t1 . Bytes  AS  res9 ,\n        t1 . UnitPrice  AS  res10 ,\n        t0 . res2  AS  res11 ,\n        t0 . res3  AS  res12 \nFROM\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name ) AS  t0 \nINNER JOIN  Track  AS  t1  ON ( t1 . GenreId )=( t0 . res0 )\nWHERE ( t0 . res3 ) =(?) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t1 . TrackId  AS  res2 ,\n        t1 . Name  AS  res3 ,\n        t1 . AlbumId  AS  res4 ,\n        t1 . MediaTypeId  AS  res5 ,\n        t1 . GenreId  AS  res6 ,\n        t1 . Composer  AS  res7 ,\n        t1 . Milliseconds  AS  res8 ,\n        t1 . Bytes  AS  res9 ,\n        t1 . UnitPrice  AS  res10 ,\n        t0 . res2  AS  res11 ,\n        t0 . res3  AS  res12 \nFROM\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name ) AS  t0 \nINNER JOIN  Track  AS  t1  ON ( t1 . GenreId ) = ( t0 . res0 )\nWHERE ( t0 . res3 )  = (300000) \n         \n    \n         \n    \n                 \n                      The position of  filter_  changes the code generated. Above, the  filter_ \nproduced a  WHERE  clause on the outermost  SELECT . If instead, we put the filter_  clause right outside the  aggregate_ , beam will produce a  HAVING  clause instead.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes\ndo (genre, priceCnt, trackLength)  -\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -  totalTrackLength  =. 300000) $\n            aggregate_ (\\(genre, track) - \n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb))\n   track  - join_ (track chinookDb) (\\track -  trackGenreId track ==. just_ (pk genre))\n   pure (genre, track, priceCnt, trackLength) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t1 . TrackId  AS  res2 ,\n        t1 . Name  AS  res3 ,\n        t1 . AlbumId  AS  res4 ,\n        t1 . MediaTypeId  AS  res5 ,\n        t1 . GenreId  AS  res6 ,\n        t1 . Composer  AS  res7 ,\n        t1 . Milliseconds  AS  res8 ,\n        t1 . Bytes  AS  res9 ,\n        t1 . UnitPrice  AS  res10 ,\n        t0 . res2  AS  res11 ,\n        t0 . res3  AS  res12 \nFROM\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name \n   HAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?)) AS  t0 \nINNER JOIN  Track  AS  t1  ON ( t1 . GenreId )=( t0 . res0 ) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 ,\n        t1 . TrackId  AS  res2 ,\n        t1 . Name  AS  res3 ,\n        t1 . AlbumId  AS  res4 ,\n        t1 . MediaTypeId  AS  res5 ,\n        t1 . GenreId  AS  res6 ,\n        t1 . Composer  AS  res7 ,\n        t1 . Milliseconds  AS  res8 ,\n        t1 . Bytes  AS  res9 ,\n        t1 . UnitPrice  AS  res10 ,\n        t0 . res2  AS  res11 ,\n        t0 . res3  AS  res12 \nFROM\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name \n   HAVING ((SUM(ALL  t1 . Milliseconds )) / (1000))  = (300000)) AS  t0 \nINNER JOIN  Track  AS  t1  ON ( t1 . GenreId ) = ( t0 . res0 ) \n         \n    \n         \n    \n                 \n                      Due to the monadic structure, putting the filtered aggregate as the second\nclause in the JOIN causes the HAVING to be floated out, because the compiler\ncan't prove that the conditional expression only depends on the results of the\naggregate.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes\ndo track_  - all_ (track chinookDb)\n   (genre, priceCnt, trackLength)  -\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -  totalTrackLength  =. 300000) $\n            aggregate_ (\\(genre, track) - \n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb)) \n   guard_ (trackGenreId track_ ==. just_ (pk genre))\n   pure (genre, track_, priceCnt, trackLength) \n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,\n        t1 . res1  AS  res1 ,\n        t0 . TrackId  AS  res2 ,\n        t0 . Name  AS  res3 ,\n        t0 . AlbumId  AS  res4 ,\n        t0 . MediaTypeId  AS  res5 ,\n        t0 . GenreId  AS  res6 ,\n        t0 . Composer  AS  res7 ,\n        t0 . Milliseconds  AS  res8 ,\n        t0 . Bytes  AS  res9 ,\n        t0 . UnitPrice  AS  res10 ,\n        t1 . res2  AS  res11 ,\n        t1 . res3  AS  res12 \nFROM  Track  AS  t0 \nINNER JOIN\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name ) AS  t1 \nWHERE (( t1 . res3 ) =(?))\n  AND (( t0 . GenreId )=( t1 . res0 )) \n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,\n        t1 . res1  AS  res1 ,\n        t0 . TrackId  AS  res2 ,\n        t0 . Name  AS  res3 ,\n        t0 . AlbumId  AS  res4 ,\n        t0 . MediaTypeId  AS  res5 ,\n        t0 . GenreId  AS  res6 ,\n        t0 . Composer  AS  res7 ,\n        t0 . Milliseconds  AS  res8 ,\n        t0 . Bytes  AS  res9 ,\n        t0 . UnitPrice  AS  res10 ,\n        t1 . res2  AS  res11 ,\n        t1 . res3  AS  res12 \nFROM  Track  AS  t0 \nINNER JOIN\n  (SELECT  t0 . GenreId  AS  res0 ,\n           t0 . Name  AS  res1 ,\n          COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n          (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \n   FROM  Genre  AS  t0 \n   INNER JOIN  Track  AS  t1 \n   GROUP BY  t0 . GenreId ,\n             t0 . Name ) AS  t1 \nWHERE (( t1 . res3 )  = (300000))\n  AND (( t0 . GenreId ) = ( t1 . res0 )) \n         \n    \n         \n    \n                 \n                      You can prove to the compiler that the  filter_  should generate a having by\nusing the  subselect_  combinator.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             -- Only return results for genres whose total track length is over 5 minutes\ndo track_  - all_ (track chinookDb)\n   (genre, priceCnt, trackLength)  -\n            subselect_ $\n            filter_ (\\(genre, distinctPriceCount, totalTrackLength) -  totalTrackLength  =. 300000) $\n            aggregate_ (\\(genre, track) - \n                          ( group_ genre\n                          , as_ @Int $ countOver_ distinctInGroup_ (trackUnitPrice track)\n                          , sumOver_ allInGroupExplicitly_ (trackMilliseconds track) `div_` 1000 )) $\n            ((,)  $  all_ (genre chinookDb)  *  all_ (track chinookDb)) \n   guard_ (trackGenreId track_ ==. just_ (pk genre))\n   pure (genre, track_, priceCnt, trackLength) \n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,\n        t1 . res1  AS  res1 ,\n        t0 . TrackId  AS  res2 ,\n        t0 . Name  AS  res3 ,\n        t0 . AlbumId  AS  res4 ,\n        t0 . MediaTypeId  AS  res5 ,\n        t0 . GenreId  AS  res6 ,\n        t0 . Composer  AS  res7 ,\n        t0 . Milliseconds  AS  res8 ,\n        t0 . Bytes  AS  res9 ,\n        t0 . UnitPrice  AS  res10 ,\n        t1 . res2  AS  res11 ,\n        t1 . res3  AS  res12 \nFROM  Track  AS  t0 \nINNER JOIN\n  (SELECT  t0 . res0  AS  res0 ,\n           t0 . res1  AS  res1 ,\n           t0 . res2  AS  res2 ,\n           t0 . res3  AS  res3 \n   FROM\n     (SELECT  t0 . GenreId  AS  res0 ,\n              t0 . Name  AS  res1 ,\n             COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n             (SUM(ALL  t1 . Milliseconds )) / (?) AS  res3 \n      FROM  Genre  AS  t0 \n      INNER JOIN  Track  AS  t1 \n      GROUP BY  t0 . GenreId ,\n                t0 . Name \n      HAVING ((SUM(ALL  t1 . Milliseconds )) / (?)) =(?)) AS  t0 ) AS  t1 \nWHERE ( t0 . GenreId )=( t1 . res0 ) \n         \n    \n         \n             SELECT  t1 . res0  AS  res0 ,\n        t1 . res1  AS  res1 ,\n        t0 . TrackId  AS  res2 ,\n        t0 . Name  AS  res3 ,\n        t0 . AlbumId  AS  res4 ,\n        t0 . MediaTypeId  AS  res5 ,\n        t0 . GenreId  AS  res6 ,\n        t0 . Composer  AS  res7 ,\n        t0 . Milliseconds  AS  res8 ,\n        t0 . Bytes  AS  res9 ,\n        t0 . UnitPrice  AS  res10 ,\n        t1 . res2  AS  res11 ,\n        t1 . res3  AS  res12 \nFROM  Track  AS  t0 \nINNER JOIN\n  (SELECT  t0 . res0  AS  res0 ,\n           t0 . res1  AS  res1 ,\n           t0 . res2  AS  res2 ,\n           t0 . res3  AS  res3 \n   FROM\n     (SELECT  t0 . GenreId  AS  res0 ,\n              t0 . Name  AS  res1 ,\n             COUNT(DISTINCT  t1 . UnitPrice ) AS  res2 ,\n             (SUM(ALL  t1 . Milliseconds )) / (1000) AS  res3 \n      FROM  Genre  AS  t0 \n      INNER JOIN  Track  AS  t1 \n      GROUP BY  t0 . GenreId ,\n                t0 . Name \n      HAVING ((SUM(ALL  t1 . Milliseconds )) / (1000))  = (300000)) AS  t0 ) AS  t1 \nWHERE ( t0 . GenreId ) = ( t1 . res0 )", 
            "title": "The HAVING clause"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/", 
            "text": "SQL lets you combine the results of multiple \nSELECT\n statements using the\n\nUNION\n, \nINTERSECT\n, and \nEXCEPT\n clauses.\n\n\nSQL Set operations\n\n\nThe SQL Set operations are provided as the \nunion_\n, \nintersect_\n, and \nexcept_\n\nfunctions. SQL also allows an optional \nALL\n clause to be specified with each of\nthese. Beam implements these as \nunionAll_\n, \nintersectAll_\n, and \nexceptAll_\n\nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.\n\n\nFor example, suppose we wanted the first and last names of both customers and\nemployees.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet customerNames =\n      fmap (\\c -\n (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -\n (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin union_ customerNames employeeNames\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n       \nt0\n.\nLastName\n AS \nres1\n\nFROM \nCustomer\n AS \nt0\n\nUNION\nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n       \nt0\n.\nLastName\n AS \nres1\n\nFROM \nEmployee\n AS \nt0\n\n\n\n        \n\n    \n        \n\n            \n\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nCustomer\n AS \nt0\n)\nUNION\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nEmployee\n AS \nt0\n)\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nCombining arbitrary set expressions\n\n\nSuppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use \nUNION\n to combine the\nresults of a query over the first names of employees and customers, and an\n\nEXCEPT\n to get all customer last names that were not employee ones. Finally, an\n\nINTERSECT\n would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.\n\n\nOn backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.\n\n\n\n\nTODO\n\n\nThis isn't implemented yet :)\n\n\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet customerFirstNames =\n      fmap customerFirstName\n           (all_ (customer chinookDb))\n    employeeFirstNames =\n      fmap employeeFirstName\n           (all_ (employee chinookDb))\n    customerLastNames =\n      fmap customerLastName\n           (all_ (customer chinookDb))\n    employeeLastNames =\n      fmap employeeFirstName\n           (all_ (employee chinookDb))\nin (customerFirstNames `union_`employeeFirstNames) `intersect_`\n   (customerLastNames `except_` employeeLastNames)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nFirstName\n AS \nres0\n\nFROM \nCustomer\n AS \nt0\n\nUNION\nSELECT \nt0\n.\nFirstName\n AS \nres0\n\nFROM \nEmployee\n AS \nt0\n INTERSECT\nSELECT \nt0\n.\nLastName\n AS \nres0\n\nFROM \nCustomer\n AS \nt0\n\nEXCEPT\nSELECT \nt0\n.\nFirstName\n AS \nres0\n\nFROM \nEmployee\n AS \nt0\n\n\n\n        \n\n    \n        \n\n            \n(\n   (SELECT \nt0\n.\nFirstName\n AS \nres0\n\n    FROM \nCustomer\n AS \nt0\n)\n UNION\n   (SELECT \nt0\n.\nFirstName\n AS \nres0\n\n    FROM \nEmployee\n AS \nt0\n)) INTERSECT (\n                                           (SELECT \nt0\n.\nLastName\n AS \nres0\n\n                                            FROM \nCustomer\n AS \nt0\n)\n                                         EXCEPT\n                                           (SELECT \nt0\n.\nFirstName\n AS \nres0\n\n                                            FROM \nEmployee\n AS \nt0\n))\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nLIMIT\n/\nOFFSET\n and set operations\n\n\nThe \nLIMIT\n and \nOFFSET\n clauses generated by \nlimit_\n and \noffset_\n apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the \nLIMIT\n and \nOFFSET\n at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.\n\n\nFor example, to get the second ten full names in common.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet customerNames =\n      fmap (\\c -\n (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -\n (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin limit_ 10 (union_ customerNames employeeNames)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n       \nt0\n.\nLastName\n AS \nres1\n\nFROM \nCustomer\n AS \nt0\n\nUNION\nSELECT \nt0\n.\nFirstName\n AS \nres0\n,\n       \nt0\n.\nLastName\n AS \nres1\n\nFROM \nEmployee\n AS \nt0\n\nLIMIT 10\n\n\n        \n\n    \n        \n\n            \n\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nCustomer\n AS \nt0\n)\nUNION\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nEmployee\n AS \nt0\n)\nLIMIT 10\n\n\n        \n\n    \n        \n\n    \n                \n\n                    \n\n\nIf we only wanted the union of the first 10 names of each.\n\n\n\n                \n\n                    \n        \n\n            \n        \n\n            \nHaskell\n\n        \n\n    \n        \n\n            \nSqlite3\n\n        \n\n    \n        \n\n            \nPostgres\n\n        \n\n    \n        \n\n    \n        \n\n            \n        \n\n            \nlet customerNames =\n      fmap (\\c -\n (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -\n (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin union_ (limit_ 10 customerNames) (limit_ 10 employeeNames)\n\n\n        \n\n    \n        \n\n            \nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n\nFROM\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nCustomer\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\nUNION\nSELECT \nt0\n.\nres0\n AS \nres0\n,\n       \nt0\n.\nres1\n AS \nres1\n\nFROM\n  (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n          \nt0\n.\nLastName\n AS \nres1\n\n   FROM \nEmployee\n AS \nt0\n\n   LIMIT 10) AS \nt0\n\n\n\n        \n\n    \n        \n\n            \n\n  (SELECT \nt0\n.\nres0\n AS \nres0\n,\n          \nt0\n.\nres1\n AS \nres1\n\n   FROM\n     (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n             \nt0\n.\nLastName\n AS \nres1\n\n      FROM \nCustomer\n AS \nt0\n\n      LIMIT 10) AS \nt0\n)\nUNION\n  (SELECT \nt0\n.\nres0\n AS \nres0\n,\n          \nt0\n.\nres1\n AS \nres1\n\n   FROM\n     (SELECT \nt0\n.\nFirstName\n AS \nres0\n,\n             \nt0\n.\nLastName\n AS \nres1\n\n      FROM \nEmployee\n AS \nt0\n\n      LIMIT 10) AS \nt0\n)", 
            "title": "Combining queries"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#sql-set-operations", 
            "text": "The SQL Set operations are provided as the  union_ ,  intersect_ , and  except_ \nfunctions. SQL also allows an optional  ALL  clause to be specified with each of\nthese. Beam implements these as  unionAll_ ,  intersectAll_ , and  exceptAll_ \nrespectively. Each combinator takes two queries as arguments. The results of\nboth queries will be combined accordingly. The returned type is the same as the\ntype of both query arguments, which must be the same.  For example, suppose we wanted the first and last names of both customers and\nemployees.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let customerNames =\n      fmap (\\c -  (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -  (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin union_ customerNames employeeNames \n         \n    \n         \n             SELECT  t0 . FirstName  AS  res0 ,\n        t0 . LastName  AS  res1 \nFROM  Customer  AS  t0 \nUNION\nSELECT  t0 . FirstName  AS  res0 ,\n        t0 . LastName  AS  res1 \nFROM  Employee  AS  t0  \n         \n    \n         \n             \n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Customer  AS  t0 )\nUNION\n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Employee  AS  t0 )", 
            "title": "SQL Set operations"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#combining-arbitrary-set-expressions", 
            "text": "Suppose we wanted all employee and customer first names that were also customer\nlast names but not also employee last names. We could use  UNION  to combine the\nresults of a query over the first names of employees and customers, and an EXCEPT  to get all customer last names that were not employee ones. Finally, an INTERSECT  would give us the result we want. The beam query language allows\nthis and many popular backends do as well, but standard SQL makes it difficult\nto express. Beam has decided to go with the most common implement solution,\nwhich is to allow such nesting. This simplifies the API design.  On backends which allow such nesting (like Postgres), the query is translated\ndirectly. On backends that do not (like SQLite), an appropriate subselect is\ngenerated.   TODO  This isn't implemented yet :)   \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let customerFirstNames =\n      fmap customerFirstName\n           (all_ (customer chinookDb))\n    employeeFirstNames =\n      fmap employeeFirstName\n           (all_ (employee chinookDb))\n    customerLastNames =\n      fmap customerLastName\n           (all_ (customer chinookDb))\n    employeeLastNames =\n      fmap employeeFirstName\n           (all_ (employee chinookDb))\nin (customerFirstNames `union_`employeeFirstNames) `intersect_`\n   (customerLastNames `except_` employeeLastNames) \n         \n    \n         \n             SELECT  t0 . FirstName  AS  res0 \nFROM  Customer  AS  t0 \nUNION\nSELECT  t0 . FirstName  AS  res0 \nFROM  Employee  AS  t0  INTERSECT\nSELECT  t0 . LastName  AS  res0 \nFROM  Customer  AS  t0 \nEXCEPT\nSELECT  t0 . FirstName  AS  res0 \nFROM  Employee  AS  t0  \n         \n    \n         \n             (\n   (SELECT  t0 . FirstName  AS  res0 \n    FROM  Customer  AS  t0 )\n UNION\n   (SELECT  t0 . FirstName  AS  res0 \n    FROM  Employee  AS  t0 )) INTERSECT (\n                                           (SELECT  t0 . LastName  AS  res0 \n                                            FROM  Customer  AS  t0 )\n                                         EXCEPT\n                                           (SELECT  t0 . FirstName  AS  res0 \n                                            FROM  Employee  AS  t0 ))", 
            "title": "Combining arbitrary set expressions"
        }, 
        {
            "location": "/user-guide/queries/combining-queries/#limitoffset-and-set-operations", 
            "text": "The  LIMIT  and  OFFSET  clauses generated by  limit_  and  offset_  apply to\nthe entire result of the set operation. Beam will correctly generate the query\nyou specify, placing the  LIMIT  and  OFFSET  at the appropriate point. If\nnecessary, it will also generate a sub select to preserve the meaning of the\nquery.  For example, to get the second ten full names in common.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let customerNames =\n      fmap (\\c -  (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -  (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin limit_ 10 (union_ customerNames employeeNames) \n         \n    \n         \n             SELECT  t0 . FirstName  AS  res0 ,\n        t0 . LastName  AS  res1 \nFROM  Customer  AS  t0 \nUNION\nSELECT  t0 . FirstName  AS  res0 ,\n        t0 . LastName  AS  res1 \nFROM  Employee  AS  t0 \nLIMIT 10 \n         \n    \n         \n             \n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Customer  AS  t0 )\nUNION\n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Employee  AS  t0 )\nLIMIT 10 \n         \n    \n         \n    \n                 \n                      If we only wanted the union of the first 10 names of each.  \n                 \n                    \n         \n            \n         \n             Haskell \n         \n    \n         \n             Sqlite3 \n         \n    \n         \n             Postgres \n         \n    \n         \n    \n         \n            \n         \n             let customerNames =\n      fmap (\\c -  (customerFirstName c, customerLastName c))\n           (all_ (customer chinookDb))\n    employeeNames =\n      fmap (\\e -  (employeeFirstName e, employeeLastName e))\n           (all_ (employee chinookDb))\nin union_ (limit_ 10 customerNames) (limit_ 10 employeeNames) \n         \n    \n         \n             SELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 \nFROM\n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Customer  AS  t0 \n   LIMIT 10) AS  t0 \nUNION\nSELECT  t0 . res0  AS  res0 ,\n        t0 . res1  AS  res1 \nFROM\n  (SELECT  t0 . FirstName  AS  res0 ,\n           t0 . LastName  AS  res1 \n   FROM  Employee  AS  t0 \n   LIMIT 10) AS  t0  \n         \n    \n         \n             \n  (SELECT  t0 . res0  AS  res0 ,\n           t0 . res1  AS  res1 \n   FROM\n     (SELECT  t0 . FirstName  AS  res0 ,\n              t0 . LastName  AS  res1 \n      FROM  Customer  AS  t0 \n      LIMIT 10) AS  t0 )\nUNION\n  (SELECT  t0 . res0  AS  res0 ,\n           t0 . res1  AS  res1 \n   FROM\n     (SELECT  t0 . FirstName  AS  res0 ,\n              t0 . LastName  AS  res1 \n      FROM  Employee  AS  t0 \n      LIMIT 10) AS  t0 )", 
            "title": "LIMIT/OFFSET and set operations"
        }, 
        {
            "location": "/user-guide/queries/data-types/", 
            "text": "data types", 
            "title": "Common data types"
        }, 
        {
            "location": "/user-guide/queries/window-functions/", 
            "text": "window functions", 
            "title": "Window functions"
        }, 
        {
            "location": "/schema-guide/migrations/", 
            "text": "In the User Guide we saw how to declare a schema for an already created database\nand use it to perform queries. Beam can also manage a database schema based on\nHaskell datatypes you feed it.\n\n\nThe Beam Migrations Framework is meant to be a robust, modular, and opinionated\nway of managing schema changes. It is an optional part of beam provided in the\n\nbeam-migrate\n package.\n\n\nInstall the migrations framework and tool by running\n\n\n$ cabal install beam-migrate\n# or\n$ stack install beam-migrate\n\n\n\n\nIf you use \nstack\n make sure you always use \nstack exec -- beam-migrate\n instead\nof the typical \nbeam-migrate\n command in order to have the package path\nautomatically and correctly set for you.\n\n\nThe Opinions\n\n\nAs stated above, \nbeam-migrate\n is an \nopinionated\n migrations framework. It\nspecifies a precise way to lay out your schema definitions.\n\n\nYou can use the \nbeam-migrate new \nmodule-name\n \ndb-type\n command to create a new\nmigration schema module. This will create the following directory structure\n\n\nmodule-name\n.hs\n\nmodule-name\n/V0001.hs\n\n\n\n\nIf you open up \nmodule-name\n.hs\n, it will contain the following\n\n\nmodule \nmodule-name\n ( module \nmodule-name\n.V0001, db, migration ) where\n\nimport Database.Beam\n\nimport qualified \nmodule-name\n.V0001 as V0001\n\ndb :: DatabaseSettings be \ndb-type\n\ndb = V0001.db\n\nmigration :: MigrationSteps be \ndb-type\n\nmigration = migrationStep \nInitial schema\n V0001.migration\n\n\n\n\nIf you specify the \n--backend\n option while running \nbeam-migrate new\n, your\nschema will be specialized to the specific backend.\n\n\nWhen you create a new version of your schema, you will \nnot\n delete the old one.\nInstead, you will copy it, increase the version number, make your changes to the\ndatabase schema, write an appropriate migration, and then update the top-level\nmodule to use the newest schema and invoke the latest migration.", 
            "title": "The Migrations Framework"
        }, 
        {
            "location": "/schema-guide/migrations/#the-opinions", 
            "text": "As stated above,  beam-migrate  is an  opinionated  migrations framework. It\nspecifies a precise way to lay out your schema definitions.  You can use the  beam-migrate new  module-name   db-type  command to create a new\nmigration schema module. This will create the following directory structure  module-name .hs module-name /V0001.hs  If you open up  module-name .hs , it will contain the following  module  module-name  ( module  module-name .V0001, db, migration ) where\n\nimport Database.Beam\n\nimport qualified  module-name .V0001 as V0001\n\ndb :: DatabaseSettings be  db-type \ndb = V0001.db\n\nmigration :: MigrationSteps be  db-type \nmigration = migrationStep  Initial schema  V0001.migration  If you specify the  --backend  option while running  beam-migrate new , your\nschema will be specialized to the specific backend.  When you create a new version of your schema, you will  not  delete the old one.\nInstead, you will copy it, increase the version number, make your changes to the\ndatabase schema, write an appropriate migration, and then update the top-level\nmodule to use the newest schema and invoke the latest migration.", 
            "title": "The Opinions"
        }, 
        {
            "location": "/schema-guide/tool/", 
            "text": "Tool", 
            "title": "The beam-migrate tool"
        }, 
        {
            "location": "/schema-guide/supported/", 
            "text": "supported", 
            "title": "Supported migrations"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/", 
            "text": "The \nbeam-postgres\n backend is the most feature complete SQL backend for beam.\nThe Postgres RDBMS supports most of the standards beam follows, so you can\nusually expect most queries to simply work. Additionally, \nbeam-postgres\n is\npart of the standard Beam distribution, and so upgrades are applied\nperiodically, and new functions are added to achieve feature-parity with the\nlatest Postgres stable\n\n\nPostgres-specific data types\n\n\nPostgres has several data types not available from \nbeam-core\n. The\n\nbeam-postgres\n library provides several types and functions to make working\nwith these easier.\n\n\nThe \ntsvector\n and \ntsquery\n types\n\n\nThe \ntsvector\n and \ntsquery\n types form the basis of full-text search in\nPostgres.", 
            "title": "beam-postgres"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#postgres-specific-data-types", 
            "text": "Postgres has several data types not available from  beam-core . The beam-postgres  library provides several types and functions to make working\nwith these easier.", 
            "title": "Postgres-specific data types"
        }, 
        {
            "location": "/user-guide/backends/beam-postgres/#the-tsvector-and-tsquery-types", 
            "text": "The  tsvector  and  tsquery  types form the basis of full-text search in\nPostgres.", 
            "title": "The tsvector and tsquery types"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/", 
            "text": "SQLite is a lightweight RDBMS meant for embedding in larger applications.\nBecause it is not designed to be full-featured, not all Beam queries will work\nwith SQLite. The module \nDatabase.Beam.SQLite.Checked\n provides many symbols\nusually imported from the \nDatabase.Beam\n module that enforce extra checks on\nqueries to assure compliance with SQLite. Use this module in code that is SQLite\nspecific for maximal compile-time safety. Note that this module should be\nimported instead of \nDatabase.Beam\n to avoid name clashes.\n\n\nCompatibility\n\n\nSQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "beam-sqlite"
        }, 
        {
            "location": "/user-guide/backends/beam-sqlite/#compatibility", 
            "text": "SQLite is compatible enough with Beam's query syntax, that adapting to its\nquirks is pretty straightforwards. The main special case for SQLite is its\nhandling of nested set operations. On most backends, beam can output these\ndirectly, but SQLite requires us to generate subqueries.", 
            "title": "Compatibility"
        }, 
        {
            "location": "/user-guide/custom-backends/", 
            "text": "Writing a custom backend", 
            "title": "Writing a Custom Backend"
        }, 
        {
            "location": "/reference/expression/", 
            "text": "Typing\n\n\nThe type of all SQL-level expressions is \nQGenExpr\n. See the \nquery tutorial\n for more information.\n\n\nIn many cases, you'd like to type the SQL-level result of an expression without\nhaving to give explicit types for the other \nQGenExpr\n parameters. You can do\nthis with the \nas_\n combinator and \n-XTypeApplications\n.\n\n\nThe following code types the literal 1 as a \nDouble\n.\n\n\nas_ @Double 1\n\n\n\n\nThis is rarely needed, but there are a few cases where the beam types are too\ngeneral for the compiler to meaningfully infer types.\n\n\nLiterals\n\n\n\n\nInteger literals\n can be constructed using \nfromIntegral\n in the \nNum\n\n  typeclass. This means you can also just use a Haskell integer literal as a\n  \nQGenExpr\n in any context.\n\n\nRational literals\n can be constructed via \nfromRational\n in \nRational\n.\n  Regular Haskell rational literals will be automatically converted to\n  \nQGenExprs\n.\n\n\nText literals\n can be constructed via \nfromString\n in \nIsString\n. Again,\n  Haskell string constants will automaticall be converted to \nQGenExprs\n,\n  although you may have to provide an explicit type, as different backends\n  support different text types natively.\n\n\nAll other literals\n can be constructed using the \nval_\n function in\n  \nSqlValable\n. This requires that there is an implementation of\n  \nHasSqlValueSyntax (Sql92ExpressionValueSyntax syntax) x\n for the type \nx\n in\n  the appropriate \nsyntax\n for the \nQGenExpr\n. For example, to construct a value\n  of type \nVector Int\n in the \nbeam-postgres\n backend.\n\n\n\n\nval_ (V.fromList [1, 2, 3 :: Int])\n\n\n\n\n\n\nExplicit tables\n can be brought to the SQL value level by using \nval_\n as\n  well. For example, if you have an \nAddressT Identity\n named \na\n, \nval_ a ::\n  AddressT (QGenExpr context expr s)\n.\n\n\n\n\nArithmetic\n\n\nArithmetic operations that are part of the \nFractional\n and \nNum\n classes can be\nused directly. For example, if \na\n and \nb\n are \nQGenExpr\ns of the same type,\nthen \na + b\n is a \nQGenExpr\n of the same type.\n\n\nBecause of the \ntoInteger\n class method in \nIntegral\n, \nQGenExpr\ns cannot\nimplement \nIntegral\n. Nevertheless, versions of \ndiv\n and \nmod\n are available as\n\ndiv_\n and \nmod_\n, respectively, having the corresponding type.\n\n\nCASE .. WHEN .. ELSE ..\n statements\n\n\nThe SQL \nCASE .. WHEN .. ELSE\n construct can be used to implement a multi-way\nif. The corresponding beam syntax is\n\n\nif_ [ cond1 `then_` result1, cond2 `then_` result2, ... ] (else_ elseResult)\n\n\n\n\nwhere \ncond\nn\n are \nQGenExpr\n of type \nBool\n, and \nresult1\n, \nresult2\n, and\n\nelseResult\n are \nQGenExprs\n of the same type.\n\n\nSQL Functions and operators\n\n\n\n\n\n\n\n\nSQL construct\n\n\nSQL standard\n\n\nBeam equivalent\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nEXISTS (x)\n\n\nSQL92\n\n\nexists_ x\n\n\nHere, \nx\n is any query (of type \nQ\n)\n\n\n\n\n\n\nUNIQUE (x)\n\n\nSQL92\n\n\nunique_ x\n\n\nSee note for \nEXISTS (x)\n\n\n\n\n\n\nDISTINCT (x)\n\n\nSQL99\n\n\ndistinct_ x\n\n\nSee note for \nEXISTS (x)\n\n\n\n\n\n\nSELECT .. FROM ...\n \n as an expression (subqueries)\n\n\nSQL92\n\n\nsubquery_ x\n\n\nx\n is an query (of type \nQ\n)\n\n\n\n\n\n\nCOALESCE(a, b, c, ...)\n\n\nSQL92\n\n\ncoalesce_ [a, b, c, ...]\n\n\na\n, \nb\n, and \nc\n must be of \ntype \nMaybe a\n.\nThe result has type \na\n\n\n\n\n\n\na BETWEEN b AND c\n\n\nSQL92\n\n\nbetween_ a b c\n\n\n\n\n\n\n\n\na LIKE b\n\n\nSQL92\n\n\na `like_` b\n\n\na\n and \nb\n should be string types\n\n\n\n\n\n\na SIMILAR TO b\n\n\nSQL99\n\n\na `similarTo_` b\n\n\nSee note for \nLIKE\n\n\n\n\n\n\nPOSITION(x IN y)\n\n\nSQL92\n\n\nposition_ x y\n\n\nx\n and \ny\n should be string types\n\n\n\n\n\n\nCHAR_LENGTH(x)\n\n\nSQL92\n\n\ncharLength_ x\n\n\n\n\n\n\n\n\nOCTET_LENGTH(x)\n\n\nSQL92\n\n\noctetLength_ x\n\n\n\n\n\n\n\n\nBIT_LENGTH(x)\n\n\nSQL92\n\n\nbitLength_ x\n\n\nx\n must be of the beam-specific \nSqlBitString\n type\n\n\n\n\n\n\nx IS TRUE\n / \nx IS NOT TRUE\n\n\nSQL92\n\n\nisTrue_ x\n / \nisNotTrue_ x\n\n\n\n\n\n\n\n\nx IS FALSE\n / \nx IS NOT FALSE\n\n\nSQL92\n\n\nisFalse_ x\n / \nisNotFalse_ x\n\n\n\n\n\n\n\n\nx IS UNKNOWN\n / \nx IS NOT UNKNOWN\n\n\nSQL92\n\n\nisUnknown_ x\n / \nisNotUnknown_ x\n\n\n\n\n\n\n\n\nNOT x\n\n\nSQL92\n\n\nnot_ x\n\n\n\n\n\n\n\n\n\n\nMy favorite operator / function isn't listed here!\n\n\nIf your favorite operator or function is not provided here, first ask yourself\nif it is part of any SQL standard. If it is not, then check the backend you are\nusing to see if it provides a corresponding construct. If the backend does not\nor if the function / operator you need is part of a SQL standard, please open an\nissue on GitHub. Alternatively, implement the construct yourself and send us a\npull request! See the section on \nadding your own functions", 
            "title": "Expressions"
        }, 
        {
            "location": "/reference/expression/#typing", 
            "text": "The type of all SQL-level expressions is  QGenExpr . See the  query tutorial  for more information.  In many cases, you'd like to type the SQL-level result of an expression without\nhaving to give explicit types for the other  QGenExpr  parameters. You can do\nthis with the  as_  combinator and  -XTypeApplications .  The following code types the literal 1 as a  Double .  as_ @Double 1  This is rarely needed, but there are a few cases where the beam types are too\ngeneral for the compiler to meaningfully infer types.", 
            "title": "Typing"
        }, 
        {
            "location": "/reference/expression/#literals", 
            "text": "Integer literals  can be constructed using  fromIntegral  in the  Num \n  typeclass. This means you can also just use a Haskell integer literal as a\n   QGenExpr  in any context.  Rational literals  can be constructed via  fromRational  in  Rational .\n  Regular Haskell rational literals will be automatically converted to\n   QGenExprs .  Text literals  can be constructed via  fromString  in  IsString . Again,\n  Haskell string constants will automaticall be converted to  QGenExprs ,\n  although you may have to provide an explicit type, as different backends\n  support different text types natively.  All other literals  can be constructed using the  val_  function in\n   SqlValable . This requires that there is an implementation of\n   HasSqlValueSyntax (Sql92ExpressionValueSyntax syntax) x  for the type  x  in\n  the appropriate  syntax  for the  QGenExpr . For example, to construct a value\n  of type  Vector Int  in the  beam-postgres  backend.   val_ (V.fromList [1, 2, 3 :: Int])   Explicit tables  can be brought to the SQL value level by using  val_  as\n  well. For example, if you have an  AddressT Identity  named  a ,  val_ a ::\n  AddressT (QGenExpr context expr s) .", 
            "title": "Literals"
        }, 
        {
            "location": "/reference/expression/#arithmetic", 
            "text": "Arithmetic operations that are part of the  Fractional  and  Num  classes can be\nused directly. For example, if  a  and  b  are  QGenExpr s of the same type,\nthen  a + b  is a  QGenExpr  of the same type.  Because of the  toInteger  class method in  Integral ,  QGenExpr s cannot\nimplement  Integral . Nevertheless, versions of  div  and  mod  are available as div_  and  mod_ , respectively, having the corresponding type.", 
            "title": "Arithmetic"
        }, 
        {
            "location": "/reference/expression/#case-when-else-statements", 
            "text": "The SQL  CASE .. WHEN .. ELSE  construct can be used to implement a multi-way\nif. The corresponding beam syntax is  if_ [ cond1 `then_` result1, cond2 `then_` result2, ... ] (else_ elseResult)  where  cond n  are  QGenExpr  of type  Bool , and  result1 ,  result2 , and elseResult  are  QGenExprs  of the same type.", 
            "title": "CASE .. WHEN .. ELSE .. statements"
        }, 
        {
            "location": "/reference/expression/#sql-functions-and-operators", 
            "text": "SQL construct  SQL standard  Beam equivalent  Notes      EXISTS (x)  SQL92  exists_ x  Here,  x  is any query (of type  Q )    UNIQUE (x)  SQL92  unique_ x  See note for  EXISTS (x)    DISTINCT (x)  SQL99  distinct_ x  See note for  EXISTS (x)    SELECT .. FROM ...    as an expression (subqueries)  SQL92  subquery_ x  x  is an query (of type  Q )    COALESCE(a, b, c, ...)  SQL92  coalesce_ [a, b, c, ...]  a ,  b , and  c  must be of  type  Maybe a . The result has type  a    a BETWEEN b AND c  SQL92  between_ a b c     a LIKE b  SQL92  a `like_` b  a  and  b  should be string types    a SIMILAR TO b  SQL99  a `similarTo_` b  See note for  LIKE    POSITION(x IN y)  SQL92  position_ x y  x  and  y  should be string types    CHAR_LENGTH(x)  SQL92  charLength_ x     OCTET_LENGTH(x)  SQL92  octetLength_ x     BIT_LENGTH(x)  SQL92  bitLength_ x  x  must be of the beam-specific  SqlBitString  type    x IS TRUE  /  x IS NOT TRUE  SQL92  isTrue_ x  /  isNotTrue_ x     x IS FALSE  /  x IS NOT FALSE  SQL92  isFalse_ x  /  isNotFalse_ x     x IS UNKNOWN  /  x IS NOT UNKNOWN  SQL92  isUnknown_ x  /  isNotUnknown_ x     NOT x  SQL92  not_ x", 
            "title": "SQL Functions and operators"
        }, 
        {
            "location": "/reference/expression/#my-favorite-operator-function-isnt-listed-here", 
            "text": "If your favorite operator or function is not provided here, first ask yourself\nif it is part of any SQL standard. If it is not, then check the backend you are\nusing to see if it provides a corresponding construct. If the backend does not\nor if the function / operator you need is part of a SQL standard, please open an\nissue on GitHub. Alternatively, implement the construct yourself and send us a\npull request! See the section on  adding your own functions", 
            "title": "My favorite operator / function isn't listed here!"
        }, 
        {
            "location": "/reference/queries/", 
            "text": "Literals", 
            "title": "Queries"
        }, 
        {
            "location": "/reference/queries/#literals", 
            "text": "", 
            "title": "Literals"
        }, 
        {
            "location": "/reference/extensibility/", 
            "text": "The \nbeam-core\n library and respective backends strive to expose the full power\nof each underlying database. If a particular feature is missing, please feel\nfree to file a bug report on the GitHub issue tracker.\n\n\nHowever, in the meantime, beam offers a few options to inject raw SQL into your\nqueries. Of course, beam cannot predict types of expressions and queries that\nwere not created with its combinators, so \ncaveat emptor\n.\n\n\nCustom expressions\n\n\nIf you'd like to write an expression that beam currently does not support, you\ncan use the \ncustomExpr_\n function. Your backend's syntax must implement the\n\nIsSqlCustomExpressionSyntax\n type class. \ncustomExpr_\n takes a function of\narity \nn\n and \nn\n arguments, which must all be \nQGenExpr\ns with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same \ncustomExpr_\n).\n\n\nThe function supplied must return a \nByteString\n corresponding to the custom bit\nof SQL that implements your expression. The function's arguments are \nn\n\n\nByteString\ns corresponding to the expressions which will evaluate to the value\nof each of the arguments to \ncustomExpr_\n. The arguments are properly\nparenthesized and can be inserted whole into the final expression. You will\nlikely need to explicitly supply a result type using the \nas_\n function.\n\n\nCustom queries\n\n\nSometimes you would like to drop down to raw SQL to write a query that will\nreturn an entire result. Beam supports this through the \ncustomQuery_\n function.\nLike \ncustomExpr_\n, this takes a function of \nn\n arity and \nn\n arguments, which\nmay be either \nQGenExpr\ns or \nQ\ns from the same thread, select syntax, etc. The\nfunction supplied to \ncustomQuery_\n must return a \nByteString\n and its arguments\nare \nByteString\ns corresponding to the given \nQ\n or \nQGenExpr\n parameter.", 
            "title": "Extending"
        }, 
        {
            "location": "/reference/extensibility/#custom-expressions", 
            "text": "If you'd like to write an expression that beam currently does not support, you\ncan use the  customExpr_  function. Your backend's syntax must implement the IsSqlCustomExpressionSyntax  type class.  customExpr_  takes a function of\narity  n  and  n  arguments, which must all be  QGenExpr s with the same thread\nparameter. The expressions may be from different contexts (i.e., you can pass an\naggregate and scalar into the same  customExpr_ ).  The function supplied must return a  ByteString  corresponding to the custom bit\nof SQL that implements your expression. The function's arguments are  n  ByteString s corresponding to the expressions which will evaluate to the value\nof each of the arguments to  customExpr_ . The arguments are properly\nparenthesized and can be inserted whole into the final expression. You will\nlikely need to explicitly supply a result type using the  as_  function.", 
            "title": "Custom expressions"
        }, 
        {
            "location": "/reference/extensibility/#custom-queries", 
            "text": "Sometimes you would like to drop down to raw SQL to write a query that will\nreturn an entire result. Beam supports this through the  customQuery_  function.\nLike  customExpr_ , this takes a function of  n  arity and  n  arguments, which\nmay be either  QGenExpr s or  Q s from the same thread, select syntax, etc. The\nfunction supplied to  customQuery_  must return a  ByteString  and its arguments\nare  ByteString s corresponding to the given  Q  or  QGenExpr  parameter.", 
            "title": "Custom queries"
        }, 
        {
            "location": "/about/compatibility/", 
            "text": "Beam strives to cover the full breadth of the relevant SQL\nstandards. In general, if there is something in a SQL standard that is\nnot implemented in a generic manner in \nbeam-core\n, feel free to file\nan issue requesting support. There are some features that beam\npurposefully omits because no major RDBMS implements them. For\nexample, database-level assertions are not supported in any of the\ndefault beam backends, and thus are not supported by \nbeam-core\n. If\nyou have a need for these features, feel free to file an issue. Be\nsure to motivate your use case with examples and a testing strategy.\n\n\nThe relevant SQL standards are SQL-92, SQL:1999, SQL:2003, SQL:2008,\nand SQL:2011. Because not all the standards are not publicly\naccessible, I've done my best to piece together features from various\ndocuments available online. I believe I've covered most of the common\ncases, but there may be pieces of functionality that are missing. File\nan issue if this is the case.\n\n\nThe table below summarizes the features defined in each SQL standard\nand beam's support for them.\n\n\n\n\n\n\n\n\nFeature\n\n\nStandard\n\n\nStatus\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nTODO\n\n\nTODO\n\n\nTODO\n\n\nTODO", 
            "title": "Compatibility Matrix"
        }, 
        {
            "location": "/about/license/", 
            "text": "The MIT License (MIT)\n\n\nCopyright \u00a9 2017 Travis Athougies\n\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "License"
        }, 
        {
            "location": "/about/license/#the-mit-license-mit", 
            "text": "Copyright \u00a9 2017 Travis Athougies  Permission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \u201cSoftware\u201d), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:  The above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.", 
            "title": "The MIT License (MIT)"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "Beam Release Notes\n\n\n0.5.0.0\n\n\n\n\nMove to using finally tagless style for SQL generation\n\n\nSplit out backends from \nbeam-core\n\n\nAllow non-table entities to be stored in databases\n\n\nBasic migrations support", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#beam-release-notes", 
            "text": "", 
            "title": "Beam Release Notes"
        }, 
        {
            "location": "/about/release-notes/#0500", 
            "text": "Move to using finally tagless style for SQL generation  Split out backends from  beam-core  Allow non-table entities to be stored in databases  Basic migrations support", 
            "title": "0.5.0.0"
        }
    ]
}